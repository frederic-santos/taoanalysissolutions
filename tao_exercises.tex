\documentclass[11pt]{article}
\title{Propositions of solutions for \textit{Analysis I} by Terence Tao}
\author{Frédéric Santos}
% General packages:
\usepackage{a4wide}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc}
\usepackage{titlesec}
\titlelabel{\thetitle.\quad}
\usepackage{enumitem}
% Fonts and math packages:
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage[matha,mathb]{mathabx}
\usepackage{mbboard}
\usepackage{stmaryrd}
% Macros:
\newcommand{\successor}[1]{#1 \! +\!\!\!+}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\rr}{\mathbb{R}}
\newcommand{\partsof}[1]{\mathcal{P}\left( #1 \right)}
% Lemmas:
\usepackage{amsthm}
\newtheorem*{lem}{Lemma}
% Environment:
\newenvironment{exo}[2]{\noindent \textsc{Exercise #1}. ---
  \textit{#2} \vspace{3mm}}

% Begin doc:
\begin{document}
\maketitle

\section{Introduction}
\label{sec:introduction}
No exercises in this chapter.

\section{Starting at the beginning: the natural numbers}
\label{sec:natural-numbers}

\begin{exo}{2.2.1}{Prove that the addition is associative, i.e. that
    for any natural numbers $a, b, c$, we have $(a+b) + c = a + (b+c)$.}

  Let's use induction on $c$ while keeping $a$ and $b$ fixed.
  
  \begin{itemize}
  \item Base case for $c=0$: let's prove that $(a+b)+0 = a+(b+0)$. The
    left hand side is equal to $(a+b)$ according to Lemma 2.2.3. For the
    right hand side, if we apply the same lemma to the $(b+0)$ part,
    we get $a + (b+0) = a+b$. Both sides are equal to $a+b$, and the
    base case is thus done.
  \item Now let's suppose inductively that $(a+b) + c = a + (b+c)$: we
    have to prove that $(a+b) + \successor{c} = a + (b +
    \successor{c})$. Using Lemma 2.2.3 on the right
    hand side leads to $a + \successor{(b+c)}$. Now consider the left
    hand side. Using still the same lemma, we get $(a+b) +
    \successor{c} = \successor{\left((a+b) + c\right)}$. By the
    inductive hypothesis, this is also equal to
    $\successor{\left(a + (b+c)\right)}$. And, using the lemma 2.2.3
    again, this also leads to $a + \successor{b+c}$. Therefore, both
    sides are equal to $a + \successor{b+c}$, and we have closed the
    induction.
  \end{itemize}
\end{exo}

\begin{exo}{2.2.2}{Let $a$ be a positive number. Prove that there
    exists exactly one natural number $b$ such that $\successor{b} =
    a$.}
  
  Let's use induction on $a$.

  \begin{itemize}
  \item Base case for $a=1$: we know that $b=0$ matches this property,
    since $\successor{0} = 1$ by Definition 2.1.3. Furthermore, there
    is only one solution. Suppose that is another natural number $b$
    such that $\successor{b} = 1$. Then, we would have
    $\successor{b} = \successor{0}$, which would imply $b = 0$ by
    Axiom 2.4. The base case is demonstrated.
  \item Let's suppose inductively that there is exactly one natural
    number $b$ such that $\successor{b} = a$. We have to prove that
    there is exactly one natural number $b'$ such that
    $\successor{b'} = \successor{a}$. By the induction hypothesis, and
    taking $b' = \successor{b}$, we have
    $\successor{b'} = \successor{(\successor{b})} = \successor{a}$. So
    there exists a solution, with $b' = \successor{b} = a$. Uniqueness is
    given by Axiom 2.4.: if $\successor{b'} = \successor{a}$, then we
    necessarily have $b'=a$.
  \end{itemize}
\end{exo}

\begin{exo}{2.2.3}{Let $a, b, c$ be natural numbers. Prove the
    following properties of order for natural numbers:}
  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Reflexivity: $a \geq a$. This is true since $a = 0 + a$ by
    Definition 2.2.1. By commutativity of addition, we can also write
    $a = a + 0$. So there is indeed a natural number $n$ (with
    $n=0$) such that $a = a + n$, i.e. $a \geq a$.
  \item Transitivity: if $a \geq b$ and $b \geq c$, then $a \geq
    c$. From the part $a \geq b$, there exists a natural number $n$
    such that $a = b + n$ according to Definition 2.2.11. A similar
    consideration for the part $b \geq c$ leads to $b = c + m$, $m$
    being a natural number. Combining together those two equalities,
    we can write $a = b + n = (c + m) + n = c + (m + n)$ by
    associativity (see Exercise 2.2.1). Then, $n+m$ being a natural
    number\footnote{This is a trivial induction from the definition of
      addition.}, the transitivity is demonstrated.
  \item Anti-symmetry: if $a \geq b$ and $b \geq a$, then $a=b$. From
    the part $a \geq b$, there exists a natural number $n$ such that $a
    = b + n$. Similarly, there exists a natural number $m$ such that $b
    = a + m$. Combining those two equalities leads to $a = b + n = (a +
    m) + n = a + (m + n)$. By cancellation law (Proposition 2.2.6), we
    can conclude that $0 = m + n$. According to Corollary 2.2.9, this
    leads to $m = n = 0$. Therefore, both $m$ and $n$ are null,
    meaning that $a = b + 0 = b$.
  \item Preservation of order: $a \geq b$ iff $a + c \geq b +
    c$. First, let's prove that
    $a+c \geq b+c \Longrightarrow a \geq b$. If $a+c \geq b+c$, there
    exists a natural number $n$ such that $a+c = b+c+n$. By
    cancellation law (Proposition 2.2.6)\footnote{And also
      associativity and commutativity that we do not detail explicitly
      here.}, we conclude that $a = b + n$, i.e. $a\geq b$, thus
    demonstrating the first implication. Conversely, let's suppose
    that $a \geq b$. There exists a natural number $m$ such that
    $a = b + m$. Therefore, $a + c = b+m+c$ for any natural number
    $c$. Still by associativity and commutativity, we can rewrite this
    as $a+c = (b+c) +m$, i.e. $a+c \geq b+c$.
  \item $a < b$ iff $\successor{a} \leq b$. First, let's prove that
    $\successor{a} \leq b \Longrightarrow a < b$. By definition of
    ordering, there exists a natural number $n$ such that
    $b = (\successor{a}) + n$. By definition of addition, we can
    re-write: $b = \successor{(\successor{a} + n)}$. Then, by
    commutativity and yet again by definition of addition,
    $b = \successor{(n + \successor{a})} = (\successor{n}) +
    (\successor{a})$. Thus, there exists a natural number
    $\successor{n}$ such that $b = \successor{n} + a$, which means that
    $b \geq a$. But we still have to prove that $a \neq b$. Let's
    suppose that $a=b$: in this case, by cancellation law, we would
    have $\successor{n} = 0$, which is impossible according to Axiom
    2.3 (0 is not the successor of any natural number). Thus, $a \neq
    b$ et $b \geq a$: we have showed that $a < b$. 

    Conversely, let's prove that
    $a < b \Longrightarrow \successor{a} \leq b$. Starting from that
    strict inequality, there exists a \textit{positive}\footnote{We
      make use here of the statement \textit{(f)} demonstrated
      below. There is no circularity here, since proving \textit{(f)}
      will not make use of \textit{(e)}.} natural number $n$ such that
    $b = a + n$. By Lemma 2.2.10, since $n$ is positive, it has one
    unique antecessor $m$, so that $n$ can be written
    $\successor{m}$. Thus,
    $b = a + (\successor{m}) = \successor{(a + m)} = \successor{(m +
      a)} = m + (\successor{a}) = (\successor{a}) + m$. And, $m$ being
    a natural number, this corresponds to the statement $b \geq a$.
  \item $a < b$ iff $b=a+d$ for some positive number $d$. First, let's
    prove the first implication, $a<b \Longrightarrow b=a+d$ with
    $d \neq 0$. Since $a<b$, we have in particular $a \leq b$, and
    there exists a natural number $d$ such that $b=a+d$. For the sake
    of contradiction, let's suppose that $d=0$. We would have $b=a$,
    which would contradict the condition $a\neq b$ of the strict
    inequality. Thus, $d$ is a positive number, which demonstrates the
    left-to-right implication.

    Conversely, let's suppose that $b = a+d$, with $d \neq 0$. This
    expression gives immediately $a \leq b$. But if $a=b$, by
    cancellation law, this would lead to $0=d$, a contradiction with
    the fact that $d$ is a positive number. Thus, $a\neq b$ and $a
    \leq b$, which demonstrates $a<b$.
  \end{enumerate}
\end{exo}

\begin{exo}{2.2.4}{Demonstrate three lemmas used to prove the
    trichotomy of order for natural numbers.}
  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Show that we have $0 \leq b$ for any natural number $b$. This is obvious
    since, by definition of addition, $0 + b = b$ for any natural
    number $b$. This is precisely the definition of $0 \leq b$.
  \item Show that if $a > b$, then $\successor{a} > b$. If $a > b$,
    then $a = b + d$, $d$ being a positive natural number. Let's
    recall that $\successor{a} = a + 1$. Thus, $\successor{a} = a + 1
    = b + d + 1 = b + (d+1)$ by associativity of
    addition. Furthermore, $d+1$ is a positive natural number (by
    Proposition 2.2.8). Thus, $\successor{a} > b$.
  \item Show that if $a=b$, then $\successor{a}>b$. Once again, let's
    use the fact that $\successor{a} = a+1$. Thus, $\successor{a} =
    a+1 = b+1$, and $1$ is a positive natural number. This is the
    definition of $\successor{a}>b$.
  \end{enumerate}
\end{exo}

\begin{exo}{2.2.5}{Prove the strong principle of induction, formulated
    as follows: Let $m_0$ be a natural number, and let $P(m)$ be a
    property pertaining to an arbitrary natural number $m$. Suppose
    that for each $m \geq m_0$, we have the following implication: if
    $P(m')$ is true for all natural numbers $m_0 \leq m' < m$, then
    $P(m)$ is also true. (In particular, this means that $P(m_0)$ is
    true, since in this case the hypothesis is vacuous.) Then we can
    conclude that $P(m)$ is true for all natural numbers
    $m \geq m_0$.}

  First let's introduce a small lemma (similar to Proposition
  2.2.12\textit{(e)}).

  \begin{lem}
    For any natural number $a$ and $b$, $a<\successor{b}$ iff $a\leq
    b$.
  \end{lem}
  \begin{proof}
    If $a < \successor{b}$, then $\successor{b} = a+n$ for a given
    positive natural $n$. By Lemma 2.2.10, there exists one natural
    number $m$ such as $n = \successor{m}$. Thus $\successor{b} = a +
    \successor{m}$, which can be rewritten $\successor{b} =
    \successor{(a+m)}$ by Lemma 2.2.3\footnote{We could also rewrite
      $b+1 = a + m + 1$ and then use the cancellation law.}. By Axiom
    2.4., this is equivalent to $b = a+n$, which can also be written
    $a \leq b$.
    
    Conversely, if $a \leq b$, there exists a natural number $m$
    such as $b = a+m$. Thus, $\successor{b} = \successor{(a+m)} =
    a + (\successor{m})$ by Definition of addition
    (2.2.1). And, $\successor{m}$ being a positive
    number, this means that $b > a$ according to Proposition
    2.2.12\textit{(f)}.
  \end{proof}

  Now we can prove the main proposition. Let $Q(n)$ be the property
  ``$P(m)$ is true for all $m$ such that $m_0 \leq m < n$''. Let's
  induct on $n$.

  \begin{itemize}
  \item (Although this is not necessary,) we could consider two types
    of base cases. If $n < m_0$, $Q(n)$ is the proposition ``$P(m)$ is
    true for all $m$ such that $m_0 \leq m < n$'', but there is no
    such natural number $m$. Thus, $Q(n)$ is vacuously true. If
    $n = m_0$, $P(m_0)$ is true by hypothesis, thus $Q(m_0)$ is also
    true.
  \item Now let's suppose inductively that $Q(n)$ is true, and show
    that $Q(\successor{n})$ is also true. If $Q(n)$ is true, $P(m)$ is
    true for all $m$ such that $m_0 \leq m < n$. By hypothesis, this
    implies that $P(n)$ is true. Thus, $P(m)$ is true for any natural
    number $m$ such that $m_0 \leq m \leq n$, i.e. such that $m_0 \leq
    m < \successor{n}$ according to the lemma introduced above. This
    is precisely $Q(\successor{n})$, and this closes the induction.
  \end{itemize}
  Thus, $Q(n)$ is true for all natural numbers $n$, which means in
  particular that $P(m)$ is true for any natural number $m \geq
  m_0$. This demonstrates the principle of strong induction.
\end{exo}

\bigskip
\begin{exo}{2.2.6}{Let $n$ be a natural number, and let $P(m)$ be a
    property pertaining to the natural numbers such that whenever
    $P(\successor{m})$ is true, then $P(m)$ is true. Suppose that
    $P(n)$ is also true. Prove that $P(m)$ is true for all natural
    numbers $m \leq n$; this is known as the \emph{principle of
      backwards induction}.}
  
  Terence Tao suggests to use induction on $n$. So let $Q(n)$ be the
  following property: ``if $P(n)$ is true, then $P(m)$ is true for all
  $m \leq n$. The goal is to prove $Q(n)$ for all natural numbers $n$.

  \begin{itemize}
  \item Base case $n = 0$: here, $Q(n)$ means that if $P(0)$ is true,
    then $P(m)$ is true for any $m \leq 0$. By Definition 2.2.11, if
    $m \leq 0$, there exists a natural number $d$ such that $0 = m +
    d$. But, by Corollary 2.2.9, this implies that both $m = 0$ and $d
    = 0$. Thus, the only number $m$ such that $m \leq 0$ is 0
    itself. Therefore, $Q(0)$ is simply the tautology ``if $P(0)$ is
    true, then $P(0)$ is true''--- a statement that we can safely
    accept. The base case is the, demonstrated.
  \item Let's suppose inductively that $Q(n)$ is true: we must show
    that $Q(\successor{n})$ is also true. If $P(\successor{n})$ is
    true, then by definition of $P$, $P(n)$ is also true. Then, by
    induction hypothesis, $P(m)$ is true for all $m \leq n$. We have
    showed that $P(\successor{n})$ implies $P(m)$ for all
    $m \leq \successor{n}$\footnote{Actually, we use here yet another
      lemma, similar to the one introduced for the previous
      exercise. We use the fact that $m \leq \successor{n}$ is
      equivalent to $m = \successor{n}$ or $m \leq n$, which is easy
      to prove, but is not part of the ``standard'' results presented
      in the textbook.}, which is precisely $Q(\successor{n})$. This
    closes the induction.
  \end{itemize}
\end{exo}

\begin{exo}{2.3.1}{Show that multiplication is commutative, i.e., if
    $n$ and $m$ are natural numbers, show that $n \times m = m \times
    n$.}

  We will use an induction of $n$ while keeping $m$ fixed. However,
  this is not a trivial result, and even the base case is not
  straightforward. We will first introduce some lemmas.

  \begin{lem}
    For any natural number $n$, $n \times 0 = 0$.
  \end{lem}

  \begin{proof}
    Let's induct on $n$.
    For the base case $n=0$, we know by Definition 2.3.1 of
    multiplication that $0 \times 0 = 0$, since $0 \times m = 0$ for
    any natural number $m$.

    Now let's suppose that $n \times 0 = 0$. Thus, $\successor{n}
    \times 0 = (n \times 0) + 0$ by Definition 2.3.1. But by induction
    hypothesis, $n \times 0 = 0$, so that $\successor{n} \times 0 = 0
    + 0 = 0$. This closes the induction.
  \end{proof}

  \begin{lem}
    For all natural numbers $m$ and $n$, we have $m \times \successor{n} = (m
    \times n) + m$.
  \end{lem}

  \begin{proof}
    Let's induct on $m$. The base case $m=0$ is easy to prove: $0
    \times \successor{n} = 0$ by Definition 2.3.1 of multiplication, and $(0
    \times n) + 0 = 0$.

    Now suppose inductively that
    $m \times \successor{n} = (m \times n) + m$, and we must show that
    \begin{equation}
      \label{eq:proof_lemma_231}
      \successor{m} \times \successor{n} = (\successor{m} \times n) +
      \successor{m}
    \end{equation}

    We begin by the left hand side: by Definition
    2.3.1,
    $\successor{m} \times \successor{n} = (m \times \successor{n}) +
    \successor{n}$. By induction hypothesis, this is equal to
    $(m \times n) + m + \successor{n}$.

    Then, apply the definition of multiplication to the right hand
    side:
    $(\successor{m} \times n) + \successor{m} = (m \times n) + n +
    \successor{m}$. The Lemma 2.2.3 and the commutativity of addition
    leads to
    $(m \times n) + n + \successor{m} = (m \times n) + \successor{(n +
      m)} = (m \times n) + \successor{(m + n)} = (m \times n) + m +
    \successor{n}$, which is equal to the left hand side.

    Thus, both sides of equation \eqref{eq:proof_lemma_231} are equal,
    and we can close the induction.
  \end{proof}
  
  Now it is easier to prove the main result ($n \times m = m \times
  n$), by an induction on $n$.

  \begin{itemize}
  \item Base case $n = 0$: we already know by Definition 2.3.1 that $0
    \times m = 0$. The first lemma introduced in this exercise also
    provides $m \times 0 = 0$. Thus, the base case is proved, since $0
    \times m = m \times 0 \; (= 0)$.
  \item Now we suppose inductively that $n \times m = m \times n$, and
    we must prove that:
    \begin{equation}
      \label{eq:recurr_commutativity_of_multiplication}
      \successor{n} \times m = m \times \successor{n}
    \end{equation}
    By Definition 2.3.1 of multiplication, the left hand side is equal
    to $(n \times m) + m$.

    Using the lemma introduced above, the right hand side is equal to
    $(m \times n) + m$. By induction hypothesis, this is also equal to
    $(n \times m) + m$, which closes the induction.
  \end{itemize}  
\end{exo}

\begin{exo}{2.3.2}{Show that positive natural numbers have no zero
    divisors, i.e. that $nm=0$ iff $n=0$ or $m=0$. In particular, if
    $n$ and $m$ are both positive, then $nm$ is also positive.}

  We will prove the second statement first. Suppose, for the sake of
  contradiction, that $nm = 0$ and that both $n$ and $m$ are positive
  numbers. Since they are positive, by Lemma 2.2.10, there exists two
  (unique) natural numbers $a$ and $b$ such that $n = \successor{a}$
  and $m = \successor{b}$. Thus, the hypothesis $nm=0$ can also be
  written $(\successor{a}) \times (\successor{b}) = 0$. But, by
  Definition 2.3.1  of multiplication, $(\successor{a}) \times
  (\successor{b}) = (a \times \successor{b}) + \successor{b}$. Thus,
  we should have $(a \times \successor{b}) + \successor{b} = 0$. By
  Corollary 2.2.9, this implies that both $(a \times \successor{b}) =
  0$ and $\successor{b} = 0$, which is impossible since zero is the
  successor of no natural number (Axiom 2.3).

  Thus, we have proved that if $n$ and $m$ are both positive, then
  $nm$ is also positive.  The main statement can now be proved more
  easily.

  \begin{itemize}
  \item The right-to-left implication is straightforward: if $n=0$,
    then by Definition of multiplication, $n \times m = 0 \times m =
    0$. Since multiplication is commutative, we have the same result
    if $m = 0$.
  \item The left-to-right implication is exactly the contrapositive of
    the statement we have just proved above.
  \end{itemize}
\end{exo}

\begin{exo}{2.3.3}{Show that multiplication is associative, i.e., for
    any natural numbers $a, b,c $, we have $(a\times b) \times c = a
    \times (b \times c)$.}

  We will induct on $c$ while keeping $a$ and $b$ fixed.

  \begin{itemize}
  \item Base case: for $c=0$, we must prove that $(a \times b) \times
    0 = a \times (b \times 0)$. The left hand side is equal to 0 by
    definition (and commutativity) of
    multiplication\footnote{Actually, we use the second lemma
      introduced for the resolution of Exercise 2.3.1.}. The right hand
    side is equal to $a0$, which is also 0. Both sides are null, and
    the base case is proved.
  \item Suppose inductively that
    $(a\times b) \times c = a \times (b \times c)$, and let's prove
    that
    $(a\times b) \times \successor{c} = a \times (b \times
    \successor{c})$. By definition (and commutativity) of
    multiplication, the left hand side is equal to $(a \times b)
    \times c + (a \times b)$. The right hand side is equal to $a
    \times (b \times c + b)$, and by distributive law (i.e.,
    Proposition 2.3.4), this is also $a \times (b \times c) + a \times
    b$. But then, by inductive hypothesis, this can be rewritten $(a
    \times b) \times c + a \times b$, which is equal to the left hand
    side. The induction is closed.
  \end{itemize}
\end{exo}

\begin{exo}{2.3.4}{Prove the identity $(a + b)^2 = a^2 + 2ab + b^2$
    for all natural numbers $a,b$.}

  By distribution law (i.e., Proposition 2.3.4) and commutativity of
  multiplication, we have:

  \begin{align*}
    (a+b)^2 &= (a+b)(a+b) = (a+b)a + (a+b)b \\
            &= a\times a + b \times a + a \times b + b \times b \\
            &= a^2 + a \times b + a \times b + b^2 \\
            &= a^2 + 2 ab + b^2
  \end{align*}

  (For the last step, we recall that, by Definition 2.3.1, $2 \times m
  = m + m$ for any natural number $m$.)
\end{exo}

\bigskip
\begin{exo}{2.3.5}{Euclidean algorithm. Let $n$ be a natural number, and let $q$ be a
    positive number. Prove that there exists natural numbers $m, r$
    such that $0 \leq r < q$ and $n = mq + r$.}

  We will induct on $n$ while remaining $q$ fixed.

  \begin{itemize}
  \item Base case: if $n=0$, there exists an obvious solution, namely
    $m=0$ and $r=0$.
  \item Suppose inductively that there exists $m, r$ such that $n = mq
    + r$ with $0 \leq r < q$, and let's prove that there exists $m', r'$ such that
    $n+1 = m'q+r'$, with $0 \leq r' < q$.

    By the induction hypothesis, we have $n + 1 = mq + r + 1$. Since
    $r < q$, we have $r + 1 \leq q$ (this is Proposition
    2.2.12). Thus, we have two cases here:

    \begin{enumerate}
    \item If $r+1 < q$, then $n+1 = mq + (r+1)$, with $0 \leq r+1 <q$,
      so that choosing $m' = m$ and $r' = r+1$ is convenient.
    \item If $r+1 = q$, then $n + 1 = mq + q = (m + 1)q$ according to
      the distributive law (Proposition 2.3.4). Thus, choosing $m' =
      m+1$ and $r' = 0$ is convenient.
    \end{enumerate}
  \end{itemize}
  This closes the induction.
\end{exo}

\section{Set theory}
\begin{exo}{3.1.2}{Using only Definition 3.1.4, Axiom 3.1, Axiom 3.2,
    and Axiom 3.3, prove that the sets $\emptyset$, $\{\emptyset\}$,
    $\{\{\emptyset\}\}$, and $\{\emptyset, \{\emptyset\}\}$ are all
    distinct (i.e., no two of them are equal to each other).}

  As a general reminder, we recall that sets are objects (Axiom 3.1)
  and the empty set $\emptyset$ is such that no object is an element of
  $\emptyset$, thus $\emptyset \notin \emptyset$.
  
  \begin{enumerate}
  \item First let's show that $\emptyset$ is different from all other
    sets. $\emptyset$ is an element of $\{\emptyset\}$ and
    $\{\emptyset, \{\emptyset\}\}$, and $\{\emptyset\}$ is an element
    of $\{\{\emptyset\}\}$. But none of those two objects are elements
    of $\emptyset$ (by Axiom 3.2), thus $\emptyset$ is different from
    all three other sets.
  \item Then let's show that $\{\emptyset\} \neq
    \{\{\emptyset\}\}$. By Axiom 3.3, the singleton $\{\emptyset\}$ is
    such that $x \in \{\emptyset\} \Longleftrightarrow x =
    \emptyset$. Similarly, the singleton $\{\{\emptyset\}\}$ is such
    that $x \in \{\{\emptyset\}\} \Longleftrightarrow x =
    \{\emptyset\}$. But we already know that $\emptyset \neq
    \{\emptyset\}$ so there exists an object, $\emptyset$, which is a
    element of $\{\emptyset\}$ but not an element of
    $\{\{\emptyset\}\}$. Those sets are not equal.
  \item Now let's show that $\{\emptyset\} \neq \{\emptyset,
    \{\emptyset\}\}$. By Axiom 3.3, the pair $\{\emptyset,
    \{\emptyset\}\}$ is such that $x$ is an element of this set iff $x
    = \emptyset$ or $x = \{\emptyset\}$. Thus, $\{\emptyset\}$ is an
    element of $\{\emptyset, \{\emptyset\}\}$, but is not an element
    of $\{\emptyset\}$ (if it was, we should have $\emptyset =
    \{\emptyset\}$, which would be a contradiction with the first
    point of this proof). Those two sets are thus different.
  \item Finally, we also have
    $\{\{\emptyset\}\} \neq \{\emptyset, \{\emptyset\}\}$. Indeed, we
    have $\emptyset \in \{\emptyset, \{\emptyset\}\}$ by Axiom
    3.3. However,
    $\emptyset \in \{\{\emptyset\}\} \Longleftrightarrow \emptyset =
    \{\emptyset\}$ by definition of a singleton, and we know this
    latest statement is false by the first point of this proof. Those
    two sets are also different.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.3}{Prove the remaining claims in Lemma 3.1.13.}

  Those claims are the following:
  \begin{enumerate}
  \item $\{a,b\} = \{a\} \cup \{b\}$. By Axiom 3.3, the pair $\{a,
    b\}$ is such that $x \in \{a, b\} \Longleftrightarrow x = a$ or $x
    = b$. Let's consider three cases:
    \begin{itemize}
    \item if $x = a$, $x \in \{a\}$ by Axiom 3.3, thus $x \in \{a\}
      \cup \{b\}$ by Axiom 3.4
    \item if $x = b$, $x \in \{b\}$ by Axiom 3.3, thus $x \in \{a\}
      \cup \{b\}$ by Axiom 3.4
    \item if $x \neq a$ and $x \neq b$, $x \notin \{a\}$ and $x \notin
      \{b\}$ by Axiom 3.3, so that $x \notin \{a\} \cup \{b\}$
    \end{itemize}
    Thus, $\{a,b\}$ and $\{a\} \cup \{b\}$ have the same elements, and
    are equal.
  \item $A \cup B = B \cup A$ for all sets $A$ and $B$. Indeed, $x \in
    A \cup B \Longleftrightarrow x \in A$ or $x \in B$. If $x \in A$,
    then $x \in B \cup A$ by Axiom 3.4. A similar argument holds if $x
    \in B$. Thus, in both cases, $x \in B \cup A$. We can show in a
    similar fashion that any element of $B \cup A$ is in $A \cup B$.
  \item $A \cup \emptyset = \emptyset \cup A = A$. Since we've just
    showed that union is commutative, proving $A \cup \emptyset = A$
    is sufficient. If $x \in A$, then $x \in A \cup \emptyset$. The
    converse is also true: if $x \in A \cup \emptyset$, then $x \in A$
    or $x \in \emptyset$. But there is no element in $\emptyset$, so
    that we have necessarily $x \in A$. Thus, $A \cup \emptyset$ and
    $A$ have the same elements: they are equal.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.4}{Prove the remaining claims from Proposition 3.1.18.}

  Let $A, B, C$ be sets. Those claims are the following:

  \begin{enumerate}
  \item If $A \subseteq B$ and $B \subseteq A$, then $B =
    A$. According to Definition 3.1.4, two sets $A$ and $B$ are equal
    iff every element of $A$ is an element of $B$, and vice
    versa. This is precisely the present claim.
  \item If $A \subsetneq B$ and $B \subsetneq C$, then
    $A \subsetneq C$. Let $x$ be an element of $A$. Since
    $A \subsetneq B$, $x$ is also an element of $B$. And since
    $B \subsetneq C$, $x$ is also an element of $C$. This holds for
    any $x$ in $A$, and thus it demonstrates that $A \subset
    C$. Furthermore, since $A \subsetneq B$, there exists an element
    $y \in B$ which is not an element of $A$. As $B \subsetneq C$, $y$
    is also an element of $C$. Thus we have $y$, an element of $C$
    which is not in $A$. Combined to the previous result $A \subset
    C$, this demonstrates $A \subsetneq C$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.5}{Let $A, B$ be sets. Show that the three statements
    $A \subseteq B$, $A \cup B = B$ and $A \cap B = A$ are logically
    equivalent (i.e., any one of them implies the other two).}
  \begin{enumerate}
  \item First, we prove that
    $A \subseteq B \Longrightarrow A \cup B = B$. The first inclusion
    $B \subseteq A \cup B$ is trivial, since any element of a set $B$
    is always either in $A$ or $B$. For the converse inclusion, let
    $x$ be an element of $A \cup B$, and let's prove that $x \in
    B$. By Axiom 3.4, we have $x \in A$ or $x \in B$. If $x \in B$,
    the result holds. If $x \in A$, then we also have $x \in B$ since
    $A \subseteq B$. Thus, any element of $A \cup B$ is an element of
    $B$, which demonstrates the equality $A \cup B = B$.
  \item Then, we prove that $A \cup B = B \Longrightarrow A \cap B =
    A$. The first inclusion is trivial: if $x \in A \cap B$, then we
    always have $x \in A$. Now let's prove the converse inclusion: let
    $x$ be an element of $A$; we must show that $x \in A \cap B$. If
    $x \in A$, then $x \in A \cup B$. But, by hypothesis, $A \cup B =
    B$, thus $x \in B$. So, $x \in A$ and $x \in B$, i.e. $x \in A
    \cap B$. This demonstrates the implication.
  \item Finally, we prove that $A \cap B = A \Longrightarrow A
    \subseteq B$. Let $x \in A$. Since $A \cap B = A$, we have $x \in
    A \cap B$. It follows that $x \in B$. We have proved that any
    element $x \in A$ is also an element of $B$, i.e. $A \subseteq B$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.8}{Let A, B be sets. Prove the absorption laws
    $A \cap (A \cup B) = A$ and $A \cup (A \cap B) = A$.}
  \begin{enumerate}
  \item The first inclusion $A \cap (A \cup B) \subseteq A$ is
    trivial: if $x \in A \cap (A \cup B)$ then in particular $x \in A$
    by Definition 3.1.23 of an intersection\footnote{This intersection
      is not empty since $A$ and $A \cup B$ are not disjoint.}. Thus,
    we have $A \cap (A \cup B) \subseteq A$.

    For the converse inclusion, let $x$ be an element of $A$. Then by
    definition $x \in A$, and we have also $x \in A \cup B$ since $x
    \in A$. Thus, $x \in A \cap (A \cup B)$, which proves the converse
    inclusion.

    Consequently, $A = A \cap (A \cup B)$.
  \item First we show that $A \cup (A \cap B) \subseteq A$. Let
    $x \in A \cup (A \cap B)$. By Definition of an union, we have
    either $x \in A$, or $x \in A \cap B$. In both cases\footnote{If
      $A$ and $B$ are disjoint, then the first case $x \in A$
      necessarily holds, since $x \in A \cup B$ is impossible.}, we
    have $x \in A$, so that the inclusion is proved.

    Conversely, let $x \in A$. Then in particular, we have $x \in A
    \cup (A \cap B)$ by Definition of an union, because $x \in
    A$. Thus, $x \in A \cup (A \cap B)$.

    We have proved that $A \cup (A \cap B) = A$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.9}{Let $A, B, X$ be sets such that $A \cup B = X$ and
    $A \cap B = \emptyset$. Show that $A = X \backslash B$ and
    $B = X \backslash A$.}

  The two sets $A$ and $B$ play a symmetrical role here, so that
  proving one of these two assertions is sufficient. For instance, we
  prove that $A = X \backslash B$.

  \begin{itemize}
  \item Let $x$ be an element of $A$. Since $x \in A$, we also have $x
    \in A \cup B$ by definition of an union. But $A \cup B = X$, and
    then $x \in X$. On the other hand, we cannot have $x \in B$,
    because $x \in A$ and the sets $A, B$ are disjoint. Thus, $x \in
    X$ and $x \notin B$, which means that $x \in X \backslash B$. We
    have proved that $A \subseteq X \backslash B$.
  \item Conversely, let $x$ be an element of $X \backslash B$. By
    definition, this means that $x \in X$, i.e. $x \in A \cup B$, and
    $x \notin B$. Since $x \in A \cup B$, we have either $x \in A$ or
    $x \in B$, but we know that the latter is impossible. Thus, we
    have necessarily $x \in A$. We have proved that $X \backslash B
    \subseteq A$.
  \item We can conclude that $X \backslash B = A$.
  \end{itemize}
  
\end{exo}

\begin{exo}{3.1.11}{Prove that the axiom of replacement (Axiom 3.6)
    implies the axiom of specification (Axiom 3.5).}
  
  Let's recall the axiom of replacement. Let $A$ be a set. For every
  $x \in A$, and for every (abstract) object $y$, let $P(x,y)$ be a
  statement pertaining to both $x$ and $y$, such that for any
  $x \in A$ there is at most one $y$ for which $P(x,y)$ is true. Then
  there exists a set
  $\{y \, : \, P(x,y) \text{ is true for some } x \in A \}$, such that
  for any object $z$,
  \[z \in \{y \, : \, P(x,y) \text{ is true for some } x \in A \}
    \Longleftrightarrow P(x,z) \text{ is true for some } x \in A\]

  Now, let $A$ be a set, $x$ an element of $A$, and $y$ an object. We
  accept the axiom of replacement, and show that it implies the axiom
  of specification.

  Let $Q(x,y)$ be the property ``$x = y$ and $P(x)$''. According to
  the axiom of replacement, there exists a set
  $\{y \, : \, Q(x,y) \text{ is true for some } x \in A\}$ such that:
  \begin{align*}
    & z \in \{y \, : \, Q(x,y) \text{ is true for some } x \in A \} \\
    \Longleftrightarrow \; & Q(x,z) \text{ is true for some } x \in A \\
    \Longleftrightarrow \; & x = z \text{ and } P(x) \text{ is true
                             for some } x \in A
    \\
    \Longleftrightarrow \; & x = z \text{ and } P(z) \text{ is true
                             for some } x \in A \text{ 
                             (by axiom of substitution)} \\
    \Longleftrightarrow \; & z \in A \text{ and } P(z) \text{ is true }
  \end{align*}

  Thus, we have proved the existence of a set (the set $\{y \, : \,
  Q(x,y) \text{ is true for some } x \in A \}$) satisfying the axiom
  of specification: $z$ belongs to this set iff $z \in A$ and $P(z)$
  is true.
\end{exo}

\bigskip

\begin{exo}{3.3.1}{Show that the definition of equality in Definition
    3.3.7 is reflexive, symmetric and transitive. Also verify the
    substitution property: if $f_1, f_2 : X \rightarrow Y$ and $g_1,
    g_2 : Y \rightarrow Z$ are functions such that $f_1 f_2$ and $g_1
    = g_2$, then $g_1 \circ f_1 = g_2 \circ f_2$.}

  \begin{enumerate}
  \item Definition 3.3.7 says that two functions $f$ and $g$ are equal
    if they have same domain $X$ and range $Y$, and if, for all
    $x \in X$, $f(x) = g(x)$. This definition of equality is obviously
    reflexive, symmetric and transitive if we assume that the objects
    in the domain $X$ and the range $Y$ verify themselves the axioms
    of equality.
  \item Since $f_1 = f_2$, they have same domain $X$ and same range
    $Y$. This is also the case for $g_1$ and $g_2$, with domain $Y$
    and range $Z$. Thus, $g_1 \circ f_1$ has domain $X$ and range $Z$,
    and so has $g_2 \circ f_2$. Furthermore, we have, for all
    $x \in X$:
    \begin{align*}
      g_2 \circ f_2(x) &= g_2 \circ f_1(x) \text{ (since $f_1 = f_2$)}
      \\
                       &= g_1 \circ f_1(x) \text{ (since $g_1 = g_2$)}
    \end{align*}
    which closes the demonstration.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.2}{Let $f : X \rightarrow Y$ and $g : Y \rightarrow Z$
    be functions. Show that if $f$ and $g$ are both injective, then so
    is $g \circ f$. Similarly, show that if $f$ and $g$ are both
    surjective, then so is $g \circ f$.}

  First let's note that $g \circ f : X \rightarrow Z$.

  \begin{enumerate}
  \item Suppose that $f$ and $g$ are both injective, and let
    $x, x' \in X$. We have successively :
    \begin{eqnarray*}
      g \circ f (x) & =& g \circ f (x') \\
      g(f(x)) &=& g(f(x'))  \\
      f(x) &=& f(x') \; \text{ because $g$ is injective}\\
      x &=& x' \; \text{ because $f$ is injective}
    \end{eqnarray*}
    We have showed that $g \circ f (x) = g \circ f (x') \Rightarrow x
    = x'$ for all $x, x' \in X$, i.e. that $g \circ f$ is injective.
    
  \item Suppose that $f$ and $g$ are both surjective, and let
    be $z \in Z$. Since $g$ is surjective, there exists $y \in Y$ such
    that $z = g(y)$. And since $f$ is surjective, there exists $x \in
    X$ such that $y = f(x)$. Thus, combining those two results, there
    exists $x \in X$ such that $z = g(f(x))$. This means precisely
    that $g \circ f$ is surjective.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.3}{When is the empty function injective? surjective?
    bijective?}
  
  Let $f$ be the empty function, i.e. $f : \emptyset \rightarrow Y$
  for a certain range $Y$.
  \begin{enumerate}
  \item $f$ is injective iff $x \neq x' \Rightarrow f(x) \neq
    f(x')$. This can be considered as vacuously true since there are
    no such $x$ and $x'$. $f$ can be considered as always injective,
    for any range $Y$.
  \item $f$ is surjective iff for any $y \in Y$, there exists $x \in
    \emptyset$ such that $y = f(x)$. We can clearly see that this
    assertion is false if $Y \neq \emptyset$, since any $y \in Y$ will
    have no antecedent in $\emptyset$. Conversely, if $Y = \emptyset$,
    the assertion is vacuously true, since there is no element in
    $Y$. Thus, $f$ is surjective iff $Y = \emptyset$.
  \item Since $f$ is always injective, and is surjective iff $Y =
    \emptyset$, it is clear that $f$ is bijective iff $Y = \emptyset$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.4}{Let $f : X \rightarrow Y$, $\tilde{f} : X
    \rightarrow Y$, $g : Y \rightarrow Z$, $\tilde{g} : Y \rightarrow
    Z$ be functions. Show that if $g \circ f = g \circ \tilde{f}$ and
    $g$ is injective, then $f = \tilde{f}$. Is this statement true if
    $g$ is not injective? Also, show that if $g \circ f = \tilde{g}
    \circ f$ and $f$ is surjective, then $g = \tilde{g}$. Is this
    statement true if $f$ is not surjective?}

  This exercise introduces some cancellation laws for composition.

  \begin{enumerate}
  \item First, note that $f$ and $\tilde{f}$ have same domain and
    range, which is the first condition for two functions to be equal
    (by Definition 3.3.7). Then, suppose that
    $g \circ f = g \circ \tilde{f}$ and $g$ is injective. For the sake
    of contradiction, suppose that there exists $x \in X$ such that
    $f(x) \neq \tilde{f}(x)$. Since $g$ is injective, we would thus
    have $g(f(x)) \neq g(\tilde{f}(x))$, which would be a
    contradiction to the hypothesis $g \circ f = g \circ
    \tilde{f}$. Thus, there is no $x$ such that $f(x) = \tilde{f}(x)$,
    or in other words, $f = \tilde{f}$.

    This property is false if $g$ is not injective. As a
    counterexample, one can think of $f : \rr \rightarrow \rr$ with
    $f(x) = x$, $\tilde{f} : \rr \rightarrow \rr$ with
    $\tilde{f}(x) = -x$, and $g : \rr \rightarrow \rr_+$ with
    $g(x) = |x|$.
  \item As previously, first note that $g$ and $\tilde{g}$ have same
    domain and range. Let be $y, y' \in Y$. Since $f$ is surjective,
    there exist $x, x' \in X$ such that $y = f(x)$ and $y' = f(x')$
    respectively. Since $g \circ f = g \circ \tilde{f}$, we have
    $g(f(x)) = g(f(x'))$, i.e. $g(y) = g(y')$. We have showed that,
    for any $y, y' \in Y$, we have $g(y) = g(y')$, which means that $g
    = \tilde{g}$.

    This statement is false if $f$ is not surjective. For instance,
    let $f$ be a constant function, e.g. $f : \rr \rightarrow \rr$
    with $f(x) = 1$ for all $x$. Let $g, \tilde{g} : \rr \rightarrow
    \rr$ with $g(x) = 0$ and $\tilde{g}(x) = - x +1$. We have $g(1) =
    \tilde{g}(1)$, i.e. $g(f(x)) = \tilde{g}(x)$ for all $x \in X$,
    but we obviously do not have $g = \tilde{g}$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.5}{Let $f : X \rightarrow Y$ and $g : Y \rightarrow Z$
    be functions. Show that if $g \circ f$ is injective, then $f$ must
    be injective. Is it true that $g$ must also be injective? Show that
    if $g \circ f$ is surjective, then $g$ must be surjective. Is it
    true that $f$ must be surjective?}

  \begin{enumerate}
  \item If $g \circ f$ is injective, then for any given objects
    $x, x' \in X$, we have $g(f(x)) = g(f(x')) \Longrightarrow x =
    x'$. For the sake of contradiction, suppose that $f$ is not
    injective. In this case, there exist two elements $a, a' \in X$ such
    that $a \neq a'$ and $f(a) = f(a')$. We would thus have $g(f(a)) =
    g(f(a'))$ (axiom of substitution) and $a \neq a'$, which is
    incompatible with the hypothesis that $g \circ f$ is injective.

    Thus, $g \circ f$ injective implies that $f$ is injective.

    However, $g$ does not need to be injective. For instance, let's
    consider $X = \{1,2\}$ and $Y = Z = \{1, 2, 3\}$. Let's define the
    function $f$ as the mapping $f(1) = 1$, $f(2) = 2$. Let's define the
    function $g$ as the mapping $g(1) = 1$, $g(2) = 2$, $g(3) = 2$. Here,
    $f$ is injective, so is $g \circ f$, but $g$ is not injective.
  \item If $g \circ f$ is surjective, then for all $z \in Z$, there
    exists $x \in X$ such that $z = g(f(x))$. For the sake of
    contradiction, suppose that $g$ is not surjective: then, there
    exists $z \in Z$ such that for all $y \in Y$, $z \neq g(y)$. In
    particular, for all $x \in X$, since $f(x) \in Y$, we would have
    $g(f(x)) \neq z$, which would be a contradiction with $g \circ f$
    surjective.

    However, $f$ does not need to be surjective. For instance, let's
    consider $X = Y = \{1,2\}$ and $Z = \{1\}$. Let $f$ be the mapping
    $f(1) = f(2) = 1$, and $g$ be the mapping $g(1) = g(2) = 1$. Here,
    $g \circ f$ is surjective, but $f$ is not.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.6}{Let $f : X \rightarrow Y$ be a bijective function,
    and let $\inv{f} : Y \rightarrow X$ be its inverse. Verify the
    cancellation laws $\inv{f}(f(x)) = x$ for all $x \in X$ and
    $f(\inv{f}(y)) = y$ for all $y \in Y$. Conclude that $\inv{f}$ is
    also invertible and has $f$ as its inverse.}

  Recall that, by definition, for all $y \in Y$, $\inv{f}(y)$ is the only element
  $x \in X$ such that $f(x) = y$.
  \begin{enumerate}
  \item Let $a$ be an element of $X$, we thus have $f(a) \in Y$. Let's
    apply the definition to the element $y = f(a) \in Y$: by
    definition, $\inv{f}(f(a))$ is the only element $x \in X$ such
    that $f(x) = f(a)$. Since $f$ is bijective, this implies $x =
    a$. We thus have proved that $\inv{f}(f(a)) = a$.
  \item The proof for $f(\inv{f}(y)) = y$ is similar.
  \item To prove that $\inv{f}$ is also invertible, we need to prove
    that $\inv{f}$ is bijective, i.e. injective and surjective.

    For any given $y \in Y$, since $f$ is bijective, there exists exactly
    one $x \in X$ such that $y = f(x)$. Similarly, for any given $y'
    \in Y$, there exists exactly one $x' \in X$ such that $y' =
    f(x')$. In other words, $\inv{f}(y) = x$ and $\inv{f}(y') =
    x'$. Suppose that $\inv{f}(y) = \inv{f}(y')$. This can be written
    $x = x'$, which necessarily implies $f(x) = f(x')$ since $f$ is a
    function (and by axiom of substitution). And this can also be
    written $y = y'$. We thus have proved that for any $y, y' \in Y$,
    $\inv{f}(y) = \inv{f}(y') \Longrightarrow y = y'$. Thus, $\inv{f}$
    is injective.

    Furthermore, for any given $x \in X$, let's denote $y =
    f(x)$. Since $f$ is bijective, this means that $\inv{f}(y) =
    x$. Thus, any $x \in X$ has a predecessor $y \in Y$ for $\inv{f}$,
    i.e.  $\inv{f}$ is surjective.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.7}{Let $f : X \rightarrow Y$ and $g : Y \rightarrow Z$
    be functions. Show that if $f$ and $g$ are bijective, then so is $g
    \circ f$, and we have $\inv{(g \circ f)} = \inv{f} \circ \inv{g}$.}

  The first point is an immediate consequence of Exercise 3.3.2. We just
  have to show that $\inv{(g \circ f)} = \inv{f} \circ \inv{g}$.

  Let be any given element $z \in Z$. Since $g$ is bijective, there
  exists one single element $y \in Y$ such that $z = g(y)$, i.e.
  $y = \inv{g}(z)$. And since $f$ is also bijective, there exists
  exactly one single element $x \in X$ such that $y = f(x)$, i.e. $x =
  \inv{f}(y) = \inv{f}(\inv{g}(z))$.

  Thus, for every $z \in Z$, there exists exactly one $x \in X$ such
  that $g \circ f(x) = z$, and this element is
  $\inv{f}(\inv{g}(z))$. This means exactly that $\inv{(g \circ f)} =
  \inv{f} \circ \inv{g}$.
\end{exo}

\bigskip

\begin{exo}{3.4.1}{Let $f : X \rightarrow Y$ be a bijective function,
    and let $\inv{f} : Y \rightarrow X$ be its inverse. Let $V$ be any
    subset of $Y$. Prove that the forward image of $V$ under $\inv{f}$
    is the same as the inverse image of $V$ under $f$; thus the fact
    that both sets are denoted as $\inv{f}$ will not lead to any
    inconsistency.}

  Since ``$\inv{f}(V)$'' may refer to two different things here, let's
  first introduce some notations to avoid any confusion :
  \begin{itemize}
  \item Let $F$ be the \emph{forward image} of $V$ under $\inv{f}$,
    i.e. $F = \{\inv{f}(y) \; | \; y \in V\}$.
  \item Let $I$ be the \emph{inverse image} of $V$ under $f$, i.e.
    $I = \{x \in X \; | \; f(x) \in V\}$.
  \end{itemize}

  In this exercise we must show that $F = I$, so as to ensure that the
  two definitions of $\inv{f}$ are equivalent. So, we will prove that
  $F \subseteq I$ and $I \subseteq F$.

  \begin{enumerate}
  \item Let be $x \in F$. Thus, there exists $y \in V$ such that
    $x = \inv{f}(y)$. By definition, this is equivalent to $f(x) =
    y$. But since $y \in V$, we can say that $f(x) \in V$. Thus, we
    have both $x \in X$ (beacuse $F \subseteq X$) and $f(x) \in V$,
    which means that $x \in I$.
  \item Conversely, let be $x \in I$. By definition, this means that
    $x \in X$ and that $f(x) \in V$, i.e. there exists a certain
    element $y \in V$ such that $y = f(x) \in V$. This latter
    statement is equivalent to $x = \inv{f}(y)$. Thus, we have $x \in
    X$ and $x = \inv{f}(y)$ for a certain $y \in V$, which means that
    $x \in F$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.2}{Let $f : X \rightarrow Y$ be a function, let $S$ be
    a subset of $X$ and let $U$ be a subset of $Y$. What, in general,
    can one say about $\inv{f}(f(S))$ and $S$? What about
    $f(\inv{f}(U))$ and $U$?}
  
  This exercise gives a first taste of Exercise 3.4.5 below.

  \begin{enumerate}
  \item First consider $\inv{f}(f(S))$ and $S$.
    \begin{itemize}
    \item Do we have $\inv{f}(f(S)) \subset S$? Generally, no. As an
      counterexample, let's consider $f(x) = x^2$ with $X = Y =
      \rr$ and $S = \{0,2\}$. We have $\inv{f}(f(S)) =
      \inv{f}(\{0,4\}) = \{-2, 0, 2\}$. In this set, we have an
      element, $-2$, which is not an element of $S$.
    \item Do we have $S \subset \inv{f}(f(S))$? Yes. Let be $x \in
      S$. Then, by definition, $f(x) \in f(S)$. So, $x \in X$ and is
      such that $f(x) \in f(S)$: this is precisely the definition of
      $x \in \inv{f}(f(S))$.
    \item Conclusion: generally speaking, $S$ and $\inv{f}(f(S))$ are
      not equal, but $S \subset \inv{f}(f(S))$.
    \end{itemize}
  \item Now consider $f(\inv{f}(U))$ and $U$.
    \begin{itemize}
    \item Do we have $U \subset f(\inv{f}(U))$? Generally, no. As a
      counterexample, let's consider $f(x) = \sqrt{x}$ with $X =
      \rr_+$, $Y = \rr$ and $U = [-1,1]$. We have $f(\inv{f}(U)) =
      f([0,1]) = [0,1]$, which is clearly not a subset of $U$.
    \item Do we have $f(\inv{f}(U)) \subset U$ ? Yes. Let be $y \in
      f(\inv{f}(U))$. By definition, there exists $x \in \inv{f}(U)$
      such that $y = f(x)$. But if $x \in \inv{f}(U)$, we have
      $f(x)\in U$. And since $y = f(x)$, this means that $y \in U$.
    \item Conclusion: generally speaking, $U \neq f(\inv{f}(U))$,
      but $f(\inv{f}(U)) \subset U$.
    \end{itemize}
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.3}{Let $A, B$ be two subsets of $X$, and let be $f : X
    \rightarrow Y$. Show that $f(A \cap B) \subseteq f(A) \cap f(B)$,
    that $f(A) \backslash f(B) \subseteq f(A \backslash B)$, and $f(A
    \cup B) = f(A) \cup f(B)$. Is it true that, for the first two
    statements, the $\subseteq$ relation can be improved to $=$?}
  
  Let's prove the three statements successively:
  \begin{enumerate}
  \item If $y \in f(A \cap B)$, then there exists $x \in A \cap B$
    such that $f(x) = y$. Since $x \in A \cap B$, we have both $x \in
    A$ and $x \in B$, which implies $y = f(x) \in f(A)$ and $y = f(x)
    \in B$ respectively. Thus, $y \in f(A) \cap f(B)$, and we have
    proved that $f(A \cap B) \subseteq f(A) \cap f(B)$.

    However, the converse inclusion is false in general. For instance,
    let's consider the two sets $A = \{1,2\}$, $B = \{2,3\}$ and the
    (non injective) function $f$ defined as the mapping $f(1) = 1$,
    $f(2) = 2$, $f(3) = 1$. We have $f(A) = \{1,2\}$,
    $f(B) = \{1,2\}$, thus $f(A) \cap f(B) = \{1,2\}$. This is not a
    subset of $f(A \cap B) = f(\{2\}) = \{2\}$.
  \item If $y \in f(A) \backslash f(B)$, then there exists $x_0 \in A$
    such that $y = f(x_0)$, but we have $f(b) \neq y$ for all
    $b \in B$. Suppose that $x_0 \in B$: in this case,
    $f(x_0) \neq y$, a contradiction. Thus, $y = f(x_0)$ with
    $x_0 \in A \backslash B$, which proves that
    $f(A) \backslash f(B) \subseteq f(A \backslash B)$.

    However, the converse inclusion is false in general. For instance,
    let's consider the two sets $A = \{1,2,3\}$, $B = \{3\}$ and the
    function $f$ defined as the mapping $f(1) = 1$, $f(2) = 2$,
    $f(3) = 1$. We have $f(A \backslash B) = \{1,2\}$ but
    $f(A) \backslash f(B) = \{2\}$.
  \item If $y \in f(A \cup B)$, then there exists $x \in A \cup B$
    such that $y = f(x)$. If $x \in A$, then $f(x) \in f(A)$, which
    implies $x \in f(A) \cup f(B)$. There is an identical result if $x
    \in B$. Thus, $f(A\cup B) \subseteq f(A) \cup f(B)$.

    Conversely, if $y \in f(A) \cup f(B)$, then we have either $y \in
    f(A)$ or $y \in f(B)$ (or both). In the first case, there exists
    $x \in A$ such that $y = f(x)$. But since $x \in A$, we also have
    $x \in A\cup B$, so that $y \in f(A \cup B)$. The same result
    holds if $y \in B$. Thus, in both cases, $y \in f(A \cup B)$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.4}{Let be $f : X \rightarrow Y$ a function, and let
    $A, B$ be subsets of $Y$. Show that
    $\inv{f}(A \cup B) = \inv{f}(A) \cup \inv{f}(B)$, that
    $\inv{f}(A \cap B) = \inv{f}(A) \cap \inv{f}(B)$, and that
    $\inv{f}(A \backslash B) = \inv{f}(A) \backslash \inv{f}(B)$.}
  
  We prove only the first statement here; since only very small
  adjustments are required in its proof to prove the last two ones.

  \begin{itemize}
  \item Let be $x \in \inv{f}(A \cup B)$. By definition, $f(x) \in A \cup
    B$, so that we have either $f(x) \in A$ or $f(x) \in B$.

    If $f(x) \in A$, then $x \in \inv{f}(A)$ by definition. This
    implies that $x \in \inv{f}(A) \cup \inv{f}(B)$.

    The same conclusion holds if $f(x) \in B$. Thus, we have
    demonstrated that
    $\inv{f}(A \cup B) \subseteq \inv{f}(A) \cup \inv{f}(B)$.

  \item For the conserve inclusion, let be $x \in \inv{f}(A) \cup
  \inv{f}(B)$. We have either $x \in \inf{f}(A)$ or $x \in
  \inv{f}(B)$.

  If $x \in \inv{f}(A)$, then $f(x) \in A$, and since
  $A \subset A \cup B$, we have $f(x) \in A \cup B$. This implies
  $x \in \inv{f}(A \cup B)$.

  The same conclusion holds if $x \in \inv{f}(B)$. Thus,
  $\inv{f}(A) \cup \inv{f}(B) \subseteq \inv{f}(A \cup B)$.

  \item This proves the equality $\inv{f}(A \cup B) = \inv{f}(A) \cup
    \inv{f}(B)$.
  \end{itemize}
\end{exo}

\begin{exo}{3.4.5}{Let $f : X \rightarrow Y$ be a function. Show that
    $\inv{f}(f(S)) = S$ for every $S \subseteq Y$ iff $f$ is
    surjective. Show that $f(\inv{f}(S)) = S$ for every $S \subseteq
    X$ iff $f$ is injective.}

  This exercise is a continuation of Exercise 3.4.2. Let's recall its
  results, that will reduce the amount of things to be proven here:
  \begin{itemize}
  \item we always have $\inv{f}(f(S)) \subseteq S$ for every
    $S \subseteq Y$, thus we just have to prove that $f$ is
    surjective iff $S \subseteq \inv{f}(f(S))$ for every
    $S \subseteq Y$.
  \item we always have $S \subseteq f(\inv{f}(S))$ for every
    $S \subseteq X$, thus we just have to prove that $f$ is
    injective iff then $f(\inv{f}(S)) \subseteq S$ for every
    $S \subseteq X$.
  \end{itemize}

  Let's prove those two statements.
  \begin{enumerate}
  \item Let $f$ be surjective: let's show that
    $S \subseteq f(\inv{f}(S))$ for all $S \subseteq Y$. Let $S$ be a
    subset of $Y$, and $y \in S$\footnote{If $S$ is empty, the
      statement is vacuously true, so that we can suppose
      $S \neq \emptyset$.}. Since $f$ is surjective, there exists
    $x \in X$ such that $y = f(x)$. Recall that $y \in S$: this means
    that$f(x) \in S$, i.e. $x \in \inv{f}(S)$. Thus,
    $y = f(x) \in f(\inv{f}(S))$. We have proved that, if $f$ is
    surjective, $y \in S \Rightarrow y \in f(\inv{f}(S))$, i.e.
    $S \subseteq f(\inv{f}(S))$.

    Conversely, suppose that $S \subseteq f(\inv{f}(S))$ for every
    $S \subseteq Y$ and let's show that $f$ is surjective. Let's
    choose $S = Y$: by hypothesis, we have
    $Y \subseteq f(\inv{f}(Y))$. Then, let be $y \in Y$. There exists
    $x \in \inv{f}(Y) \subseteq X$ such that $y = f(x)$. This means
    precisely that $f$ is surjective.

    The first equivalence is proved.

  \item Let $f$ be injective, and $S \subseteq X$. Let be
    $x \in \inv{f}(f(S))$. Thus, by definition, $f(x) \in f(S)$. This
    means that there exists $x' \in f(S)$ such that $f(x) =
    f(x')$. And since $f$ is injective, $x = x' \in S$. Thus, if $f$
    is injective, $\inv{f}(f(S)) \subseteq S$ for every
    $S \subseteq X$.

    Conversely, suppose that $\inv{f}(f(S)) \subseteq S$ for every
    $S \subseteq X$. In particular, this is true for any singleton
    $S = \{x_0\}$, with $x_0 \in S$. In such a case, we obtain
    $\inv{f}(f(\{x_0\})) = \{x_0\}$. For any element $x \in X$, if
    $x \neq x_0$, we have $x \notin \{x_0\}$ by definition of a
    singleton, thus $x \notin \inv{f}(f(\{x_0\}))$, and thus
    $f(x) \neq f(x_0)$. This means that $f$ is injective.

    The second equivalence is proved.    
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.6}{Prove lemma 3.4.9. (Hint: start with the set
    $\{0,1\}^X$ and apply the replacement axiom, replacing each
    function $f$ with the object $f^{-1}(\{1\})$.)}

  First, let's recall the main propositions involved in this exercise:

  \begin{itemize}
  \item \textbf{Replacement axiom}. Let $A$ be a set. For any object
    $x \in A$, and any object $y$, suppose we have a statement
    $P(x,y)$ pertaining to $x$ and $y$, such that for each $x \in A$
    there is at most one $y$ for which $P(x,y)$ is true. Then there
    exists a set
    $\{y \; | \; P(x,y) \text{ is true for some } x \in A\}$, such
    that for any object $z$,
    \[ z \in \{y \; | \; P(x,y) \text{ is true for some } x \in A\}
      \Longleftrightarrow P(x,z) \text{ is true for some } x \in A\]

\item \textbf{Power set axiom}. Let $X$ and $Y$ be sets. There there
  exists a set, denoted $Y^X$, which consists of all the function from
  $X$ to $Y$:
  \[f \in Y^X \Longleftrightarrow (f \text{ is a function from $X$ to
      $Y$}\}\]

\item \textbf{Lemma 3.4.9}. Let $X$ be a set. Then the set
  $\{Y \; | \; Y \text{ is a subset of X}\}$ is a set.
  \end{itemize}

  The aim is to prove this lemma using the two axioms recalled here.

  \begin{enumerate}
  \item Let $X$ be a set, and $Y = \{0,1\}$. Per the power set axiom,
    $\{0,1\}^X$ is a set, and it contains all the functions
    $f : X \rightarrow \{0,1\}$.
  \item Let $A$ be a subset of $X$. One can define the function
    $f_A : X \rightarrow \{0,1\}$, such that for all $x \in X$,
    $f(x) = 1$ if $x \in A$, and $f(x)=0$ otherwise. We can even say
    more:
    \begin{itemize}
    \item If $A$ is a subset of $X$, then there exists an element
      $f \in \{0,1\}^X$ such that $A = f^{-1}(\{1\})$: this is
      precisely $f_A$ as defined above.
    \item Conversely, if $f \in \{0,1\}^X$, then $A = f^{-1}(\{1\})$
      is by definition a subset of $X$.
    \end{itemize}
    Thus, the two statements ``$A$ is a subset of $X$'' and ``there
    exists $f \in \{0,1\}^X$ such that $A = f^{-1}(\{1\})$'' are
    equivalent.
  \item Finally, let be $A \subset X$ and $f \in \{0,1\}^X$. Let's
    define $P(f,A)$ the statement ``$A = f^{-1}(\{1\})$''. For each
    $f$, there is at most one $A$ (in fact, \emph{exactly} one $A$)
    such that $P(f,A)$ is true. Thus, per the axiom of replacement,
    there exists a set:
    \[\mathcal{P} = \{A \; | \; A = f^{-1}(\{1\}) \text{ for some } f \in \{0,1\}^X\}\]
    And, thanks to the equivalence demonstrated in 2.:
    \[ \mathcal{P} = \{A \; | \; A \text{ is a subset of } X\} \]
    is a well-defined set, which we wanted to prove.
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.7}{Let $X, Y$ be sets. Define a partial function
    from $X$ to $Y$ to be any function $f: X' \rightarrow Y'$ with
    $X' \subseteq X$ and $Y'\subseteq Y$. Show that the collection of
    all partial functions from $X$ to $Y$ is itself a set.}
  \begin{itemize}
   \item Let be $X' \subseteq X$ and $Y' \subseteq Y$. If both $X'$
     and $Y'$ are fixed, then per the power set axiom (3.10), there
     exists a set $Y'^{X'}$ which consists of all the functions from
     $X'$ to $Y'$.
   \item By lemma 3.4.9, there exist a set $2^X$ which consists of all
     the subsets of $X$, and a set $2^Y$ which consists of all the
     subsets of $Y$.
   \item Now we \emph{fix} an element $X'$ of $2^X$. Let be $Y'$ an
     element of the set $2^Y$, $A$ a set, and $P$ the property
     ``$P(Y', A)$: $A = Y'^{X'}$''. Per the replacement axiom, there
     exists exactly one (and thus, at most one) set:
     \begin{align*}
       \{A \, | \, P(Y', A) \text{ is true for some } Y' \in 2^Y\}
       &= \{A \, | \, A = Y'^{X'} \text{ for some } Y' \in 2^Y\}\\
       &= \{Y'^{X'} \, | \, Y' \in 2^Y\}
     \end{align*}
   \item Each element of this set is itself a set. Thus we can apply
     the axiom of union (3.11): there exists a set
     $\bigcup \{Y'^{X'} \, | \, Y' \in 2^Y\}$ whose elements are those
     objects which are elements of elements of
     $\{Y'^{X'} \, | \, Y' \in 2^Y\}$, i.e.:

     \[ \bigcup \{Y'^{X'} \, | \, Y' \in 2^Y\} = \{f | f:X'
       \rightarrow Y' \text{ for some } Y' \in 2^Y\}\]

     This set is obtained for one given \emph{fixed} subset
     $X' \subseteq X$, so let's denote this set:
     \[S_{X'} = \{f | f:X' \rightarrow Y' \text{ for some } Y' \in
       2^Y\}\]
   \item Now we apply once again the union set (3.11), especially in
     its second formulation. If we denote $I = 2^X$, then for each
     element $X' \in I$ we do have one set $S_{X'}$, which is defined
     above. Thus, there exists a set
     $\bigcup_{X' \in 2^X} S_{X'} := \bigcup \{S_{X'} \, | \, X' \in
     2^X\}$. And, for every function $f$, we have
     $f \in \bigcup \{S_{X'} \, | \, X' \in 2^X\}$ iff there exists
     $X' \in 2^X$ such that $f \in S_{X'}$, i.e. if there exists
     $X' \subset X$ and $Y' \subset Y$ such that
     $f: X' \rightarrow Y'$.
   \item Consequently, we have proved that there exists a set which
     consists of the collection of all partial functions from $X$ to
     $Y$.
\end{itemize}
\end{exo}

\begin{exo}{3.4.8}{Prove that Axiom 3.4 can be deduced from Axiom 3.1,
  Axiom 3.3 and Axiom 3.11.}

Let's recall very briefly the four axioms involved here :
\begin{itemize}
  \item Axiom 3.4 (to be proved) says that if $A$ and $B$ are sets,
    then there exists a union set $A \cup B$ such that $x \in A \cup
    B$ iff $x \in A$ or $x \in B$.
\item Axiom 3.1 essentially says that sets are objects.
\item Axiom 3.3 says that singletons are pair sets do exist.
\item Axiom 3.11: let $A$ be a set, whose all elements are themselves
  sets. Then there exists a set $\bigcup A$ whose elements are those
  objects which are elements of elements of $A$, i.e., $x \in \bigcup
  A$ iff $x \in S$ for some $S \in A$.
\end{itemize}
\end{exo}

Here is a sketch of proof for Axiom 3.4. Let $A$ and $B$ be
sets. According to Axiom 3.1, $A$ and $B$ are themselves objects: they
can be elements of other sets. Consequently, according to Axiom 3.3,
it makes sense to talk about the singleton sets $\{A\}$ and $\{B\}$,
and the set $\{A, B\}$.

Now we consider this latter set, which we denote $\mathcal{A} = \{A,
B\}$. According to axiom 3.11, there exists a set $\bigcup
\mathcal{A}$ whose elements those objects which are the elements of
$\mathcal{A}$, i.e., $x \in \mathcal{A}$ iff there exists $S \in
\mathcal{A}$ such that $x \in S$. But $\mathcal{A}$ is a pair set with
only two elements, so that $S$ must necessarily be equal to $A$ or
$B$.

This leads to the following conclusion: if $A$ and $B$ are sets, then
there exists a set $\mathcal{A}$ such that $x \in \mathcal{A}$ iff
$x \in A$ or $x \in B$. This is precisely the Axiom 3.4.

\bigskip
\begin{exo}{3.5.1}{Suppose we define the ordered pair $(x,y)$  for any
    objects $x$ and $y$ by the formula $(x,y) := \{\{x\},
    \{x,y\}\}$. Show that  this definition obeys the property (3.5), and
    also whenever $X$ and $Y$ are sets, the cartesian product $X \times
    Y$ is also a set.}

  Recall that property (3.5) says that $(x,y) = (x',y')$ iff $x=x'$
  and $y=y'$. The proof below is heavily inspired by the sketch given
  by Paul Halmos in his famous book, \textit{Naive Set Theory}. (The
  proof below is just immensely more verbose.)

  \begin{enumerate}
  \item First, we go back to Remark 3.1.9 by Terence Tao (page
    37). In this remark, Tao says that for any object $a$, the pair
    set $\{a, a\}$ is in fact the singleton $\{a\}$. Tao asks
    \textit{why?} to the reader. This is easy to prove using the
    Definition 3.1.4 (equality of sets): both sets have the same
    elements, thus they are equal. This fact is a crucial point for
    the current proof.

    Indeed, first note that for any object $x$, the ordered pair
    $(x,x)$ will be (by definition) equal to $\{\{x\},
    \{x,x\}\}$. Applying twice the Remark 3.1.9 made by Terence Tao,
    we can conclude that $(x,x) = \{\{x\}\}$ for any object $x$.
    
    Conversely, if any ordered pair $(x,y)$ is a singleton, this means
    that $\{\{x\}, \{x,y\}\}$ is a singleton. This implies that both
    elements of this pair set are equal, i.e. $\{x\} = \{x,y\}$. Thus,
    (by Definition 3.1.4,) $y \in \{x\}$, i.e. $x=y$.
    
    This gives a handy conclusion, that we can write as a lemma:
    \begin{lem} An ordered pair $(x,y)$ is a singleton if and only
      if $x=y$ (and in this case, this singleton is $\{\{x\}\} =
      \{\{y\}\}$).
    \end{lem}
    We can now prove more easily that property (3.5) is met.
  \item Let's prove that the property (3.5) is satisfied.
    \begin{itemize}
    \item First, let be two ordered pairs $(a,b) = \{\{a\}, \{a,b\}\}$
      and $(x,y) = \{\{x\}, \{x,y\}\}$. If $a=x$ and $y=b$, then we
      obviously have $\{\{a\}, \{a,b\}\} = \{\{x\}, \{x,y\}\}$.
    \item For the reciprocal, suppose that $(a,b) = (x,y)$, and let's
      show that $a=x$ and $b=y$. We will consider two distinct cases.
      \begin{enumerate}[label=\emph{(\alph*)}]
      \item First consider the case where $a=b$ (note that this also
        covers the case $x=y$, since they play symmetrical
        roles). Thus $(a,b) = \{\{a\}\}$. Since $(a,b) = (x,y)$, we have
        $\{\{x\},\{x,y\}\} = \{\{a\}\}$.

        This means that $\{x\} \in \{\{a\}\}$, i.e. $a=x$.

        But we also have $\{x,y\} \in \{\{a\}\}$, i.e. $\{x,y\} =
        \{a\}$. This means in particular that $\{x,y\}$ is a
        singleton, which is only possible if $x=y$ according to the
        lemma introduced above.

        Thus, $a=b$ by hypothesis, and $a=x$, and $x=y$. This finally
        means that all four elements are equal: $a=b=x=y$.

        We can insist: if we have either $a=b$ or $x=y$, then all four
        elements are equal, and property (3.5) is met.
        
      \item The other case is $a \neq b$ (which also implies $x \neq
        y$, otherwise all four elements would be equal). Since $(a,b)
        = (x,y)$, we have $\{a\} \in \{\{x\}, \{x,y\}\}$, so that we
        have either $\{a\} = \{x\}$ or $\{a\} = \{x,y\}$. The latter
        case can be excluded: $\{a\} = \{x,y\}$ would mean that
        $\{x,y\}$ is a singleton, thus $x=y$, a contradiction with our
        hypothesis. Thus, the only possibility is $\{a\} = \{x\}$,
        i.e. $a=x$.

        We also have $\{a,b\} \in \{\{x\}, \{x,y\}\}$, and for the
        same reason, the only possibility is $\{a,b\} = \{x,y\}$. But
        we have showed that $a=x$, so that $\{a,b\} = \{a,y\}$. The
        conclusion is $y=b$.
      \end{enumerate}
        
      \item Conclusion: in both cases, $(a,b)$ implies both $a=x$ and $y=b$,
      which is our initial goal. Property (3.5) is met.
    \end{itemize}
  \item Finally, if we adopt this definition, $X \times Y$ is a
    set. Indeed, for every $x\in X$ and $y \in Y$, both $x$ and $y$
    are elements of $X \cup Y$. Thus, the singleton $\{x\}$ and the
    pair set $\{x,y\}$ are elements of the power set of $X \cup Y$
    (which is indeed a set, by Lemma 3.4.9: see Exercise 3.4.6). In
    other words, if $\partsof{A}$ denotes the power set of a set $A$,
    we have $\{x\} \in \partsof{X \cup Y}$ and
    $\{x,y\} \in \partsof{X \cup Y}$.

    Thus, for every objects $x \in X$ and $y \in Y$,
    $\{\{x\}, \{x,y\}\} \subset \partsof{X \cup Y}$. This latter
    statement is equivalent to $\{\{x\}, \{x,y\}\} \in
    \partsof{\partsof{X \cup Y}}$, which is also a well-defined set by
    a (recursive) application of Lemma 3.4.9.

    Then, for any element $S \in \partsof{\partsof{X \cup Y}}$, let
    $P(S)$ be the property ``There exists $x \in X$ and $y \in Y$ such
    that $S = \{\{x\}, \{x,y\}\}$''. By the axiom of specification
    (Axiom 3.5), there exists a set $\{S \in \partsof{\partsof{X \cup
        Y}} \, | \, P(S) \text{ is true}\}$: this set is precisely the
    cartesian product $X \times Y$ we were looking for.
  \end{enumerate}
\end{exo}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
