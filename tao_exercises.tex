\documentclass[11pt]{article}
\title{Propositions of solutions for \textit{Analysis I} by Terence Tao}
\author{Frédéric Santos}
% General packages:
\usepackage{a4wide}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc}
\usepackage{titlesec}
\titlelabel{\thetitle.\quad}
\usepackage{enumitem}
% Fonts and math packages:
\usepackage{lmodern}
\usepackage{amsmath}
\numberwithin{equation}{section}
\usepackage[matha,mathb]{mathabx}
\usepackage{mbboard}
\usepackage{stmaryrd}
\usepackage{hyperref}
% Macros:
\newcommand{\successor}[1]{#1 \! +\!\!\!+}
\newcommand{\aval}[1]{\left\lvert #1 \right\rvert}
\newcommand{\intset}[2]{\llbracket #1, #2 \rrbracket}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\rr}{\mathbb{R}}
\newcommand{\partsof}[1]{\mathcal{P}\left( #1 \right)}
\newcommand{\minus}{\, \textrm{---}\!\textrm{--} \:}
\newcommand{\quot}{\, \textrm{/}\!\textrm{/} \:}
\newcommand{\nn}{\mathbb{N}}
\newcommand{\zz}{\mathbb{Z}}
\newcommand{\qq}{\mathbb{Q}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\formallimit}[1]{\text{LIM}_{n \to \infty} #1}
\newcommand{\seq}[2]{(#1)_{n=#2}^\infty}
\newcommand{\limit}[1]{\text{lim}_{n \to \infty} #1}
\newcommand{\extrr}{\overline{\rr}}
\newcommand{\adh}[1]{\overline{#1}}
\newcommand{\liminfp}[2]{\inf (#1^+_N)_{N=#2}^{\infty}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\renewcommand{\epsilon}{\varepsilon}
% Lemmas:
\usepackage{amsthm}
\newtheorem*{lem}{Lemma}
% Environment:
\newenvironment{exo}[2]{\noindent \textsc{Exercise #1}. ---
  \textit{#2} \vspace{3mm}}

%%%%%%%%%%%%%%
%%% Begin doc:
\begin{document}
\maketitle
\tableofcontents

\pagebreak
\section{Introduction}
\label{sec:introduction}
No exercises in this chapter.

\pagebreak
\section{Starting at the beginning: the natural numbers}
\label{sec:natural-numbers}

\begin{exo}{2.2.1}{Prove that the addition is associative, i.e. that
    for any natural numbers $a, b, c$, we have $(a+b) + c = a + (b+c)$.}

  Let's use induction on $c$ while keeping $a$ and $b$ fixed.
  
  \begin{itemize}
  \item Base case for $c=0$: let's prove that $(a+b)+0 = a+(b+0)$. The
    left hand side is equal to $(a+b)$ according to Lemma 2.2.3. For the
    right hand side, if we apply the same lemma to the $(b+0)$ part,
    we get $a + (b+0) = a+b$. Both sides are equal to $a+b$, and the
    base case is thus done.
  \item Now let's suppose inductively that $(a+b) + c = a + (b+c)$: we
    have to prove that $(a+b) + \successor{c} = a + (b +
    \successor{c})$. Using Lemma 2.2.3 on the right
    hand side leads to $a + \successor{(b+c)}$. Now consider the left
    hand side. Using still the same lemma, we get $(a+b) +
    \successor{c} = \successor{\left((a+b) + c\right)}$. By the
    inductive hypothesis, this is also equal to
    $\successor{\left(a + (b+c)\right)}$. And, using the lemma 2.2.3
    again, this also leads to $a + \successor{b+c}$. Therefore, both
    sides are equal to $a + \successor{b+c}$, and we have closed the
    induction.
  \end{itemize}
\end{exo}

\begin{exo}{2.2.2}{Let $a$ be a positive number. Prove that there
    exists exactly one natural number $b$ such that $\successor{b} =
    a$.}
  
  Let's use induction on $a$.

  \begin{itemize}
  \item Base case for $a=1$: we know that $b=0$ matches this property,
    since $\successor{0} = 1$ by Definition 2.1.3. Furthermore, there
    is only one solution. Suppose that is another natural number $b$
    such that $\successor{b} = 1$. Then, we would have
    $\successor{b} = \successor{0}$, which would imply $b = 0$ by
    Axiom 2.4. The base case is demonstrated.
  \item Let's suppose inductively that there is exactly one natural
    number $b$ such that $\successor{b} = a$. We have to prove that
    there is exactly one natural number $b'$ such that
    $\successor{b'} = \successor{a}$. By the induction hypothesis, and
    taking $b' = \successor{b}$, we have
    $\successor{b'} = \successor{(\successor{b})} = \successor{a}$. So
    there exists a solution, with $b' = \successor{b} = a$. Uniqueness is
    given by Axiom 2.4.: if $\successor{b'} = \successor{a}$, then we
    necessarily have $b'=a$.
  \end{itemize}
\end{exo}

\begin{exo}{2.2.3}{Let $a, b, c$ be natural numbers. Prove the
    following properties of order for natural numbers:}
  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Reflexivity: $a \geq a$. This is true since $a = 0 + a$ by
    Definition 2.2.1. By commutativity of addition, we can also write
    $a = a + 0$. So there is indeed a natural number $n$ (with
    $n=0$) such that $a = a + n$, i.e. $a \geq a$.
  \item Transitivity: if $a \geq b$ and $b \geq c$, then $a \geq
    c$. From the part $a \geq b$, there exists a natural number $n$
    such that $a = b + n$ according to Definition 2.2.11. A similar
    consideration for the part $b \geq c$ leads to $b = c + m$, $m$
    being a natural number. Combining together those two equalities,
    we can write $a = b + n = (c + m) + n = c + (m + n)$ by
    associativity (see Exercise 2.2.1). Then, $n+m$ being a natural
    number\footnote{This is a trivial induction from the definition of
      addition.}, the transitivity is demonstrated.
  \item Anti-symmetry: if $a \geq b$ and $b \geq a$, then $a=b$. From
    the part $a \geq b$, there exists a natural number $n$ such that $a
    = b + n$. Similarly, there exists a natural number $m$ such that $b
    = a + m$. Combining those two equalities leads to $a = b + n = (a +
    m) + n = a + (m + n)$. By cancellation law (Proposition 2.2.6), we
    can conclude that $0 = m + n$. According to Corollary 2.2.9, this
    leads to $m = n = 0$. Therefore, both $m$ and $n$ are null,
    meaning that $a = b + 0 = b$.
  \item Preservation of order: $a \geq b$ iff $a + c \geq b +
    c$. First, let's prove that
    $a+c \geq b+c \Longrightarrow a \geq b$. If $a+c \geq b+c$, there
    exists a natural number $n$ such that $a+c = b+c+n$. By
    cancellation law (Proposition 2.2.6)\footnote{And also
      associativity and commutativity that we do not detail explicitly
      here.}, we conclude that $a = b + n$, i.e. $a\geq b$, thus
    demonstrating the first implication. Conversely, let's suppose
    that $a \geq b$. There exists a natural number $m$ such that
    $a = b + m$. Therefore, $a + c = b+m+c$ for any natural number
    $c$. Still by associativity and commutativity, we can rewrite this
    as $a+c = (b+c) +m$, i.e. $a+c \geq b+c$.
  \item $a < b$ iff $\successor{a} \leq b$. First, let's prove that
    $\successor{a} \leq b \Longrightarrow a < b$. By definition of
    ordering, there exists a natural number $n$ such that
    $b = (\successor{a}) + n$. By definition of addition, we can
    re-write: $b = \successor{(\successor{a} + n)}$. Then, by
    commutativity and yet again by definition of addition,
    $b = \successor{(n + \successor{a})} = (\successor{n}) +
    (\successor{a})$. Thus, there exists a natural number
    $\successor{n}$ such that $b = \successor{n} + a$, which means that
    $b \geq a$. But we still have to prove that $a \neq b$. Let's
    suppose that $a=b$: in this case, by cancellation law, we would
    have $\successor{n} = 0$, which is impossible according to Axiom
    2.3 (0 is not the successor of any natural number). Thus, $a \neq
    b$ et $b \geq a$: we have showed that $a < b$. 

    Conversely, let's prove that
    $a < b \Longrightarrow \successor{a} \leq b$. Starting from that
    strict inequality, there exists a \textit{positive}\footnote{We
      make use here of the statement \textit{(f)} demonstrated
      below. There is no circularity here, since proving \textit{(f)}
      will not make use of \textit{(e)}.} natural number $n$ such that
    $b = a + n$. By Lemma 2.2.10, since $n$ is positive, it has one
    unique antecessor $m$, so that $n$ can be written
    $\successor{m}$. Thus,
    $b = a + (\successor{m}) = \successor{(a + m)} = \successor{(m +
      a)} = m + (\successor{a}) = (\successor{a}) + m$. And, $m$ being
    a natural number, this corresponds to the statement $b \geq a$.
  \item $a < b$ iff $b=a+d$ for some positive number $d$. First, let's
    prove the first implication, $a<b \Longrightarrow b=a+d$ with
    $d \neq 0$. Since $a<b$, we have in particular $a \leq b$, and
    there exists a natural number $d$ such that $b=a+d$. For the sake
    of contradiction, let's suppose that $d=0$. We would have $b=a$,
    which would contradict the condition $a\neq b$ of the strict
    inequality. Thus, $d$ is a positive number, which demonstrates the
    left-to-right implication.

    Conversely, let's suppose that $b = a+d$, with $d \neq 0$. This
    expression gives immediately $a \leq b$. But if $a=b$, by
    cancellation law, this would lead to $0=d$, a contradiction with
    the fact that $d$ is a positive number. Thus, $a\neq b$ and $a
    \leq b$, which demonstrates $a<b$.
  \end{enumerate}
\end{exo}

\begin{exo}{2.2.4}{Demonstrate three lemmas used to prove the
    trichotomy of order for natural numbers.}
  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Show that we have $0 \leq b$ for any natural number $b$. This is obvious
    since, by definition of addition, $0 + b = b$ for any natural
    number $b$. This is precisely the definition of $0 \leq b$.
  \item Show that if $a > b$, then $\successor{a} > b$. If $a > b$,
    then $a = b + d$, $d$ being a positive natural number. Let's
    recall that $\successor{a} = a + 1$. Thus, $\successor{a} = a + 1
    = b + d + 1 = b + (d+1)$ by associativity of
    addition. Furthermore, $d+1$ is a positive natural number (by
    Proposition 2.2.8). Thus, $\successor{a} > b$.
  \item Show that if $a=b$, then $\successor{a}>b$. Once again, let's
    use the fact that $\successor{a} = a+1$. Thus, $\successor{a} =
    a+1 = b+1$, and $1$ is a positive natural number. This is the
    definition of $\successor{a}>b$.
  \end{enumerate}
\end{exo}

\begin{exo}{2.2.5}{Prove the strong principle of induction, formulated
    as follows: Let $m_0$ be a natural number, and let $P(m)$ be a
    property pertaining to an arbitrary natural number $m$. Suppose
    that for each $m \geq m_0$, we have the following implication: if
    $P(m')$ is true for all natural numbers $m_0 \leq m' < m$, then
    $P(m)$ is also true. (In particular, this means that $P(m_0)$ is
    true, since in this case the hypothesis is vacuous.) Then we can
    conclude that $P(m)$ is true for all natural numbers
    $m \geq m_0$.}

  First let's introduce a small lemma (similar to Proposition
  2.2.12\textit{(e)}).

  \begin{lem}
    For any natural number $a$ and $b$, $a<\successor{b}$ iff $a\leq
    b$.
  \end{lem}
  \begin{proof}
    If $a < \successor{b}$, then $\successor{b} = a+n$ for a given
    positive natural $n$. By Lemma 2.2.10, there exists one natural
    number $m$ such as $n = \successor{m}$. Thus $\successor{b} = a +
    \successor{m}$, which can be rewritten $\successor{b} =
    \successor{(a+m)}$ by Lemma 2.2.3\footnote{We could also rewrite
      $b+1 = a + m + 1$ and then use the cancellation law.}. By Axiom
    2.4., this is equivalent to $b = a+n$, which can also be written
    $a \leq b$.
    
    Conversely, if $a \leq b$, there exists a natural number $m$
    such as $b = a+m$. Thus, $\successor{b} = \successor{(a+m)} =
    a + (\successor{m})$ by Definition of addition
    (2.2.1). And, $\successor{m}$ being a positive
    number, this means that $b > a$ according to Proposition
    2.2.12\textit{(f)}.
  \end{proof}

  Now we can prove the main proposition. Let $Q(n)$ be the property
  ``$P(m)$ is true for all $m$ such that $m_0 \leq m < n$''. Let's
  induct on $n$.

  \begin{itemize}
  \item (Although this is not necessary,) we could consider two types
    of base cases. If $n < m_0$, $Q(n)$ is the proposition ``$P(m)$ is
    true for all $m$ such that $m_0 \leq m < n$'', but there is no
    such natural number $m$. Thus, $Q(n)$ is vacuously true. If
    $n = m_0$, $P(m_0)$ is true by hypothesis, thus $Q(m_0)$ is also
    true.
  \item Now let's suppose inductively that $Q(n)$ is true, and show
    that $Q(\successor{n})$ is also true. If $Q(n)$ is true, $P(m)$ is
    true for all $m$ such that $m_0 \leq m < n$. By hypothesis, this
    implies that $P(n)$ is true. Thus, $P(m)$ is true for any natural
    number $m$ such that $m_0 \leq m \leq n$, i.e. such that $m_0 \leq
    m < \successor{n}$ according to the lemma introduced above. This
    is precisely $Q(\successor{n})$, and this closes the induction.
  \end{itemize}
  Thus, $Q(n)$ is true for all natural numbers $n$, which means in
  particular that $P(m)$ is true for any natural number $m \geq
  m_0$. This demonstrates the principle of strong induction.
\end{exo}

\bigskip
\begin{exo}{2.2.6}{Let $n$ be a natural number, and let $P(m)$ be a
    property pertaining to the natural numbers such that whenever
    $P(\successor{m})$ is true, then $P(m)$ is true. Suppose that
    $P(n)$ is also true. Prove that $P(m)$ is true for all natural
    numbers $m \leq n$; this is known as the \emph{principle of
      backwards induction}.}
  
  Terence Tao suggests to use induction on $n$. So let $Q(n)$ be the
  following property: ``if $P(n)$ is true, then $P(m)$ is true for all
  $m \leq n$. The goal is to prove $Q(n)$ for all natural numbers $n$.

  \begin{itemize}
  \item Base case $n = 0$: here, $Q(n)$ means that if $P(0)$ is true,
    then $P(m)$ is true for any $m \leq 0$. By Definition 2.2.11, if
    $m \leq 0$, there exists a natural number $d$ such that $0 = m +
    d$. But, by Corollary 2.2.9, this implies that both $m = 0$ and $d
    = 0$. Thus, the only number $m$ such that $m \leq 0$ is 0
    itself. Therefore, $Q(0)$ is simply the tautology ``if $P(0)$ is
    true, then $P(0)$ is true''--- a statement that we can safely
    accept. The base case is the, demonstrated.
  \item Let's suppose inductively that $Q(n)$ is true: we must show
    that $Q(\successor{n})$ is also true. If $P(\successor{n})$ is
    true, then by definition of $P$, $P(n)$ is also true. Then, by
    induction hypothesis, $P(m)$ is true for all $m \leq n$. We have
    showed that $P(\successor{n})$ implies $P(m)$ for all
    $m \leq \successor{n}$\footnote{Actually, we use here yet another
      lemma, similar to the one introduced for the previous
      exercise. We use the fact that $m \leq \successor{n}$ is
      equivalent to $m = \successor{n}$ or $m \leq n$, which is easy
      to prove, but is not part of the ``standard'' results presented
      in the textbook.}, which is precisely $Q(\successor{n})$. This
    closes the induction.
  \end{itemize}
\end{exo}

\begin{exo}{2.3.1}{Show that multiplication is commutative, i.e., if
    $n$ and $m$ are natural numbers, show that $n \times m = m \times
    n$.}

  We will use an induction of $n$ while keeping $m$ fixed. However,
  this is not a trivial result, and even the base case is not
  straightforward. We will first introduce some lemmas.

  \begin{lem}
    For any natural number $n$, $n \times 0 = 0$.
  \end{lem}

  \begin{proof}
    Let's induct on $n$.
    For the base case $n=0$, we know by Definition 2.3.1 of
    multiplication that $0 \times 0 = 0$, since $0 \times m = 0$ for
    any natural number $m$.

    Now let's suppose that $n \times 0 = 0$. Thus, $\successor{n}
    \times 0 = (n \times 0) + 0$ by Definition 2.3.1. But by induction
    hypothesis, $n \times 0 = 0$, so that $\successor{n} \times 0 = 0
    + 0 = 0$. This closes the induction.
  \end{proof}

  \begin{lem}
    For all natural numbers $m$ and $n$, we have $m \times \successor{n} = (m
    \times n) + m$.
  \end{lem}

  \begin{proof}
    Let's induct on $m$. The base case $m=0$ is easy to prove: $0
    \times \successor{n} = 0$ by Definition 2.3.1 of multiplication, and $(0
    \times n) + 0 = 0$.

    Now suppose inductively that
    $m \times \successor{n} = (m \times n) + m$, and we must show that
    \begin{equation}
      \label{eq:proof_lemma_231}
      \successor{m} \times \successor{n} = (\successor{m} \times n) +
      \successor{m}
    \end{equation}

    We begin by the left hand side: by Definition
    2.3.1,
    $\successor{m} \times \successor{n} = (m \times \successor{n}) +
    \successor{n}$. By induction hypothesis, this is equal to
    $(m \times n) + m + \successor{n}$.

    Then, apply the definition of multiplication to the right hand
    side:
    $(\successor{m} \times n) + \successor{m} = (m \times n) + n +
    \successor{m}$. The Lemma 2.2.3 and the commutativity of addition
    leads to
    $(m \times n) + n + \successor{m} = (m \times n) + \successor{(n +
      m)} = (m \times n) + \successor{(m + n)} = (m \times n) + m +
    \successor{n}$, which is equal to the left hand side.

    Thus, both sides of equation \eqref{eq:proof_lemma_231} are equal,
    and we can close the induction.
  \end{proof}
  
  Now it is easier to prove the main result ($n \times m = m \times
  n$), by an induction on $n$.

  \begin{itemize}
  \item Base case $n = 0$: we already know by Definition 2.3.1 that $0
    \times m = 0$. The first lemma introduced in this exercise also
    provides $m \times 0 = 0$. Thus, the base case is proved, since $0
    \times m = m \times 0 \; (= 0)$.
  \item Now we suppose inductively that $n \times m = m \times n$, and
    we must prove that:
    \begin{equation}
      \label{eq:recurr_commutativity_of_multiplication}
      \successor{n} \times m = m \times \successor{n}
    \end{equation}
    By Definition 2.3.1 of multiplication, the left hand side is equal
    to $(n \times m) + m$.

    Using the lemma introduced above, the right hand side is equal to
    $(m \times n) + m$. By induction hypothesis, this is also equal to
    $(n \times m) + m$, which closes the induction.
  \end{itemize}  
\end{exo}

\begin{exo}{2.3.2}{Show that positive natural numbers have no zero
    divisors, i.e. that $nm=0$ iff $n=0$ or $m=0$. In particular, if
    $n$ and $m$ are both positive, then $nm$ is also positive.}

  We will prove the second statement first. Suppose, for the sake of
  contradiction, that $nm = 0$ and that both $n$ and $m$ are positive
  numbers. Since they are positive, by Lemma 2.2.10, there exists two
  (unique) natural numbers $a$ and $b$ such that $n = \successor{a}$
  and $m = \successor{b}$. Thus, the hypothesis $nm=0$ can also be
  written $(\successor{a}) \times (\successor{b}) = 0$. But, by
  Definition 2.3.1  of multiplication, $(\successor{a}) \times
  (\successor{b}) = (a \times \successor{b}) + \successor{b}$. Thus,
  we should have $(a \times \successor{b}) + \successor{b} = 0$. By
  Corollary 2.2.9, this implies that both $(a \times \successor{b}) =
  0$ and $\successor{b} = 0$, which is impossible since zero is the
  successor of no natural number (Axiom 2.3).

  Thus, we have proved that if $n$ and $m$ are both positive, then
  $nm$ is also positive.  The main statement can now be proved more
  easily.

  \begin{itemize}
  \item The right-to-left implication is straightforward: if $n=0$,
    then by Definition of multiplication, $n \times m = 0 \times m =
    0$. Since multiplication is commutative, we have the same result
    if $m = 0$.
  \item The left-to-right implication is exactly the contrapositive of
    the statement we have just proved above.
  \end{itemize}
\end{exo}

\begin{exo}{2.3.3}{Show that multiplication is associative, i.e., for
    any natural numbers $a, b,c $, we have $(a\times b) \times c = a
    \times (b \times c)$.}

  We will induct on $c$ while keeping $a$ and $b$ fixed.

  \begin{itemize}
  \item Base case: for $c=0$, we must prove that $(a \times b) \times
    0 = a \times (b \times 0)$. The left hand side is equal to 0 by
    definition (and commutativity) of
    multiplication\footnote{Actually, we use the second lemma
      introduced for the resolution of Exercise 2.3.1.}. The right hand
    side is equal to $a0$, which is also 0. Both sides are null, and
    the base case is proved.
  \item Suppose inductively that
    $(a\times b) \times c = a \times (b \times c)$, and let's prove
    that
    $(a\times b) \times \successor{c} = a \times (b \times
    \successor{c})$. By definition (and commutativity) of
    multiplication, the left hand side is equal to $(a \times b)
    \times c + (a \times b)$. The right hand side is equal to $a
    \times (b \times c + b)$, and by distributive law (i.e.,
    Proposition 2.3.4), this is also $a \times (b \times c) + a \times
    b$. But then, by inductive hypothesis, this can be rewritten $(a
    \times b) \times c + a \times b$, which is equal to the left hand
    side. The induction is closed.
  \end{itemize}
\end{exo}

\begin{exo}{2.3.4}{Prove the identity $(a + b)^2 = a^2 + 2ab + b^2$
    for all natural numbers $a,b$.}

  By distribution law (i.e., Proposition 2.3.4) and commutativity of
  multiplication, we have:

  \begin{align*}
    (a+b)^2 &= (a+b)(a+b) = (a+b)a + (a+b)b \\
            &= a\times a + b \times a + a \times b + b \times b \\
            &= a^2 + a \times b + a \times b + b^2 \\
            &= a^2 + 2 ab + b^2
  \end{align*}

  (For the last step, we recall that, by Definition 2.3.1, $2 \times m
  = m + m$ for any natural number $m$.)
\end{exo}

\bigskip
\begin{exo}{2.3.5}{Euclidean algorithm. Let $n$ be a natural number, and let $q$ be a
    positive number. Prove that there exists natural numbers $m, r$
    such that $0 \leq r < q$ and $n = mq + r$.}

  We will induct on $n$ while remaining $q$ fixed.

  \begin{itemize}
  \item Base case: if $n=0$, there exists an obvious solution, namely
    $m=0$ and $r=0$.
  \item Suppose inductively that there exists $m, r$ such that $n = mq
    + r$ with $0 \leq r < q$, and let's prove that there exists $m', r'$ such that
    $n+1 = m'q+r'$, with $0 \leq r' < q$.

    By the induction hypothesis, we have $n + 1 = mq + r + 1$. Since
    $r < q$, we have $r + 1 \leq q$ (this is Proposition
    2.2.12). Thus, we have two cases here:

    \begin{enumerate}
    \item If $r+1 < q$, then $n+1 = mq + (r+1)$, with $0 \leq r+1 <q$,
      so that choosing $m' = m$ and $r' = r+1$ is convenient.
    \item If $r+1 = q$, then $n + 1 = mq + q = (m + 1)q$ according to
      the distributive law (Proposition 2.3.4). Thus, choosing $m' =
      m+1$ and $r' = 0$ is convenient.
    \end{enumerate}
  \end{itemize}
  This closes the induction.
\end{exo}

\pagebreak
\section{Set theory}
\begin{exo}{3.1.2}{Using only Definition 3.1.4, Axiom 3.1, Axiom 3.2,
    and Axiom 3.3, prove that the sets $\emptyset$, $\{\emptyset\}$,
    $\{\{\emptyset\}\}$, and $\{\emptyset, \{\emptyset\}\}$ are all
    distinct (i.e., no two of them are equal to each other).}

  As a general reminder, we recall that sets are objects (Axiom 3.1)
  and the empty set $\emptyset$ is such that no object is an element of
  $\emptyset$, thus $\emptyset \notin \emptyset$.
  
  \begin{enumerate}
  \item First let's show that $\emptyset$ is different from all other
    sets. $\emptyset$ is an element of $\{\emptyset\}$ and
    $\{\emptyset, \{\emptyset\}\}$, and $\{\emptyset\}$ is an element
    of $\{\{\emptyset\}\}$. But none of those two objects are elements
    of $\emptyset$ (by Axiom 3.2), thus $\emptyset$ is different from
    all three other sets.
  \item Then let's show that $\{\emptyset\} \neq
    \{\{\emptyset\}\}$. By Axiom 3.3, the singleton $\{\emptyset\}$ is
    such that $x \in \{\emptyset\} \Longleftrightarrow x =
    \emptyset$. Similarly, the singleton $\{\{\emptyset\}\}$ is such
    that $x \in \{\{\emptyset\}\} \Longleftrightarrow x =
    \{\emptyset\}$. But we already know that $\emptyset \neq
    \{\emptyset\}$ so there exists an object, $\emptyset$, which is a
    element of $\{\emptyset\}$ but not an element of
    $\{\{\emptyset\}\}$. Those sets are not equal.
  \item Now let's show that $\{\emptyset\} \neq \{\emptyset,
    \{\emptyset\}\}$. By Axiom 3.3, the pair $\{\emptyset,
    \{\emptyset\}\}$ is such that $x$ is an element of this set iff $x
    = \emptyset$ or $x = \{\emptyset\}$. Thus, $\{\emptyset\}$ is an
    element of $\{\emptyset, \{\emptyset\}\}$, but is not an element
    of $\{\emptyset\}$ (if it was, we should have $\emptyset =
    \{\emptyset\}$, which would be a contradiction with the first
    point of this proof). Those two sets are thus different.
  \item Finally, we also have
    $\{\{\emptyset\}\} \neq \{\emptyset, \{\emptyset\}\}$. Indeed, we
    have $\emptyset \in \{\emptyset, \{\emptyset\}\}$ by Axiom
    3.3. However,
    $\emptyset \in \{\{\emptyset\}\} \Longleftrightarrow \emptyset =
    \{\emptyset\}$ by definition of a singleton, and we know this
    latest statement is false by the first point of this proof. Those
    two sets are also different.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.3}{Prove the remaining claims in Lemma 3.1.13.}

  Those claims are the following:
  \begin{enumerate}
  \item $\{a,b\} = \{a\} \cup \{b\}$. By Axiom 3.3, the pair $\{a,
    b\}$ is such that $x \in \{a, b\} \Longleftrightarrow x = a$ or $x
    = b$. Let's consider three cases:
    \begin{itemize}
    \item if $x = a$, $x \in \{a\}$ by Axiom 3.3, thus $x \in \{a\}
      \cup \{b\}$ by Axiom 3.4
    \item if $x = b$, $x \in \{b\}$ by Axiom 3.3, thus $x \in \{a\}
      \cup \{b\}$ by Axiom 3.4
    \item if $x \neq a$ and $x \neq b$, $x \notin \{a\}$ and $x \notin
      \{b\}$ by Axiom 3.3, so that $x \notin \{a\} \cup \{b\}$
    \end{itemize}
    Thus, $\{a,b\}$ and $\{a\} \cup \{b\}$ have the same elements, and
    are equal.
  \item $A \cup B = B \cup A$ for all sets $A$ and $B$. Indeed, $x \in
    A \cup B \Longleftrightarrow x \in A$ or $x \in B$. If $x \in A$,
    then $x \in B \cup A$ by Axiom 3.4. A similar argument holds if $x
    \in B$. Thus, in both cases, $x \in B \cup A$. We can show in a
    similar fashion that any element of $B \cup A$ is in $A \cup B$.
  \item $A \cup \emptyset = \emptyset \cup A = A$. Since we've just
    showed that union is commutative, proving $A \cup \emptyset = A$
    is sufficient. If $x \in A$, then $x \in A \cup \emptyset$. The
    converse is also true: if $x \in A \cup \emptyset$, then $x \in A$
    or $x \in \emptyset$. But there is no element in $\emptyset$, so
    that we have necessarily $x \in A$. Thus, $A \cup \emptyset$ and
    $A$ have the same elements: they are equal.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.4}{Prove the remaining claims from Proposition 3.1.18.}

  Let $A, B, C$ be sets. Those claims are the following:

  \begin{enumerate}
  \item If $A \subseteq B$ and $B \subseteq A$, then $B =
    A$. According to Definition 3.1.4, two sets $A$ and $B$ are equal
    iff every element of $A$ is an element of $B$, and vice
    versa. This is precisely the present claim.
  \item If $A \subsetneq B$ and $B \subsetneq C$, then
    $A \subsetneq C$. Let $x$ be an element of $A$. Since
    $A \subsetneq B$, $x$ is also an element of $B$. And since
    $B \subsetneq C$, $x$ is also an element of $C$. This holds for
    any $x$ in $A$, and thus it demonstrates that $A \subset
    C$. Furthermore, since $A \subsetneq B$, there exists an element
    $y \in B$ which is not an element of $A$. As $B \subsetneq C$, $y$
    is also an element of $C$. Thus we have $y$, an element of $C$
    which is not in $A$. Combined to the previous result $A \subset
    C$, this demonstrates $A \subsetneq C$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.5}{Let $A, B$ be sets. Show that the three statements
    $A \subseteq B$, $A \cup B = B$ and $A \cap B = A$ are logically
    equivalent (i.e., any one of them implies the other two).}
  \begin{enumerate}
  \item First, we prove that
    $A \subseteq B \Longrightarrow A \cup B = B$. The first inclusion
    $B \subseteq A \cup B$ is trivial, since any element of a set $B$
    is always either in $A$ or $B$. For the converse inclusion, let
    $x$ be an element of $A \cup B$, and let's prove that $x \in
    B$. By Axiom 3.4, we have $x \in A$ or $x \in B$. If $x \in B$,
    the result holds. If $x \in A$, then we also have $x \in B$ since
    $A \subseteq B$. Thus, any element of $A \cup B$ is an element of
    $B$, which demonstrates the equality $A \cup B = B$.
  \item Then, we prove that $A \cup B = B \Longrightarrow A \cap B =
    A$. The first inclusion is trivial: if $x \in A \cap B$, then we
    always have $x \in A$. Now let's prove the converse inclusion: let
    $x$ be an element of $A$; we must show that $x \in A \cap B$. If
    $x \in A$, then $x \in A \cup B$. But, by hypothesis, $A \cup B =
    B$, thus $x \in B$. So, $x \in A$ and $x \in B$, i.e. $x \in A
    \cap B$. This demonstrates the implication.
  \item Finally, we prove that $A \cap B = A \Longrightarrow A
    \subseteq B$. Let $x \in A$. Since $A \cap B = A$, we have $x \in
    A \cap B$. It follows that $x \in B$. We have proved that any
    element $x \in A$ is also an element of $B$, i.e. $A \subseteq B$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.8}{Let A, B be sets. Prove the absorption laws
    $A \cap (A \cup B) = A$ and $A \cup (A \cap B) = A$.}
  \begin{enumerate}
  \item The first inclusion $A \cap (A \cup B) \subseteq A$ is
    trivial: if $x \in A \cap (A \cup B)$ then in particular $x \in A$
    by Definition 3.1.23 of an intersection\footnote{This intersection
      is not empty since $A$ and $A \cup B$ are not disjoint.}. Thus,
    we have $A \cap (A \cup B) \subseteq A$.

    For the converse inclusion, let $x$ be an element of $A$. Then by
    definition $x \in A$, and we have also $x \in A \cup B$ since $x
    \in A$. Thus, $x \in A \cap (A \cup B)$, which proves the converse
    inclusion.

    Consequently, $A = A \cap (A \cup B)$.
  \item First we show that $A \cup (A \cap B) \subseteq A$. Let
    $x \in A \cup (A \cap B)$. By Definition of an union, we have
    either $x \in A$, or $x \in A \cap B$. In both cases\footnote{If
      $A$ and $B$ are disjoint, then the first case $x \in A$
      necessarily holds, since $x \in A \cup B$ is impossible.}, we
    have $x \in A$, so that the inclusion is proved.

    Conversely, let $x \in A$. Then in particular, we have $x \in A
    \cup (A \cap B)$ by Definition of an union, because $x \in
    A$. Thus, $x \in A \cup (A \cap B)$.

    We have proved that $A \cup (A \cap B) = A$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.1.9}{Let $A, B, X$ be sets such that $A \cup B = X$ and
    $A \cap B = \emptyset$. Show that $A = X \backslash B$ and
    $B = X \backslash A$.}

  The two sets $A$ and $B$ play a symmetrical role here, so that
  proving one of these two assertions is sufficient. For instance, we
  prove that $A = X \backslash B$.

  \begin{itemize}
  \item Let $x$ be an element of $A$. Since $x \in A$, we also have $x
    \in A \cup B$ by definition of an union. But $A \cup B = X$, and
    then $x \in X$. On the other hand, we cannot have $x \in B$,
    because $x \in A$ and the sets $A, B$ are disjoint. Thus, $x \in
    X$ and $x \notin B$, which means that $x \in X \backslash B$. We
    have proved that $A \subseteq X \backslash B$.
  \item Conversely, let $x$ be an element of $X \backslash B$. By
    definition, this means that $x \in X$, i.e. $x \in A \cup B$, and
    $x \notin B$. Since $x \in A \cup B$, we have either $x \in A$ or
    $x \in B$, but we know that the latter is impossible. Thus, we
    have necessarily $x \in A$. We have proved that $X \backslash B
    \subseteq A$.
  \item We can conclude that $X \backslash B = A$.
  \end{itemize}
  
\end{exo}

\begin{exo}{3.1.11}{Prove that the axiom of replacement (Axiom 3.6)
    implies the axiom of specification (Axiom 3.5).}
  
  Let's recall the axiom of replacement. Let $A$ be a set. For every
  $x \in A$, and for every (abstract) object $y$, let $P(x,y)$ be a
  statement pertaining to both $x$ and $y$, such that for any
  $x \in A$ there is at most one $y$ for which $P(x,y)$ is true. Then
  there exists a set
  $\{y \, : \, P(x,y) \text{ is true for some } x \in A \}$, such that
  for any object $z$,
  \[z \in \{y \, : \, P(x,y) \text{ is true for some } x \in A \}
    \Longleftrightarrow P(x,z) \text{ is true for some } x \in A\]

  Now, let $A$ be a set, $x$ an element of $A$, and $y$ an object. We
  accept the axiom of replacement, and show that it implies the axiom
  of specification.

  Let $Q(x,y)$ be the property ``$x = y$ and $P(x)$''. According to
  the axiom of replacement, there exists a set
  $\{y \, : \, Q(x,y) \text{ is true for some } x \in A\}$ such that:
  \begin{align*}
    & z \in \{y \, : \, Q(x,y) \text{ is true for some } x \in A \} \\
    \Longleftrightarrow \; & Q(x,z) \text{ is true for some } x \in A \\
    \Longleftrightarrow \; & x = z \text{ and } P(x) \text{ is true
                             for some } x \in A
    \\
    \Longleftrightarrow \; & x = z \text{ and } P(z) \text{ is true
                             for some } x \in A \text{ 
                             (by axiom of substitution)} \\
    \Longleftrightarrow \; & z \in A \text{ and } P(z) \text{ is true }
  \end{align*}

  Thus, we have proved the existence of a set (the set $\{y \, : \,
  Q(x,y) \text{ is true for some } x \in A \}$) satisfying the axiom
  of specification: $z$ belongs to this set iff $z \in A$ and $P(z)$
  is true.
\end{exo}

\bigskip

\begin{exo}{3.3.1}{Show that the definition of equality in Definition
    3.3.7 is reflexive, symmetric and transitive. Also verify the
    substitution property: if $f_1, f_2 : X \to Y$ and $g_1,
    g_2 : Y \to Z$ are functions such that $f_1 f_2$ and $g_1
    = g_2$, then $g_1 \circ f_1 = g_2 \circ f_2$.}

  \begin{enumerate}
  \item Definition 3.3.7 says that two functions $f$ and $g$ are equal
    if they have same domain $X$ and range $Y$, and if, for all
    $x \in X$, $f(x) = g(x)$. This definition of equality is obviously
    reflexive, symmetric and transitive if we assume that the objects
    in the domain $X$ and the range $Y$ verify themselves the axioms
    of equality.
  \item Since $f_1 = f_2$, they have same domain $X$ and same range
    $Y$. This is also the case for $g_1$ and $g_2$, with domain $Y$
    and range $Z$. Thus, $g_1 \circ f_1$ has domain $X$ and range $Z$,
    and so has $g_2 \circ f_2$. Furthermore, we have, for all
    $x \in X$:
    \begin{align*}
      g_2 \circ f_2(x) &= g_2 \circ f_1(x) \text{ (since $f_1 = f_2$)}
      \\
                       &= g_1 \circ f_1(x) \text{ (since $g_1 = g_2$)}
    \end{align*}
    which closes the demonstration.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.2}{Let $f : X \to Y$ and $g : Y \to Z$
    be functions. Show that if $f$ and $g$ are both injective, then so
    is $g \circ f$. Similarly, show that if $f$ and $g$ are both
    surjective, then so is $g \circ f$.}

  First let's note that $g \circ f : X \to Z$.

  \begin{enumerate}
  \item Suppose that $f$ and $g$ are both injective, and let
    $x, x' \in X$. We have successively :
    \begin{eqnarray*}
      g \circ f (x) & =& g \circ f (x') \\
      g(f(x)) &=& g(f(x'))  \\
      f(x) &=& f(x') \; \text{ because $g$ is injective}\\
      x &=& x' \; \text{ because $f$ is injective}
    \end{eqnarray*}
    We have showed that $g \circ f (x) = g \circ f (x') \to x
    = x'$ for all $x, x' \in X$, i.e. that $g \circ f$ is injective.
    
  \item Suppose that $f$ and $g$ are both surjective, and let
    be $z \in Z$. Since $g$ is surjective, there exists $y \in Y$ such
    that $z = g(y)$. And since $f$ is surjective, there exists $x \in
    X$ such that $y = f(x)$. Thus, combining those two results, there
    exists $x \in X$ such that $z = g(f(x))$. This means precisely
    that $g \circ f$ is surjective.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.3}{When is the empty function injective? surjective?
    bijective?}
  
  Let $f$ be the empty function, i.e. $f : \emptyset \to Y$
  for a certain range $Y$.
  \begin{enumerate}
  \item $f$ is injective iff $x \neq x' \Rightarrow f(x) \neq f(x')$.
    This can be considered as vacuously true since there are no such
    $x$ and $x'$ in $\emptyset$. $f$ can be considered as always
    injective, for any range $Y$.
  \item $f$ is surjective iff for any $y \in Y$, there exists $x \in
    \emptyset$ such that $y = f(x)$. We can clearly see that this
    assertion is false if $Y \neq \emptyset$, since any $y \in Y$ will
    have no antecedent in $\emptyset$. Conversely, if $Y = \emptyset$,
    the assertion is vacuously true, since there is no element in
    $Y$. Thus, $f$ is surjective iff $Y = \emptyset$.
  \item Since $f$ is always injective, and is surjective iff $Y =
    \emptyset$, it is clear that $f$ is bijective iff $Y = \emptyset$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.4}{Let $f : X \to Y$, $\tilde{f} : X
    \to Y$, $g : Y \to Z$, $\tilde{g} : Y \to
    Z$ be functions. Show that if $g \circ f = g \circ \tilde{f}$ and
    $g$ is injective, then $f = \tilde{f}$. Is this statement true if
    $g$ is not injective? Also, show that if $g \circ f = \tilde{g}
    \circ f$ and $f$ is surjective, then $g = \tilde{g}$. Is this
    statement true if $f$ is not surjective?}

  This exercise introduces some cancellation laws for composition.

  \begin{enumerate}
  \item First, note that $f$ and $\tilde{f}$ have same domain and
    range, which is the first condition for two functions to be equal
    (by Definition 3.3.7). Then, suppose that
    $g \circ f = g \circ \tilde{f}$ and $g$ is injective. For the sake
    of contradiction, suppose that there exists $x \in X$ such that
    $f(x) \neq \tilde{f}(x)$. Since $g$ is injective, we would thus
    have $g(f(x)) \neq g(\tilde{f}(x))$, which would be a
    contradiction to the hypothesis $g \circ f = g \circ
    \tilde{f}$. Thus, there is no $x$ such that $f(x) = \tilde{f}(x)$,
    or in other words, $f = \tilde{f}$.

    This property is false if $g$ is not injective. As a
    counterexample, one can think of $f : \rr \to \rr$ with
    $f(x) = x$, $\tilde{f} : \rr \to \rr$ with
    $\tilde{f}(x) = -x$, and $g : \rr \to \rr_+$ with
    $g(x) = |x|$.
  \item As previously, first note that $g$ and $\tilde{g}$ have same
    domain and range. Let be $y, y' \in Y$. Since $f$ is surjective,
    there exist $x, x' \in X$ such that $y = f(x)$ and $y' = f(x')$
    respectively. Since $g \circ f = g \circ \tilde{f}$, we have
    $g(f(x)) = g(f(x'))$, i.e. $g(y) = g(y')$. We have showed that,
    for any $y, y' \in Y$, we have $g(y) = g(y')$, which means that $g
    = \tilde{g}$.

    This statement is false if $f$ is not surjective. For instance,
    let $f$ be a constant function, e.g. $f : \rr \to \rr$
    with $f(x) = 1$ for all $x$. Let $g, \tilde{g} : \rr \to
    \rr$ with $g(x) = 0$ and $\tilde{g}(x) = - x +1$. We have $g(1) =
    \tilde{g}(1)$, i.e. $g(f(x)) = \tilde{g}(x)$ for all $x \in X$,
    but we obviously do not have $g = \tilde{g}$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.5}{Let $f : X \to Y$ and $g : Y \to Z$
    be functions. Show that if $g \circ f$ is injective, then $f$ must
    be injective. Is it true that $g$ must also be injective? Show that
    if $g \circ f$ is surjective, then $g$ must be surjective. Is it
    true that $f$ must be surjective?}

  \begin{enumerate}
  \item If $g \circ f$ is injective, then for any given objects
    $x, x' \in X$, we have $g(f(x)) = g(f(x')) \Longrightarrow x =
    x'$. For the sake of contradiction, suppose that $f$ is not
    injective. In this case, there exist two elements $a, a' \in X$ such
    that $a \neq a'$ and $f(a) = f(a')$. We would thus have $g(f(a)) =
    g(f(a'))$ (axiom of substitution) and $a \neq a'$, which is
    incompatible with the hypothesis that $g \circ f$ is injective.

    Thus, $g \circ f$ injective implies that $f$ is injective.

    However, $g$ does not need to be injective. For instance, let's
    consider $X = \{1,2\}$ and $Y = Z = \{1, 2, 3\}$. Let's define the
    function $f$ as the mapping $f(1) = 1$, $f(2) = 2$. Let's define the
    function $g$ as the mapping $g(1) = 1$, $g(2) = 2$, $g(3) = 2$. Here,
    $f$ is injective, so is $g \circ f$, but $g$ is not injective.
  \item If $g \circ f$ is surjective, then for all $z \in Z$, there
    exists $x \in X$ such that $z = g(f(x))$. For the sake of
    contradiction, suppose that $g$ is not surjective: then, there
    exists $z \in Z$ such that for all $y \in Y$, $z \neq g(y)$. In
    particular, for all $x \in X$, since $f(x) \in Y$, we would have
    $g(f(x)) \neq z$, which would be a contradiction with $g \circ f$
    surjective.

    However, $f$ does not need to be surjective. For instance, let's
    consider $X = Y = \{1,2\}$ and $Z = \{1\}$. Let $f$ be the mapping
    $f(1) = f(2) = 1$, and $g$ be the mapping $g(1) = g(2) = 1$. Here,
    $g \circ f$ is surjective, but $f$ is not.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.6}{Let $f : X \to Y$ be a bijective function,
    and let $\inv{f} : Y \to X$ be its inverse. Verify the
    cancellation laws $\inv{f}(f(x)) = x$ for all $x \in X$ and
    $f(\inv{f}(y)) = y$ for all $y \in Y$. Conclude that $\inv{f}$ is
    also invertible and has $f$ as its inverse.}

  Recall that, by definition, for all $y \in Y$, $\inv{f}(y)$ is the only element
  $x \in X$ such that $f(x) = y$.
  \begin{enumerate}
  \item Let $a$ be an element of $X$, we thus have $f(a) \in Y$. Let's
    apply the definition to the element $y = f(a) \in Y$: by
    definition, $\inv{f}(f(a))$ is the only element $x \in X$ such
    that $f(x) = f(a)$. Since $f$ is bijective, this implies $x =
    a$. We thus have proved that $\inv{f}(f(a)) = a$.
  \item The proof for $f(\inv{f}(y)) = y$ is similar.
  \item To prove that $\inv{f}$ is also invertible, we need to prove
    that $\inv{f}$ is bijective, i.e. injective and surjective.

    For any given $y \in Y$, since $f$ is bijective, there exists exactly
    one $x \in X$ such that $y = f(x)$. Similarly, for any given $y'
    \in Y$, there exists exactly one $x' \in X$ such that $y' =
    f(x')$. In other words, $\inv{f}(y) = x$ and $\inv{f}(y') =
    x'$. Suppose that $\inv{f}(y) = \inv{f}(y')$. This can be written
    $x = x'$, which necessarily implies $f(x) = f(x')$ since $f$ is a
    function (and by axiom of substitution). And this can also be
    written $y = y'$. We thus have proved that for any $y, y' \in Y$,
    $\inv{f}(y) = \inv{f}(y') \Longrightarrow y = y'$. Thus, $\inv{f}$
    is injective.

    Furthermore, for any given $x \in X$, let's denote $y =
    f(x)$. Since $f$ is bijective, this means that $\inv{f}(y) =
    x$. Thus, any $x \in X$ has a predecessor $y \in Y$ for $\inv{f}$,
    i.e.  $\inv{f}$ is surjective.
  \end{enumerate}
\end{exo}

\begin{exo}{3.3.7}{Let $f : X \to Y$ and $g : Y \to Z$
    be functions. Show that if $f$ and $g$ are bijective, then so is $g
    \circ f$, and we have $\inv{(g \circ f)} = \inv{f} \circ \inv{g}$.}

  The first point is an immediate consequence of Exercise 3.3.2. We just
  have to show that $\inv{(g \circ f)} = \inv{f} \circ \inv{g}$.

  Let be any given element $z \in Z$. Since $g$ is bijective, there
  exists one single element $y \in Y$ such that $z = g(y)$, i.e.
  $y = \inv{g}(z)$. And since $f$ is also bijective, there exists
  exactly one single element $x \in X$ such that $y = f(x)$, i.e. $x =
  \inv{f}(y) = \inv{f}(\inv{g}(z))$.

  Thus, for every $z \in Z$, there exists exactly one $x \in X$ such
  that $g \circ f(x) = z$, and this element is
  $\inv{f}(\inv{g}(z))$. This means exactly that $\inv{(g \circ f)} =
  \inv{f} \circ \inv{g}$.
\end{exo}

\bigskip

\begin{exo}{3.4.1}{Let $f : X \to Y$ be a bijective function,
    and let $\inv{f} : Y \to X$ be its inverse. Let $V$ be any
    subset of $Y$. Prove that the forward image of $V$ under $\inv{f}$
    is the same as the inverse image of $V$ under $f$; thus the fact
    that both sets are denoted as $\inv{f}$ will not lead to any
    inconsistency.}

  Since ``$\inv{f}(V)$'' may refer to two different things here, let's
  first introduce some notations to avoid any confusion :
  \begin{itemize}
  \item Let $F$ be the \emph{forward image} of $V$ under $\inv{f}$,
    i.e. $F = \{\inv{f}(y) \; | \; y \in V\}$.
  \item Let $I$ be the \emph{inverse image} of $V$ under $f$, i.e.
    $I = \{x \in X \; | \; f(x) \in V\}$.
  \end{itemize}

  In this exercise we must show that $F = I$, so as to ensure that the
  two definitions of $\inv{f}$ are equivalent. So, we will prove that
  $F \subseteq I$ and $I \subseteq F$.

  \begin{enumerate}
  \item Let be $x \in F$. Thus, there exists $y \in V$ such that
    $x = \inv{f}(y)$. By definition, this is equivalent to $f(x) =
    y$. But since $y \in V$, we can say that $f(x) \in V$. Thus, we
    have both $x \in X$ (beacuse $F \subseteq X$) and $f(x) \in V$,
    which means that $x \in I$.
  \item Conversely, let be $x \in I$. By definition, this means that
    $x \in X$ and that $f(x) \in V$, i.e. there exists a certain
    element $y \in V$ such that $y = f(x) \in V$. This latter
    statement is equivalent to $x = \inv{f}(y)$. Thus, we have $x \in
    X$ and $x = \inv{f}(y)$ for a certain $y \in V$, which means that
    $x \in F$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.2}{Let $f : X \to Y$ be a function, let $S$ be
    a subset of $X$ and let $U$ be a subset of $Y$. What, in general,
    can one say about $\inv{f}(f(S))$ and $S$? What about
    $f(\inv{f}(U))$ and $U$?}
  
  This exercise gives a first taste of Exercise 3.4.5 below.

  \begin{enumerate}
  \item First consider $\inv{f}(f(S))$ and $S$.
    \begin{itemize}
    \item Do we have $\inv{f}(f(S)) \subset S$? Generally, no. As an
      counterexample, let's consider $f(x) = x^2$ with $X = Y =
      \rr$ and $S = \{0,2\}$. We have $\inv{f}(f(S)) =
      \inv{f}(\{0,4\}) = \{-2, 0, 2\}$. In this set, we have an
      element, $-2$, which is not an element of $S$.
    \item Do we have $S \subset \inv{f}(f(S))$? Yes. Let be $x \in
      S$. Then, by definition, $f(x) \in f(S)$. So, $x \in X$ and is
      such that $f(x) \in f(S)$: this is precisely the definition of
      $x \in \inv{f}(f(S))$.
    \item Conclusion: generally speaking, $S$ and $\inv{f}(f(S))$ are
      not equal, but $S \subset \inv{f}(f(S))$.
    \end{itemize}
  \item Now consider $f(\inv{f}(U))$ and $U$.
    \begin{itemize}
    \item Do we have $U \subset f(\inv{f}(U))$? Generally, no. As a
      counterexample, let's consider $f(x) = \sqrt{x}$ with $X =
      \rr_+$, $Y = \rr$ and $U = [-1,1]$. We have $f(\inv{f}(U)) =
      f([0,1]) = [0,1]$, which is clearly not a subset of $U$.
    \item Do we have $f(\inv{f}(U)) \subset U$ ? Yes. Let be $y \in
      f(\inv{f}(U))$. By definition, there exists $x \in \inv{f}(U)$
      such that $y = f(x)$. But if $x \in \inv{f}(U)$, we have
      $f(x)\in U$. And since $y = f(x)$, this means that $y \in U$.
    \item Conclusion: generally speaking, $U \neq f(\inv{f}(U))$,
      but $f(\inv{f}(U)) \subset U$.
    \end{itemize}
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.3}{Let $A, B$ be two subsets of $X$, and let be $f : X
    \to Y$. Show that $f(A \cap B) \subseteq f(A) \cap f(B)$,
    that $f(A) \backslash f(B) \subseteq f(A \backslash B)$, and $f(A
    \cup B) = f(A) \cup f(B)$. Is it true that, for the first two
    statements, the $\subseteq$ relation can be improved to $=$?}
  
  Let's prove the three statements successively:
  \begin{enumerate}
  \item If $y \in f(A \cap B)$, then there exists $x \in A \cap B$
    such that $f(x) = y$. Since $x \in A \cap B$, we have both $x \in
    A$ and $x \in B$, which implies $y = f(x) \in f(A)$ and $y = f(x)
    \in B$ respectively. Thus, $y \in f(A) \cap f(B)$, and we have
    proved that $f(A \cap B) \subseteq f(A) \cap f(B)$.

    However, the converse inclusion is false in general. For instance,
    let's consider the two sets $A = \{1,2\}$, $B = \{2,3\}$ and the
    (non injective) function $f$ defined as the mapping $f(1) = 1$,
    $f(2) = 2$, $f(3) = 1$. We have $f(A) = \{1,2\}$,
    $f(B) = \{1,2\}$, thus $f(A) \cap f(B) = \{1,2\}$. This is not a
    subset of $f(A \cap B) = f(\{2\}) = \{2\}$.
  \item If $y \in f(A) \backslash f(B)$, then there exists $x_0 \in A$
    such that $y = f(x_0)$, but we have $f(b) \neq y$ for all
    $b \in B$. Suppose that $x_0 \in B$: in this case,
    $f(x_0) \neq y$, a contradiction. Thus, $y = f(x_0)$ with
    $x_0 \in A \backslash B$, which proves that
    $f(A) \backslash f(B) \subseteq f(A \backslash B)$.

    However, the converse inclusion is false in general. For instance,
    let's consider the two sets $A = \{1,2,3\}$, $B = \{3\}$ and the
    function $f$ defined as the mapping $f(1) = 1$, $f(2) = 2$,
    $f(3) = 1$. We have $f(A \backslash B) = \{1,2\}$ but
    $f(A) \backslash f(B) = \{2\}$.
  \item If $y \in f(A \cup B)$, then there exists $x \in A \cup B$
    such that $y = f(x)$. If $x \in A$, then $f(x) \in f(A)$, which
    implies $x \in f(A) \cup f(B)$. There is an identical result if $x
    \in B$. Thus, $f(A\cup B) \subseteq f(A) \cup f(B)$.

    Conversely, if $y \in f(A) \cup f(B)$, then we have either $y \in
    f(A)$ or $y \in f(B)$ (or both). In the first case, there exists
    $x \in A$ such that $y = f(x)$. But since $x \in A$, we also have
    $x \in A\cup B$, so that $y \in f(A \cup B)$. The same result
    holds if $y \in B$. Thus, in both cases, $y \in f(A \cup B)$.
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.4}{Let be $f : X \to Y$ a function, and let
    $A, B$ be subsets of $Y$. Show that
    $\inv{f}(A \cup B) = \inv{f}(A) \cup \inv{f}(B)$, that
    $\inv{f}(A \cap B) = \inv{f}(A) \cap \inv{f}(B)$, and that
    $\inv{f}(A \backslash B) = \inv{f}(A) \backslash \inv{f}(B)$.}
  
  We prove only the first statement here; since only very small
  adjustments are required in its proof to prove the last two ones.

  \begin{itemize}
  \item Let be $x \in \inv{f}(A \cup B)$. By definition, $f(x) \in A \cup
    B$, so that we have either $f(x) \in A$ or $f(x) \in B$.

    If $f(x) \in A$, then $x \in \inv{f}(A)$ by definition. This
    implies that $x \in \inv{f}(A) \cup \inv{f}(B)$.

    The same conclusion holds if $f(x) \in B$. Thus, we have
    demonstrated that
    $\inv{f}(A \cup B) \subseteq \inv{f}(A) \cup \inv{f}(B)$.

  \item For the conserve inclusion, let be $x \in \inv{f}(A) \cup
  \inv{f}(B)$. We have either $x \in \inf{f}(A)$ or $x \in
  \inv{f}(B)$.

  If $x \in \inv{f}(A)$, then $f(x) \in A$, and since
  $A \subset A \cup B$, we have $f(x) \in A \cup B$. This implies
  $x \in \inv{f}(A \cup B)$.

  The same conclusion holds if $x \in \inv{f}(B)$. Thus,
  $\inv{f}(A) \cup \inv{f}(B) \subseteq \inv{f}(A \cup B)$.

  \item This proves the equality $\inv{f}(A \cup B) = \inv{f}(A) \cup
    \inv{f}(B)$.
  \end{itemize}
\end{exo}

\begin{exo}{3.4.5}{Let $f : X \to Y$ be a function. Show that
    $\inv{f}(f(S)) = S$ for every $S \subseteq Y$ iff $f$ is
    surjective. Show that $f(\inv{f}(S)) = S$ for every $S \subseteq
    X$ iff $f$ is injective.}

  This exercise is a continuation of Exercise 3.4.2. Let's recall its
  results, that will reduce the amount of things to be proven here:
  \begin{itemize}
  \item we always have $\inv{f}(f(S)) \subseteq S$ for every
    $S \subseteq Y$, thus we just have to prove that $f$ is
    surjective iff $S \subseteq \inv{f}(f(S))$ for every
    $S \subseteq Y$.
  \item we always have $S \subseteq f(\inv{f}(S))$ for every
    $S \subseteq X$, thus we just have to prove that $f$ is
    injective iff then $f(\inv{f}(S)) \subseteq S$ for every
    $S \subseteq X$.
  \end{itemize}

  Let's prove those two statements.
  \begin{enumerate}
  \item Let $f$ be surjective: let's show that
    $S \subseteq f(\inv{f}(S))$ for all $S \subseteq Y$. Let $S$ be a
    subset of $Y$, and $y \in S$\footnote{If $S$ is empty, the
      statement is vacuously true, so that we can suppose
      $S \neq \emptyset$.}. Since $f$ is surjective, there exists
    $x \in X$ such that $y = f(x)$. Recall that $y \in S$: this means
    that$f(x) \in S$, i.e. $x \in \inv{f}(S)$. Thus,
    $y = f(x) \in f(\inv{f}(S))$. We have proved that, if $f$ is
    surjective, $y \in S \to y \in f(\inv{f}(S))$, i.e.
    $S \subseteq f(\inv{f}(S))$.

    Conversely, suppose that $S \subseteq f(\inv{f}(S))$ for every
    $S \subseteq Y$ and let's show that $f$ is surjective. Let's
    choose $S = Y$: by hypothesis, we have
    $Y \subseteq f(\inv{f}(Y))$. Then, let be $y \in Y$. There exists
    $x \in \inv{f}(Y) \subseteq X$ such that $y = f(x)$. This means
    precisely that $f$ is surjective.

    The first equivalence is proved.

  \item Let $f$ be injective, and $S \subseteq X$. Let be
    $x \in \inv{f}(f(S))$. Thus, by definition, $f(x) \in f(S)$. This
    means that there exists $x' \in f(S)$ such that $f(x) =
    f(x')$. And since $f$ is injective, $x = x' \in S$. Thus, if $f$
    is injective, $\inv{f}(f(S)) \subseteq S$ for every
    $S \subseteq X$.

    Conversely, suppose that $\inv{f}(f(S)) \subseteq S$ for every
    $S \subseteq X$. In particular, this is true for any singleton
    $S = \{x_0\}$, with $x_0 \in S$. In such a case, we obtain
    $\inv{f}(f(\{x_0\})) = \{x_0\}$. For any element $x \in X$, if
    $x \neq x_0$, we have $x \notin \{x_0\}$ by definition of a
    singleton, thus $x \notin \inv{f}(f(\{x_0\}))$, and thus
    $f(x) \neq f(x_0)$. This means that $f$ is injective.

    The second equivalence is proved.    
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.6}{Prove lemma 3.4.9. (Hint: start with the set
    $\{0,1\}^X$ and apply the replacement axiom, replacing each
    function $f$ with the object $f^{-1}(\{1\})$.)}

  First, let's recall the main propositions involved in this exercise:

  \begin{itemize}
  \item \textbf{Replacement axiom}. Let $A$ be a set. For any object
    $x \in A$, and any object $y$, suppose we have a statement
    $P(x,y)$ pertaining to $x$ and $y$, such that for each $x \in A$
    there is at most one $y$ for which $P(x,y)$ is true. Then there
    exists a set
    $\{y \; | \; P(x,y) \text{ is true for some } x \in A\}$, such
    that for any object $z$,
    \[ z \in \{y \; | \; P(x,y) \text{ is true for some } x \in A\}
      \Longleftrightarrow P(x,z) \text{ is true for some } x \in A\]

\item \textbf{Power set axiom}. Let $X$ and $Y$ be sets. There there
  exists a set, denoted $Y^X$, which consists of all the function from
  $X$ to $Y$:
  \[f \in Y^X \Longleftrightarrow (f \text{ is a function from $X$ to
      $Y$}\}\]

\item \textbf{Lemma 3.4.9}. Let $X$ be a set. Then the set
  $\{Y \; | \; Y \text{ is a subset of X}\}$ is a set.
  \end{itemize}

  The aim is to prove this lemma using the two axioms recalled here.

  \begin{enumerate}
  \item Let $X$ be a set, and $Y = \{0,1\}$. Per the power set axiom,
    $\{0,1\}^X$ is a set, and it contains all the functions
    $f : X \to \{0,1\}$.
  \item Let $A$ be a subset of $X$. One can define the function
    $f_A : X \to \{0,1\}$, such that for all $x \in X$,
    $f(x) = 1$ if $x \in A$, and $f(x)=0$ otherwise. We can even say
    more:
    \begin{itemize}
    \item If $A$ is a subset of $X$, then there exists an element
      $f \in \{0,1\}^X$ such that $A = f^{-1}(\{1\})$: this is
      precisely $f_A$ as defined above.
    \item Conversely, if $f \in \{0,1\}^X$, then $A = f^{-1}(\{1\})$
      is by definition a subset of $X$.
    \end{itemize}
    Thus, the two statements ``$A$ is a subset of $X$'' and ``there
    exists $f \in \{0,1\}^X$ such that $A = f^{-1}(\{1\})$'' are
    equivalent.
  \item Finally, let be $A \subset X$ and $f \in \{0,1\}^X$. Let's
    define $P(f,A)$ the statement ``$A = f^{-1}(\{1\})$''. For each
    $f$, there is at most one $A$ (in fact, \emph{exactly} one $A$)
    such that $P(f,A)$ is true. Thus, per the axiom of replacement,
    there exists a set:
    \[\mathcal{P} = \{A \; | \; A = f^{-1}(\{1\}) \text{ for some } f \in \{0,1\}^X\}\]
    And, thanks to the equivalence demonstrated in 2.:
    \[ \mathcal{P} = \{A \; | \; A \text{ is a subset of } X\} \]
    is a well-defined set, which we wanted to prove.
  \end{enumerate}
\end{exo}

\begin{exo}{3.4.7}{Let $X, Y$ be sets. Define a partial function
    from $X$ to $Y$ to be any function $f: X' \to Y'$ with
    $X' \subseteq X$ and $Y'\subseteq Y$. Show that the collection of
    all partial functions from $X$ to $Y$ is itself a set.}
  \begin{itemize}
   \item Let be $X' \subseteq X$ and $Y' \subseteq Y$. If both $X'$
     and $Y'$ are fixed, then per the power set axiom (3.10), there
     exists a set $Y'^{X'}$ which consists of all the functions from
     $X'$ to $Y'$.
   \item By lemma 3.4.9, there exist a set $2^X$ which consists of all
     the subsets of $X$, and a set $2^Y$ which consists of all the
     subsets of $Y$.
   \item Now we \emph{fix} an element $X'$ of $2^X$. Let be $Y'$ an
     element of the set $2^Y$, $A$ a set, and $P$ the property
     ``$P(Y', A)$: $A = Y'^{X'}$''. Per the replacement axiom, there
     exists exactly one (and thus, at most one) set:
     \begin{align*}
       \{A \, | \, P(Y', A) \text{ is true for some } Y' \in 2^Y\}
       &= \{A \, | \, A = Y'^{X'} \text{ for some } Y' \in 2^Y\}\\
       &= \{Y'^{X'} \, | \, Y' \in 2^Y\}
     \end{align*}
   \item Each element of this set is itself a set. Thus we can apply
     the axiom of union (3.11): there exists a set
     $\bigcup \{Y'^{X'} \, | \, Y' \in 2^Y\}$ whose elements are those
     objects which are elements of elements of
     $\{Y'^{X'} \, | \, Y' \in 2^Y\}$, i.e.:

     \[ \bigcup \{Y'^{X'} \, | \, Y' \in 2^Y\} = \{f | f:X'
       \to Y' \text{ for some } Y' \in 2^Y\}\]

     This set is obtained for one given \emph{fixed} subset
     $X' \subseteq X$, so let's denote this set:
     \[S_{X'} = \{f | f:X' \to Y' \text{ for some } Y' \in
       2^Y\}\]
   \item Now we apply once again the union set (3.11), especially in
     its second formulation. If we denote $I = 2^X$, then for each
     element $X' \in I$ we do have one set $S_{X'}$, which is defined
     above. Thus, there exists a set
     $\bigcup_{X' \in 2^X} S_{X'} := \bigcup \{S_{X'} \, | \, X' \in
     2^X\}$. And, for every function $f$, we have
     $f \in \bigcup \{S_{X'} \, | \, X' \in 2^X\}$ iff there exists
     $X' \in 2^X$ such that $f \in S_{X'}$, i.e. if there exists
     $X' \subset X$ and $Y' \subset Y$ such that
     $f: X' \to Y'$.
   \item Consequently, we have proved that there exists a set which
     consists of the collection of all partial functions from $X$ to
     $Y$.
\end{itemize}
\end{exo}

\begin{exo}{3.4.8}{Prove that Axiom 3.4 can be deduced from Axiom 3.1,
  Axiom 3.3 and Axiom 3.11.}

Let's recall very briefly the four axioms involved here :
\begin{itemize}
  \item Axiom 3.4 (to be proved) says that if $A$ and $B$ are sets,
    then there exists a union set $A \cup B$ such that $x \in A \cup
    B$ iff $x \in A$ or $x \in B$.
\item Axiom 3.1 essentially says that sets are objects.
\item Axiom 3.3 says that singletons are pair sets do exist.
\item Axiom 3.11: let $A$ be a set, whose all elements are themselves
  sets. Then there exists a set $\bigcup A$ whose elements are those
  objects which are elements of elements of $A$, i.e., $x \in \bigcup
  A$ iff $x \in S$ for some $S \in A$.
\end{itemize}
\end{exo}

Here is a sketch of proof for Axiom 3.4. Let $A$ and $B$ be
sets. According to Axiom 3.1, $A$ and $B$ are themselves objects: they
can be elements of other sets. Consequently, according to Axiom 3.3,
it makes sense to talk about the singleton sets $\{A\}$ and $\{B\}$,
and the set $\{A, B\}$.

Now we consider this latter set, which we denote $\mathcal{A} = \{A,
B\}$. According to axiom 3.11, there exists a set $\bigcup
\mathcal{A}$ whose elements those objects which are the elements of
$\mathcal{A}$, i.e., $x \in \mathcal{A}$ iff there exists $S \in
\mathcal{A}$ such that $x \in S$. But $\mathcal{A}$ is a pair set with
only two elements, so that $S$ must necessarily be equal to $A$ or
$B$.

This leads to the following conclusion: if $A$ and $B$ are sets, then
there exists a set $\mathcal{A}$ such that $x \in \mathcal{A}$ iff
$x \in A$ or $x \in B$. This is precisely the Axiom 3.4.

\bigskip
\begin{exo}{3.5.1}{Suppose we define the ordered pair $(x,y)$  for any
    objects $x$ and $y$ by the formula $(x,y) := \{\{x\},
    \{x,y\}\}$. Show that  this definition obeys the property (3.5), and
    also whenever $X$ and $Y$ are sets, the cartesian product $X \times
    Y$ is also a set.}

  Recall that property (3.5) says that $(x,y) = (x',y')$ iff $x=x'$
  and $y=y'$. The proof below is heavily inspired by the sketch given
  by Paul Halmos in his famous book, \textit{Naive Set Theory}. (The
  proof below is just immensely more verbose.)

  \begin{enumerate}
  \item First, we go back to Remark 3.1.9 by Terence Tao (page
    37). In this remark, Tao says that for any object $a$, the pair
    set $\{a, a\}$ is in fact the singleton $\{a\}$. Tao asks
    \textit{why?} to the reader. This is easy to prove using the
    Definition 3.1.4 (equality of sets): both sets have the same
    elements, thus they are equal. This fact is a crucial point for
    the current proof.

    Indeed, first note that for any object $x$, the ordered pair
    $(x,x)$ will be (by definition) equal to $\{\{x\},
    \{x,x\}\}$. Applying twice the Remark 3.1.9 made by Terence Tao,
    we can conclude that $(x,x) = \{\{x\}\}$ for any object $x$.
    
    Conversely, if any ordered pair $(x,y)$ is a singleton, this means
    that $\{\{x\}, \{x,y\}\}$ is a singleton. This implies that both
    elements of this pair set are equal, i.e. $\{x\} = \{x,y\}$. Thus,
    (by Definition 3.1.4,) $y \in \{x\}$, i.e. $x=y$.
    
    This gives a handy conclusion, that we can write as a lemma:
    \begin{lem} An ordered pair $(x,y)$ is a singleton if and only
      if $x=y$ (and in this case, this singleton is $\{\{x\}\} =
      \{\{y\}\}$).
    \end{lem}
    We can now prove more easily that property (3.5) is met.
  \item Let's prove that the property (3.5) is satisfied.
    \begin{itemize}
    \item First, let be two ordered pairs $(a,b) = \{\{a\}, \{a,b\}\}$
      and $(x,y) = \{\{x\}, \{x,y\}\}$. If $a=x$ and $y=b$, then we
      obviously have $\{\{a\}, \{a,b\}\} = \{\{x\}, \{x,y\}\}$.
    \item For the reciprocal, suppose that $(a,b) = (x,y)$, and let's
      show that $a=x$ and $b=y$. We will consider two distinct cases.
      \begin{enumerate}[label=\emph{(\alph*)}]
      \item First consider the case where $a=b$ (note that this also
        covers the case $x=y$, since they play symmetrical
        roles). Thus $(a,b) = \{\{a\}\}$. Since $(a,b) = (x,y)$, we have
        $\{\{x\},\{x,y\}\} = \{\{a\}\}$.

        This means that $\{x\} \in \{\{a\}\}$, i.e. $a=x$.

        But we also have $\{x,y\} \in \{\{a\}\}$, i.e. $\{x,y\} =
        \{a\}$. This means in particular that $\{x,y\}$ is a
        singleton, which is only possible if $x=y$ according to the
        lemma introduced above.

        Thus, $a=b$ by hypothesis, and $a=x$, and $x=y$. This finally
        means that all four elements are equal: $a=b=x=y$.

        We can insist: if we have either $a=b$ or $x=y$, then all four
        elements are equal, and property (3.5) is met.
        
      \item The other case is $a \neq b$ (which also implies $x \neq
        y$, otherwise all four elements would be equal). Since $(a,b)
        = (x,y)$, we have $\{a\} \in \{\{x\}, \{x,y\}\}$, so that we
        have either $\{a\} = \{x\}$ or $\{a\} = \{x,y\}$. The latter
        case can be excluded: $\{a\} = \{x,y\}$ would mean that
        $\{x,y\}$ is a singleton, thus $x=y$, a contradiction with our
        hypothesis. Thus, the only possibility is $\{a\} = \{x\}$,
        i.e. $a=x$.

        We also have $\{a,b\} \in \{\{x\}, \{x,y\}\}$, and for the
        same reason, the only possibility is $\{a,b\} = \{x,y\}$. But
        we have showed that $a=x$, so that $\{a,b\} = \{a,y\}$. The
        conclusion is $y=b$.
      \end{enumerate}
        
      \item Conclusion: in both cases, $(a,b)$ implies both $a=x$ and $y=b$,
      which is our initial goal. Property (3.5) is met.
    \end{itemize}
  \item Finally, if we adopt this definition, $X \times Y$ is a
    set. Indeed, for every $x\in X$ and $y \in Y$, both $x$ and $y$
    are elements of $X \cup Y$. Thus, the singleton $\{x\}$ and the
    pair set $\{x,y\}$ are elements of the power set of $X \cup Y$
    (which is indeed a set, by Lemma 3.4.9: see Exercise 3.4.6). In
    other words, if $\partsof{A}$ denotes the power set of a set $A$,
    we have $\{x\} \in \partsof{X \cup Y}$ and
    $\{x,y\} \in \partsof{X \cup Y}$.

    Thus, for every objects $x \in X$ and $y \in Y$,
    $\{\{x\}, \{x,y\}\} \subset \partsof{X \cup Y}$. This latter
    statement is equivalent to $\{\{x\}, \{x,y\}\} \in
    \partsof{\partsof{X \cup Y}}$, which is also a well-defined set by
    a (recursive) application of Lemma 3.4.9.

    Then, for any element $S \in \partsof{\partsof{X \cup Y}}$, let
    $P(S)$ be the property ``There exists $x \in X$ and $y \in Y$ such
    that $S = \{\{x\}, \{x,y\}\}$''. By the axiom of specification
    (Axiom 3.5), there exists a set $\{S \in \partsof{\partsof{X \cup
        Y}} \, | \, P(S) \text{ is true}\}$: this set is precisely the
    cartesian product $X \times Y$ we were looking for.
  \end{enumerate}
\end{exo}

\begin{exo}{3.6.2}{Show that a set $X$ has cardinality $0$ if and only
    if $X$ is the empty set.}

  First suppose that $X = \emptyset$ and let's show that $\#X = 0$. By
  Definition 3.6.5, we must show that there exists a bijection between
  $X$ and the set $\{i \in \nn \, : \, 1 \leq i \leq 0\}$. It turns
  out that $X = \emptyset$ by hypothesis, and that $\{i \in \nn \, :
  \, 1 \leq i \leq 0\}$ is also equal to $\emptyset$. And, by Exercise
  3.3.3, we know that the empty function $f : \emptyset \to \emptyset$
  is bijective. Thus, we have indeed $\#X = 0$.

  Now suppose that we have a set $X$ such that $\#X = 0$, and let's
  show that $X = \emptyset$. If $\#X = 0$, we know that there exists a
  bijection from $\{i \in \nn \, : \, 1 \leq i \leq 0\}$ to $X$, i.e.
  from $\emptyset$ to $X$. Still by Exercise 3.3.3, a function $f :
  \emptyset \to X$ can be bijective if and only if $X = \emptyset$, so
  we are done.
\end{exo}

\bigskip
\begin{exo}{3.6.3}{Let $n$ be a natural number, and let
    $f : \{i \in \nn \, : \, 1 \leq i \leq n\} \to \nn$ be a
    function. Show that there exists a natural number $M$ such that
    $f(i) \leq M$ for all $1 \leq i \leq n$. Thus ﬁnite subsets of the
    natural numbers are bounded.}

  Let's induct on $n$.

  \begin{itemize}
  \item Let's take $n=1$ for the base case. $f$ is thus a function
    from the singleton $\{1\}$ to $\nn$. If we choose the natural
    number $M := f(1)$, we have indeed $f(i) \leq M$ for all
    $i \in \{1\}$.
  \item Now suppose inductively that the proposition is true for a
    natural number $n$, and let's show that it is still true for
    $n+1$.

    Let be
    $f : \{i \in \nn \, : \, 1 \leq i \leq n+1\} \to \nn$. By
    the induction hypothesis, we already know that there exists an $M$
    such that $f(i) \leq M$ for $1 \leq i \leq n$. Now let be
    $M' := M + f(n+1)$. Since $f(n+1)$ is a natural number, we have
    $M \leq M'$, so that $f(i) \leq M'$ for all $1 \leq i \leq n$ by
    transitivity.

    Also, we have $f(n+1) \leq f(n+1) + M = M'$ because $M$ is a
    natural number.

    Thus, we have found a natural number $M'$ such that $f(i) \leq M'$
    for all $i \in \intset{1}{n+1}$, as required. This closes the
    proof.
  \end{itemize}
\end{exo}

\begin{exo}{3.6.7}{Let $A$ and $B$ be sets. Let us say that $A$ has
    \emph{lesser or equal cardinality} to $B$ if there exists an
    injection $f : A \to B$ from $A$ to $B$. Show that if $A$ and $B$
    are ﬁnite sets, then $A$ has lesser or equal cardinality to $B$ if
    and only if $\#(A) \leq \#(B)$.}

  Since $A$ is finite, there exists a natural number $n$ such that $\#
  A = n$; and thus a bijection $g : \intset{1}{n} \to A$.

  Similarly, there exists $m \in \nn$ such that $\# B = m$; and thus a
  bijection $h : \intset{1}{m} \to B$.

  \begin{itemize}
  \item First suppose that $n \leq m$, and let's show that there
    exists a bijection $f : A \to B$. Let's define a function $f : A
    \to B$, such that for all $i \in \intset{1}{n}$, we have $f(g(i))
    = h(i)$. We claim that $f$ is injective. Indeed, let's suppose
    that we have $f(x) = f(x')$ for $x, x' \in A$. Since $g$ is
    bijective, there exists $i,j \in \intset{1}{n}$ such that $f(g(i))
    = f(g(j))$. By definition of $f$, this means that $h(i) = h(j)$.
    Since $h$ is also bijective, it means that $i = j$. And since
    $i=i$, we have $g(i) = g(j)$, and thus $x=x'$.

    We have showed that $f(x) = f(x')$ for all $x,x' \in A$, i.e.,
    that $f$ is injective, as required.
  \item Now suppose that there exists an injection $f : A \to B$, and
    let's show that $\# A \leq  \# B$. Obviously, $f$ is a bijection
    from $A$ to $f(A)$. It means that $f(A)$ and $A$ have the same
    cardinality, $n$.

    But $f(A) \subseteq B$, so that by Proposition 3.6.14(c), we have
    $\# B \geq \# (f(A)) = n$, which closes the proof.
  \end{itemize}
  
\end{exo}

\pagebreak
\section{Integers and rationals}
\begin{exo}{4.1.1}{Verify that the definition of equality on the
    integers is both reflexive and symmetric.}

  Recall the Definition 4.1.1 of equality on integers: two integers
  $a \minus b$ and $c \minus d$ are equal iff $a+d = c+b$. This
  defines a binary relation on $\zz$, denoted ``$=$''. Let's show that
  this relation is reflexive and symmetric.

  \begin{itemize}
  \item Reflexivity: let $a$ and $b$ be natural numbers, so that
    $a \minus b$ is an integer. We know that, on natural numbers,
    equality is reflexive, i.e. $a+b = a+b$. This equality means
    precisely that $a \minus b = a \minus b$.
  \item Symmetry: let $a, b, c, d$ be natural numbers. If $a \minus b
    = c \minus d$, do we also have $c \minus d = a \minus b$?

    \[
    \begin{array}{lrcl}
                          & a \minus b  &=& c \minus d \\
      \Longleftrightarrow & a+d &=& c+b \\
      \Longleftrightarrow & c+b &=& a+d \text{ (equality is symmetric
      on naturals})\\
      \Longleftrightarrow & c \minus d &=& a \minus b
    \end{array}
    \]
  \end{itemize}
\end{exo}

\begin{exo}{4.1.2}{Show that the definition of negation on the
    integers is well-defined in the sense that if
    $(a \minus b)=(a' \minus b')$, then
    $-(a \minus b)=-(a' \minus b')$ (so equal integers have equal
    negations).}

  Since $a \minus b = a' \minus b'$, we have $a+b' = a' + b$.

  Also, by Definition 4.1.4 of negation, we have:
  \begin{align*}
    -(a \minus b) &= b \minus a \\
    -(a' \minus b') &= b' \minus a' \\
  \end{align*}

  Then, we have successively:
  \begin{align*}
    b + a' &= a' + b \text{ (addition is commutative on naturals,
             Prop. 2.2.4)}\\
           &= a + b' \text{ (initial hypothesis)}\\
           &= b' + a \text{ (by commutativity on naturals once again)}
  \end{align*}
  and this equality $b+a' = b'+a$ precisely means that $b \minus a =
  b' \minus a'$, i.e. that $-(a \minus b) = -(a' \minus b')$.
\end{exo}

\bigskip
\begin{exo}{4.1.3}{Show that $(-1) \times a = -a$ for every integer
    $a$.}

  Since $a$ is an integer, there exist two natural numbers $n$ and $m$
  such that $a = m \minus n$.
  
  On the one hand, by Definition 4.1.4, $-a = n \minus m$.

  On the other hand, using once again Definition 4.1.4 and Definition
  4.1.2,
  \begin{align*}
    (-1) \times a &= (0 \minus 1) \times (m \minus n) \\
                  &= (0 \times m + 1 \times n) \minus (0 \times n + 1
                    \times m) \\
                  &= n \minus m
  \end{align*}

  Thus, we have indeed $(-1) \times a = -a$.
\end{exo}

\bigskip
\begin{exo}{4.1.4}{Prove the remaining identities in Proposition
    4.1.6.}

  Let $x = a \minus b$, $y = c \minus d$ and $z = e \minus f$ be three
  integers. Those identities are the following:

  \begin{enumerate}
  \item $x+y = y+x$, i.e., we must prove that addition is commutative
    on the integers. We have:
    \begin{align*}
      x+y &= (a \minus b) + (c \minus d) \\
          &= (a+c) \minus (b+d) \text{ (by Definition 4.1.2)} \\
          &= (c+a) \minus (d+b) \text{ (addition is commutative on
            naturals)} \\
          &= (c \minus d) + (a \minus b) \text{ (by Definition 4.1.2
            again)} \\
          &= y + x
    \end{align*}
  \item $(x+y)+z = x+(y+z)$, i.e. prove that addition is associative on the
    integers. This is a very similar proof, and this is a direct
    consequence of associativity of addition on the naturals.
  \item $x+0 = 0+x = x$. We have already showed that addition is
    commutative on the integers, so we just have to prove that $x+0=x$.
    \begin{align*}
      x + 0 &= (a \minus b) + (0 \minus 0) \\
            &= (a+0) \minus (b+0) \\
            &= a \minus b = x.
    \end{align*}
  \item $x + (-x) = (-x)+x = 0$. Once again, thanks to the previous
    result about commutativity, we just have to prove that $x + (-x) =
    0$.
    \begin{align*}
      x + (-x) &= (a \minus b) + (b \minus a) \text{ (by Definition
                 4.1.4)} \\
               &= (a+b) \minus (b+a) \text{ (by Definition
                 4.1.2)} \\
               &= (a+b) \minus (a+b) \text{ (addition is commutative on
                 naturals)} \\
               &= 0 \text{ (because $m \minus m = 0 \minus 0$ for all integer $m$)}
    \end{align*}
  \item $xy = yx$, i.e. multiplication is commutative on the integers.
    \begin{align*}
      xy &= (a \minus b) \times (c \minus d) \\
         &= (ac+bd) \minus (ad+bc) \text{ (by Definition 4.1.2)}\\
         &= (ca+db) \minus (da+cb) \text{ (multiplication is
           commutative on the naturals)}\\
         &= yx \text{ (by Definition 4.1.2)}
    \end{align*}
  \item $(xy)z = x(yz)$, i.e. multiplication is associative on the
    integers. This is actually the only identity proved in the main
    text by Terence Tao.
  \item $x1 = 1x = x$. The equality between the first two terms is a
    direct consequence of commutativity of multiplication on the
    integers. We just have to prove that $x1 = x$. And indeed, $x1 =
    (a \minus b) \times (1 \minus 0) = (a1 + b0) \minus (b1 + a0) = a
    \minus b = x$.
  \item $x(y+z) = xy+xz$, i.e. show distributivity on the integers. On
    the left side, we have:
    \begin{align*}
      x(y+z) &= (a \minus b)\left((c \minus d) + (e \minus f)\right)
      \\
             &= (a \minus b)\left((c+e) \minus (d+f) \right) \\
             &= \left(a(c+e) + b(d+f) \right) \minus \left(a(d+f) +
               b(c+e)\right) \\
             &= \left((ac+ae+bd+bf)\right) \minus
               \left((ad+af+bc+be)\right)
    \end{align*}
    and then on the left side:
    \begin{align*}
      xy+xz &= (a \minus b) (c \minus d) + (a \minus b)(e \minus f)\\
            &= \left((ac+bd) \minus (ad+bc)\right) + \left((ae+bf)
              \minus (af + be)\right)\\
            &= \left((ac+ae+bd+bf)\right) \minus \left((ad+af+bc+be)\right)
    \end{align*}
  \item $(y+z)x = yx + zx$. This latter identity is a direct
    consequence of commutativity of multiplication on the integers,
    and distributivity on the integers, both being already proved
    earlier in this exercise.
  \end{enumerate}  
\end{exo}

\begin{exo}{4.1.5}{Prove Proposition 4.1.8, i.e.: let $x$ and $y$ be
    integers such that $xy = 0$, then either $x=0$ or $y=0$ (or both).}

  We will use here Lemma 4.1.5 (trichotomy of integers, which says
  that any integer is either zero, or equal to a positive natural
  number, or the negation of a positive natural number), and Lemma
  2.3.3 (which provides an equivalent of Proposition 4.1.8 for natural
  numbers only). We will prove the proposition for (all) three
  possible cases: $x=0$, $x$ is a positive natural number, $-x$ is a
  positive natural number.

  $y$ will be considered as a fixed integer, $y = c \minus d$ with
  $c,d$ natural numbers.

  \begin{enumerate}
  \item First let's take the case $x=0$. There is nothing to prove
    here, the proposition is obviously true.
  \item Then let's take the case where $x$ is a positive natural
    number (and, consequently, is not equal to zero). In this case, as
    an integer, $x$ can be written $n \minus 0$ with $n$ a positive
    natural number.

    We have $xy = (n \minus 0) \times (c \minus d) = (nc +
    0d) \minus (nd + 0c) = nc \minus nd$.

    Thus, $xy = 0$ iff $nc \minus nd = 0 \minus 0$, and by Definition
    4.1.1, this means that $nc = nd$. But since all three $n,c,d$ are
    natural numbers, we can use the cancellation law for natural
    numbers and conclude that $c=d$.

    This means that $y = c \minus c = 0 \minus 0 = 0$. Thus, in this
    case, if $xy=0$ with $x$ non-zero, we have showed that $y$ is
    necessarily equal to 0.
  \item Finally, let's take the case where $x$ is the opposite of a
    positive natural number $n$, i.e. $x = 0 \minus n$. A very similar
    proof also leads to $c=d$, and to $y=0$.
  \end{enumerate}
\end{exo}

\begin{exo}{4.1.6}{Prove Corollary 4.1.9, i.e. if $a,b,c$ are integers
    such that $ac = bc$ and $c$ is non-zero, then $a=b$.}

  If $ac = bc$, then $ac + (-bc) = bc + (-bc) = 0$. Thus, $ac - bc =
  0$.

  Let's use the property of distributivity (Proposition 4.1.6): we
  obtain $(a-b)c = 0$. According to Proposition 4.1.8 (see also the
  previous exercise), this implies either $c=0$ or $a-b=0$. The first
  option ($c=0$) must be discarded since it does not fit the initial
  hypothesis. The only possibility is thus $a-b = 0$, and adding
  $b$ to both sides finally leads to $a=b$.
\end{exo}

\bigskip

\begin{exo}{4.1.7}{Prove Lemma 4.1.11.}
  
  The statements to prove are the following:

  \begin{enumerate}
  \item Show that $a>b$ if and only if $a-b$ is a positive natural
    number.

    First suppose that $a>b$. This means (Definition 4.1.10) that
    there exists a natural number $n$ such that $a = b+n$, and
    $a \neq b$. Then, we add to both sides the opposite of $b$, and we
    get $a + (-b) = b + n + (-b)$, i.e. $a-b = n$. In this latest
    equality, $n$ cannot be zero, otherwise we would have $a=b$, which
    is excluded. The first implication is proved.

    Then suppose that $a-b =n$ with $n$ a positive natural
    number. Adding $b$ to both sides leads to $a = b+n$, i.e. $a \geq
    b$. We cannot have $a=b$, because this would be a contradiction
    with the fact that $n \neq 0$. Thus, $a > b$.

  \item Show that addition preserves order, i.e. if $a>b$, then $a+c >
    b+c$.

    Suppose that $a>b$. According to the previous point, this
    means that $a-b = n$, with $n$ a positive natural number. Then, we
    get successively:
    \[
      \begin{array}{rcll}
      a &=& b+n &\text{ (by adding $b$ to both sides)}\\
      a+c &=& b+c+n &\text{ (by adding $c$ to both sides)}\\
      a + c -b -c &=& n &\text{ (by adding $(-b) + (-c)$ to both sides)}\\
      a+c - (b+c) &=& n &\text{ (by using the distributive law and
                    Exercise 4.1.3)}
      \end{array}
    \]
    Using again the previous point, since $(a+c) - (b+c)$ is equal to
    a positive natural number, we can conclude that $a+c > b+c$.
    
  \item Show that positive multiplication preserves order, i.e. if
    $a>b$ and $c$ is positive, then $ac > bc$.

    Since $a>b$, according to the first point of this exercise, we
    have $a-b=n$, with $n$ a positive natural number. According to the
    distributive law, $(a-b)c =ac-bc$. But we also have $(a-b)c = nc$,
    and $nc$ is a positive natural number (as product of two positive
    numbers, see Lemma 2.3.3). Thus, $ac-bc$ is equal to a positive
    number, which means that $ac > bc$.
    
  \item Show that negation reverses order, i.e. if $a>b$, then
    $-a<-b$.

    Here, we will need a small lemma, which says that for any natural
    number $n$, we have $n = -(-n)$. There are several ways to show
    this result: either by proving that $(-1) \times (-1) = 1$ and
    using Exercise 4.1.3, or simply by noting that $n + (n) = 0$ for
    all $n$, which means that $n$ is the opposite of $-n$ (i.e., $n =
    -(-n)$).

    Now this point is easy to prove. $a>b$ means that $a-b$ is a
    positive number, as shown earlier in this exercise. We want to
    prove that $-a < -b$, and proving this assertion requires to show
    that $-b -(-a)$ is a positive number. But $-b-(-a) = -b+a = a-b$,
    which is a positive natural number. Thus we are done.
    
  \item Show that order is transitive, i.e. if $a>b$ and $b>c$, then
    $a>c$.

    Still using the first point of this exercise, we have $a-b=n$ and
    $b-c=m$, with $n,m$ two positive natural numbers. We know that
    $n+m$ is positive as the sum of two positive numbers, thus
    $n+m = a-b+b-c = a-c$ is positive. This means that $a>c$.
    
  \item Show order trichotomy, i.e.: exactly one of the statements
    $a>b$, $a<b$, or $a=b$ is true.
    \begin{itemize}
    \item If $a=b$, then obviously (exactly) one of those statements is
    true.
    \item Now consider the case $a \neq b$, and let's show that we
    have either $a>b$ or $a<b$ (and cannot have both).

    Let's consider the integer $a-b$. By trichotomy of integers (Lemma
    4.1.5), we know that we have either $a-b=0$ (which is excluded
    here), or $a-b=n$ with $n$ positive, or $a-b = -n$ with $n$
    positive.

    If $a-b = n$, then $a>b$ according to the first point of this
    exercise. If $a-b = -n$, then $-n = -(a-b) = b-a$, thus $b>a$.

    Finally, we just have to show that we cannot have both $a>b$ and
    $b>a$ at the same time. If $a>b$, then the integer $a-b$ is
    positive. If $b>a$, then $b-a$ is positive, i.e. $-(b-a) = a-b$ is
    the opposite of a positive natural. Thus, $a-b$ is both positive
    and the opposite of a positive number, which is excluded by the
    trichotomy of integers.
    \end{itemize}
  \end{enumerate}
\end{exo}

\begin{exo}{4.1.8}{Show that the principle of induction (Axiom 2.5)
    does not apply directly to the integers. More precisely, give an
    example of a property $P(n)$ pertaining to an integer $n$ such
    that $P(0)$ is true, and that $P(n)$ implies $P(n{{+}\!{+}})$ for
    all integers $n$, but that $P(n)$ is not true for all integers
    $n$.}

  According to Lemma 4.1.5, an integer is either equal to 0, or equal
  to a positive natural number, or equal to the negation of a positive
  natural number.

  Let's define $P(n)$ as the property ``The integer $n$ is a natural
  number, i.e. is either equal to 0 or equal to a positive natural
  number''. Obviously, $P(0)$ is true. Furthermore, if $n$ is a
  natural number, then $\successor{n}$ is also a natural number (Axiom
  2.2), so that if $P(n)$ is true, then $P(\successor{n})$ is
  true. Thus, $P(n)$ matches the required condtions.

  However, $P(-1)$ is obviously false.
\end{exo}

\bigskip
\begin{exo}{4.2.1}{Show that the definition of equality for the
    rational numbers is reflexive, symmetric, and transitive.}

  This exercise ressembles Exercise 4.1.1, and the same approach
  applies. Recall the Definition 4.2.1: two rational numbers
  $a \quot b$ and $c \quot d$ are equal iff $ad=bc$. This defines a
  binary relation on $\qq$, denoted ``$=$''. Let's show that this
  relation is reflexive, symmetric and transitive.

  Hereafter, $a, b, c, d, e, f$ are integers (and $b,d,f$ are
  non-zero).

  \begin{itemize}
  \item Reflexivity: here we must prove that $a \quot b = a \quot
    b$. This is the case iff $ab = ba$, with is true because of
    (commutativity of multiplication on $\zz$ and) reflexivity of
    equality on $\zz$.
  \item Symmetry: here we must prove that if $a \quot b = c \quot d$,
    we also have $c \quot d = a \quot b$. We have successively:    
    \[\begin{array}{lrcl}
                          & a \quot b  &=& c \quot d \\
      \Longleftrightarrow & ad &=& bc \\
      \Longleftrightarrow & da &=& cb \text{ ($\times$ is commutative
                                   on $\zz$)}\\
      \Longleftrightarrow & cb &=& da \text{ ($=$ is symmetric
                                   on $\zz$)}\\
      \Longleftrightarrow & c \quot d &=& a \quot b
    \end{array}\]
  \item Transitivity: here we must prove that if $a \quot b = c \quot d$
    and $c \quot d = e \quot f$, then $a \quot b = e \quot f$. I.e.,
    we must prove that if $ad=bc$ and $cf = de$, then $af=be$.

    Let's multiply by $e$ both sides of the equality $ad=bc$: we get
    $ade = bce$. Since $de=cf$, we also get $acf=bce$.

    In this latest equality, using the cancellation law (Corollary
    4.1.9) for $c$ would lead to $af=be$, which would close the
    proof. However, unlike $b$, $d$ or $f$, the integer $c$ may be
    equal to 0, and in this case we cannot use the cancellation
    law. There are thus two different cases:
    \begin{itemize}
    \item If $c \neq 0$, we simply use the cancellation law: since
      $acf=bce$, then $af=be$, which means that
      $a \quot b = e \quot f$.
    \item If $c=0$, then $bc = 0$. But since $ad = bc$, we also have
      $ad = 0$, and we know that $d \neq 0$. According to Proposition
      4.1.8, this leads to $a=0$. A similar reasoning leads to
      $e=0$. Thus, $a=c=e=0$, and $0=af=be$, which means
      $a \quot b = e \quot f$.
    \end{itemize}
  \end{itemize}

\end{exo}

\begin{exo}{4.2.2}{Prove the remaining components of Lemma 4.2.3.}

  Let $a \quot b = a' \quot b'$ be two rationals; let $c \quot d = c'
  \quot d'$ be two rationals. The remaining claims are the following:

  \begin{itemize}
  \item Prove that $-(a' \quot b') = -(a \quot b)$. This equality
    holds iff $(-a') \quot b' = (-a) \quot b$, i.e. iff $(-a')b =
    b'(-a)$. We have successively:
    \begin{align*}
      (-a')b &= (-1)a'b \text{ (see Exercise 4.1.3)} \\
             &= (-1)ab' \text{ (because $a \quot b = a' \quot b'$)} \\
             &= (-a)b' \text{ (using Exercise 4.1.3 one again)}
    \end{align*}
    Thus we are done.
  \item Prove that
    $(a \quot b) \times (c \quot d) = (a' \quot b') \times (c \quot
    d)$. To prove this equality, we must show that
    $(ac) \quot (bd) = (a'c) \quot (b'd)$. By definition of equality
    between rationals, this holds iff $acb'd = bda'c$. Since
    $ab'=ba'$, the claim follows (using commutativity of
    multiplication on integers\footnote{This kind of precision about
      very basic properties of naturals and integers will not be
      mentioned anymore.}).
  \item Prove that $(a \quot b) \times (c \quot d) = (a \quot b)
    \times (c' \quot d')$. To prove this equality, we must show that
    $(ac) \quot (bd) = (ac') \quot (bd')$. By definition of equality
    between rationals, this holds iff $acbd' = bdac'$. Since
    $cd'=dc'$, the claim follows.
  \end{itemize}
\end{exo}

\begin{exo}{4.2.3}{Prove the remaining components of Proposition
    4.2.4.}

  Let $x = a \quot b$, $y = c \quot d$, and $z=e \quot f$ be rational
  numbers, with $a,c,e$ integers, and $b,d,f$ non-zero integers. The
  remaining claims are the following:

  \begin{enumerate}
  \item $x+y = y+x$, i.e. addition is commutative for the
    rationals.

    On the one hand, we have $x+y = a \quot b + c \quot d =
    (ad + bc) \quot bd$.

    On the other hand, $y + x = c \quot d + a \quot b = (cb + da)
    \quot db = (ad + bc) \quot bd$ using the commutativity of addition
    and multiplication on the integers. Thus, the two expressions are
    equal.
  \item $(x+y) + z = x + (y+z)$: already proved in the book.
  \item $x+0 = 0 + x = x$. By the first point of this exercise, we
    already know that $x+0 = 0+x$, so we have just to show that
    $x+0=x$. We have $x+0= a \quot b + 0 \quot 1 = (a1+b0) \quot (b1) = a
    \quot b = x$, which is the required result.
  \item $x + (-x) = (-x) + x = 0$. Once again, the part $x + (-x) =
    (-x) + x$ comes from the first point of this exercise, so we just
    have to prove that $x + (-x) = 0$. We have $x + (-x) = a \quot b +
    -(a \quot b) = a \quot b + (-a) \quot b = (ab - ba) \quot b^2 = 0
    \quot b^2$. But we know that $0 \quot m = 0 \quot 1 = 0$ for all non-zero
    integer $m$, since $0 \times 1 = m \times 0$. Thus, $x + (-x) = 0
    \quot b^2 = 0$, as required.
  \item $xy = yx$, i.e. multiplication is commutative on the
    rationals. Indeed, $xy = (a \quot b) \times (c \quot d) = (ac)
    \quot (bd)$ by definition. On the other hand, $yx = (c \quot d)
    \times (a \quot b) = (ca) \quot (db) = (ac) \quot (bd)$ by
    commutativity of multiplication on the integers. Thus, $xy = yx$.
  \item $(xy)z = x(yz)$, i.e. multiplication is associative on the
    rationals. We have $(xy)z = (ace) \quot (bdf) = x(yz)$ by
    associativity of multiplication on the integers.
  \item $x1 = 1x = x$. Once again, we already know that $x1 = 1x$,
    thanks to the fifth point of this exercise. So we just have to
    show that $x1 = x$. We have $x1 = (a \quot b) \times (1 \quot 1) =
    (a1) \quot (b1) = a \quot b = x$.
  \item $x(y+z) = xy+xz$, i.e. distributivity of multplication for the
    rationals. On the one hand, we have:
    \begin{align*}
      x(y+z) &= (a \quot b) (c \quot d + e \quot f) \\
             &= (a \quot b) ((cf + de) \quot (df)) \\
             &= (acf + ade) \quot (bdf)
    \end{align*}
    On the other hand\footnote{We use implicitly here the fact that
      $(nm) \quot n = m \quot 1$ for all integers $n,m$ with $m \neq
      0$, which is straightforward to prove.}:
    \begin{align*}
      xy + xz &= (a \quot b)(c \quot d) + (a \quot b)(e \quot f) \\
              &= (ac) \quot (bd) + (ae) \quot (bf) \\
              &= (acbf + bdae) \quot (b^2df) \\
              &= (acf + ade) \quot (bdf)
    \end{align*}
    Thus we have indeed $x(y+z) = xy+xz$.
  \item $(y+z)x = yx+zx$. This can be deduced immediately from
    commutativity of multiplication and the eighth point of this
    exercise.
  \item For all $x \neq 0$, $xx^{-1} = x^{-1}x = 1$. Once again, the
    part $xx^{-1} = x^{-1}x$ comes from the fifth point of this
    exercise, so that we just have have to show that $xx^{-1} = 1$.
    \begin{align*}
      x\inv{x} &= (a \quot b) \times (b \quot a) \\
               &= (ab) \quot (ba) \\
               &= 1 \quot 1 = 1
    \end{align*}
  \end{enumerate}
\end{exo}

\begin{exo}{4.2.4}{Prove Lemma 4.2.7. (trichotomy of rationals), i.e.,
    if $x$ is a rational number, then exactly one of the following
    three statements is true: (a) $x$ is equal to 0, (b) $x$ is a positive
    rational number, or (c) $x$ is a negative rational number.}

  Following the hint given by Terence Tao, we'll first prove that
  \emph{at least} one of those statements is true, and then that
  \emph{at most} one of them is true. Let be $x = a \quot b$, where
  $a$ is an integer and $b$ a non-zero integer.

  \begin{enumerate}
  \item Let's prove that at least one of those statements is
    true.

    First, an obvious case: if $a=0$, then $x = a \quot b = 0$,
    thus one of the statements is true. Now consider the case where $a
    \neq 0$. By the trichotomy of integers, $a$ can be either positive
    or negative. Similarly, $b$ can also be either positive or
    negative (it cannot be null, by definition). Thus, there are four
    main cases:

    \begin{itemize}
    \item $a>0$ and $b>0$. Here, by Definition 4.2.6, $x = a \quot b$
      is positive.
    \item $a>0$ and $b<0$. Here, $b = -m$, with $m$ a positive natural
      number. Thus, $x = a \quot (-m)$. But $a \quot (-m) = (-a) \quot
      m$ (this is easy to verify: $am = (-a)(-m)$). This means that $x
      = (-a) \quot m$, with both $a$ and $m$ positive, i.e. $x$ is
      negative.
    \item $a<0$ and $b>0$. Here, $x = a \quot b$ is negative by
      Definition 4.2.6.
    \item $a<0$ and $b<0$. Here, we can say that $a=-n$ and $b=-m$,
      with $n,m$ positive natural numbers. Thus, $x = (-n) \quot (-m)
      = n \quot m$ (once again, this latest equality is easy to
      verify). Thus, $x$ is positive.
    \end{itemize}
    Conclusion: if all four cases, at least one of the three
    properties is true.
  \item Now prove that at most one of those statements is true.
    \begin{itemize}
    \item Suppose, for the sake of contradiction, that we have both
      $x=0$ and $x$ positive. On the one hand, ``$x=a \quot b=0$''
      implies that $a=0$ (see Terence Tao's remark, page 83). On the
      other hand, ``$x$ is positive'' implies that $a>0$. So we would
      have both $a=0$ and $a$ positive, which is not compatible with
      the trichotomy of integers.
    \item A similar argument holds if we suppose both $x=0$ and $x$
      negative.
    \item Now suppose that we have both $x$ positive and $x$ negative,
      i.e. $x = c \quot d = (-n) \quot m$, with $c,d,n,m$ positive
      natural numbers. Thus, we should have $cm = (-n)d$. On the one
      hand, $cm$ is positive, as the multiplication of two positive
      natural numbers. On the other hand, $(-n)d = -(nd)$ is
      negative. The equality $cm = -nd$ is thus impossible.
    \end{itemize}
    Conclusion: all three statements are mutually exclusive.
  \end{enumerate}
\end{exo}

\begin{exo}{4.2.5}{Prove Proposition 4.2.9.}

  Let $x,y,z$ be rational numbers. This proposition includes the
  following statements:

  \begin{enumerate}
  \item Prove that exactly one of the three statements $x=y$, $x < y$, or $x > y$
    is true.

    This statement is very close to Lemma 4.2.7, proved in the
    previous exercise. Let's consider the rational number
    $x-y$. According to the trichotomy of rationals, this number can
    be either zero, positive or negative (exactly one of these
    statements is true).

    If $x-y = 0$, then $x=y$. If $x-y$ is positive, then $x>y$. And if
    $x-y$ is negative, then $x<y$. Thus, the order trichotomy is
    a direct consequence of the ordering of rationals.
  \item Prove that one has $x < y$ if and only if $y > x$.

    Since $x<y$, the rational number $x-y$ is negative, and can be
    written $(-a) \quot b$ for positive integers $a,b$. And since $x-y
    = -a \quot b$, we have $a \quot b = y-x$, i.e. $y-x$ is positive,
    i.e. $y>x$.
  \item Prove that if $x < y$ and $y < z$, then $x < z$.

    Since $x<y$, $x-y$ is negative. Similarly, $y-z$ is negative. This
    means that $x-y$ can be written $(-a) \quot b$, and $y-z$ can be
    written $(-c) \quot d$, with $a,b,c,d$ positive integers.

    On the one hand, their sum is $x-z$. On the other hand, their sum
    is $((-ad) + (-cb)) \quot (bd)$. This latest expression is a
    negative rational, thus we have $x<z$.
  \item Prove that if $x < y$, then $x+z < y+z$.

    Suppose that $x < y$. Thus, $x-y$ is negative. But we have, for
    any rational $z$, $x-y = (x+z) - (y+z)$, and thus this latter
    expression is also negative. This means that $x+z < y+z$.
  \item Prove that if $x < y$ and $z$ is positive, then $xz < yz$.

    Since $x<y$, the rational number $x-y$ is negative. Furthermore,
    we know (by Proposition 4.2.4) that $xz-yz = (x-y)z$. In the
    expression $(x-y)z$, $z$ is supposed to be positive and $x-y$ is
    negative, thus their product is negative\footnote{This is never
      explicitly mentioned in the book. However, using Exercise 4.1.3,
      we know that for every integer $a$, we have $-a = (-1) \times
      a$. So let's consider the product $n(-m)$ where $n,m$ are
      positive integers: this product is $(-1)nm = -(nm)$, and thus is
      negative.}. This means that $xz < yz$.
  \end{enumerate}
\end{exo}

\begin{exo}{4.2.6}{Show that if $x,y,z$ are rational numbers such that
    $x<y$ and $z$ is negative, then $xz>yz$.}

  If $x<y$, then $x-y$ is negative. Thus, $(x-y)z$ is the product of
  two negative rationals: it is a positive
  rational\footnote{Similarly, if $x$ and $y$ are negative, then $-x$
    and $-y$ are positive, and their product $(-x)(-y) =
    (-1)(-1)xy=xy$ is positive by definition. This can also be deduced
    from Proposition 4.2.9(e), by choosing $x=0$.}.

  But $(x-y)z = xz - yz$ by Proposition 4.2.4. And since we have
  showed that this number is positive, we have $xz>yz$.
  
  Note: in particular, this exercise says that if $x>y$, then $-x<-y$
  (with $z=-1$).
\end{exo}

\bigskip
\begin{exo}{4.3.1}{Prove Proposition 4.3.3.}

  Let $x,y,z$ be rational numbers. The statements to prove are the
  following:

  \begin{enumerate}[label=\emph{(\alph*)}]
    \item Show that $\abs{x} \geq 0$ for all $x$, and that $\abs{x} =
      0$ iff $x=0$.

      There are three cases:
      
      \begin{itemize}
      \item if $x=0$, then $\abs{x} := 0$, thus we have in particular
        $\abs{x} \geq 0$.
      \item if $x > 0$, then $\abs{x} := x$, thus $\abs{x} > 0$. And in
        particular, this means that $\abs{x} \geq 0$.
      \item if $x < 0$, then $\abs{x} := -x$, thus $\abs{x} > 0$. And
        in particular, $\abs{x} \geq 0$.
      \end{itemize}

      We can note that the only case where $\abs{x} = 0$ is when
      $x=0$. Thus, by trichotomy of rationals, $\abs{x} = 0$ iff
      $x=0$.
    \item Show that $\abs{x+y} \leq \abs{x} + \abs{y}$.

      \begin{itemize}
      \item If $x=0$ or $y=0$, this is immediate.
      \item If $x>0$ and $y>0$, $x+y$ is positive, thus
        $\abs{x+y} = x+y = \abs{x} + \abs{y}$.
      \item If $x<0$ and $y<0$, $x+y$ is negative, thus $\abs{x+y} =
        -(x+y) = -x-y$. On the other hand, $\abs{x} + \abs{y} = -x -y$.
      \item Finally, the case where $x$ and $y$ are of opposite
        signs. Say that $x$ is positive and $y$ negative, but they are
        exchangeable. On the one hand, $\abs{x} + \abs{y} = x-y >
        0$. On the other hand, $\abs{x+y}$ can be either equal to
        $x+y$ if $x+y>0$, i.e. if $x>-y$; or equal to $-x-y$ if
        $x+y<0$, i.e. if $x<-y$.

        In the first case, since $-y<0<y$ by hypothesis, we have
        $\abs{x+y} = x+y < x-y = \abs{x} + \abs{y}$.

        In the second case, since $-x < 0 < x$ by hypothesis, we have
        $\abs{x+y} = -x-y < x-y = \abs{x} + \abs{y}$.
      \end{itemize}
      Conclusion: in all cases, we have indeed $\abs{x+y} \leq \abs{x}
      + \abs{y}$.
    \item Show that $-y \leq x \leq y$ iff $y \geq \abs{x}$. (Thus, in
      particular, $-\abs{x} \leq x \leq \abs{x}$.)

      \begin{itemize}
      \item First suppose that $y \geq \abs{x}$. Note that, whatever
        could be the value of $x$, we have necessarily $y \geq 0$
        according to the first point of this exercise. Now we can
        split into three cases.

        If $x=0$ then $y \geq 0$ and the claim is immediate.

        If $x > 0$, then $\abs{x} = x$, and the part $y \geq x$ is
        immediate. Furthermore, the other part $-y \leq x$ is also
        immediate since $-y$ is negative and $x$ is positive.

        If $x < 0$, then $\abs{x} = -x$, thus we have $y \geq -x$,
        i.e. $-y \leq x$ according to Exercise 4.2.6. Additionally,
        the part $x \leq y$ is immediate since $x$ is negative and $y$
        is positive.
      \item Conversely, suppose that $-y \leq x \leq y$. If
        $x \geq 0$, then $\abs{x} = x$, thus the rightmost inequality
        gives $x = \abs{x} \leq y$. In the other case, if $x < 0$,
        then $\abs{x} = -x$. The leftmost inequality $-y \leq x$ leads
        (according to Exercise 4.2.6) to $y \geq -x$, i.e.
        $y \geq \abs{x}$.
      \end{itemize}
    \item Show that $\abs{xy} = \abs{x} \times \abs{y}$. (In particular,
      $\abs{-x} = \abs{x}$.)

      Once again, we can split into several cases, as in the second
      point of this exercise.

      \begin{itemize}
      \item If $x=0$ or $y=0$, both sides of the equality are zero
        (cf. the first point of this exercise), thus the claim is
        immediate.
      \item If $x>0$ and $y>0$, the product $xy$ is also
        positive. Thus, $\abs{xy} = xy$, and $\abs{x}\times \abs{y} =
        xy$, and the claim follows.
      \item If $x<0$ and $y<0$, then the product $xy$ is positive, and
        $\abs{xy} = xy$. On the other hand, $\abs{x} \times \abs{y} =
        (-x)(-y) = xy$, and the claim follows.
      \item If $x$ and $y$ are of opposite signs (say $x$ positive and
        $y$ negative, but they are exchangeable), then $xy$ is
        negative, and $\abs{xy} = -xy$. On the other hand, $\abs{x}
        \times \abs{y} = -xy$, thus the claim follows.
      \end{itemize}

    \item Show that $d(x,y) \leq 0$ for all $x,y$, and that $d(x,y) = 0$ iff $x=y$.
      
      We have $d(x,y) = \abs{x-y} \geq 0$ according to the first point
      of this exercise. Furthermore, still according to the first point, $d(x,y) =
      \abs{x-y} = 0$ iff $x-y = 0$, i.e. $x=y$.
    \item Show that $d(x,y) = d(y,x)$.
      
      We have $d(x,y) = \abs{x-y}$ and $d(y,x) = \abs{y-x}$ by
      definition. But $\abs{y-x} = \abs{-(x-y)} = \abs{x-y}$ according
      to the fourth point of this exercise.
    \item Show that $d(x,z) = d(x,y) + d(y,z)$.
      
      We have $d(x,z) = \abs{x-z} = \abs{(x-y) + (y-z)} \leq \abs{x-y} +
      \abs{y-z}$ according to the second point of this exercise. The
      claim follows.
    \end{enumerate}
\end{exo}

\begin{exo}{4.3.2}{Prove the remaining claims in Proposition 4.3.7.}

  Let $x,y,z,w$ be rational numbers.

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item If $x=y$, then $d(x,y)=0$ according to Proposition
    4.3.3(e). Thus, $d(x,y) \leq \epsilon$ for any positive number
    $\epsilon$.

    Conversely, suppose that $d(x,y) \leq \epsilon$ for any
    $\epsilon > 0$, and let's prove that $x=y$. Suppose, for the the
    sake of contradiction, that $x \neq y$; and let be
    $\epsilon = \abs{x-y}/2$. Since $x \neq y$, we have $\abs{x-y}>0$,
    thus $\epsilon$ is a positive number. Furthermore,
    $d(x,y) = \epsilon + \epsilon$, thus $d(x,y) > \epsilon$, which is
    a contradiction.
  \item This is a direct consequence from Proposition
    4.3.3(f). Indeed, since $d(x,y) = d(y,x)$, we obviously have
    $d(y,x) \leq \epsilon$ when $d(x,y) \leq \epsilon$.
  \item Suppose that $d(x,y) \leq \epsilon$ and $d(y,z) \leq
    \delta$. Thus, by triangle inequality, $d(x,z) \leq d(x,y) +
    d(y,z) \leq \epsilon + \delta$.
  \item Suppose that $d(x,y) \leq \epsilon$ and $d(z,w) \leq
    \delta$. Thus,
    \begin{align*}
      d(x+z, y+w) &= \abs{(x+z) - (y+w)}\\
                  &= \abs{(x-y) + (z-w)}\\
                  &\leq \abs{x-y} + \abs{z-w}\\
                  &\leq \epsilon + \delta
    \end{align*}
    which means that $x+z$ and $y+w$ are $(\epsilon+\delta)$-close.

    Similarly, $d(x-z, y-w) = \abs{(x-y)+(w-z)}$, and using just the
    symmetry of distance, we can conclude that $x-z$ and $y-w$ are
    $(\epsilon+\delta)$-close according to the previous result.
  \item This is clear: we have $d(x,y) \leq \epsilon < \epsilon'$.
  \item Since $d(x,y) \leq \epsilon$, we have
    $-\epsilon \leq y-x \leq \epsilon$. Similarly, we have
    $-\epsilon \leq z-x \leq \epsilon$.

    $y$ and $z$ are exchangeable here, so we can suppose that $y
    \leq w \leq z$. From this inequality, we can get $y-x \leq w-x
    \leq z-x$. Extending this with the former inequalities, we have:
    \[-\epsilon \leq y-x \leq w-x \leq z-x \leq \epsilon\] and in
    particular $-\epsilon \leq w-x \leq \epsilon$, which means
    $d(w,x) \leq \epsilon$.
  \item We have $d(x,y) = \abs{x-y} \leq \epsilon$. Since $z$ is
    positive, we have $\abs{z} > 0$, thus
    $\abs{x-y}\abs{z} \leq \epsilon \abs{z}$. But according to
    Proposition 4.3.3(d), $\abs{x-y}{z} = \abs{(x-y)z} =
    \abs{xz-yz}$. Thus, $\abs{xz-yz} \leq \epsilon \abs{z}$, i.e.,
    $xz$ and $yz$ are $\epsilon \abs{z}$-close.
  \end{enumerate}  
\end{exo}

\begin{exo}{4.3.3}{Prove Proposition 4.3.10.}
  
  Let $x$, $y$ be rationals, and $n$, $m$ be natural numbers. The
  claims to prove are the following (they are re-ordered and
  re-numbered here):

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Show that $x^n x^m = x^{n+m}$. We induct on $n$ while keeping
    $m$ fixed.
    
    For the base case $n=0$ , we have on the one hand $x^n x^m = x^0
    x^m = 1 \cdot x^m = x^m$. On the other hand, $x^{n+m} = x^{0+m} =
    x^m$. Thus, both sides are equal, and the base case is done.
    
    Now suppose that $x^n x^m = x^{n+m}$, and let's show that $x^{n+1}
    x^m = x^{(n+1)m}$. We have:
    \[
      \begin{array}{rcll}
        x^{n+1} x^m  &=& (x^n x)x^m & \text{ (by Definition 4.3.9)} \\
                     &=& x^n x^m x  & \text{ (by associativity and
                                      commutativity of multiplication)} \\
                     &=& x^{n+m} x  & \text{ (by induction hypothesis)} \\
                     &=& x^{n+m+1}  & \text{ (by Definition 4.3.9 once again)}
      \end{array}
  \]
  This closes the induction.

  \item Show that $(xy)^n = x^n y^n$. Let's induct on $n$. The base
    case $n=0$ is obvious, since both sides are equal to 1. Now
    suppose inductively that $(xy)^n = x^n y^n$. Thus we have:
    \[
      \begin{array}{rcll}
        (xy)^{n+1}  &=& (xy)^n (xy) & \text{ (by Definition 4.3.9)} \\
                    &=& x^n y^n xy & \text{ (by inductive
                                     hypothesis)}\\
                    &=& x^n x y^n y & \text{ (by commutativity of
                        multiplication)}\\
                    &=& x^{n+1} y^{n+1} & \text{ (by Definition 4.3.9
                                          once again)}
      \end{array}
    \]
    
  \item Show that $(x^n)^m = x^{nm}$. We induct on $n$ while keeping
    $m$ fixed.

    For the base case $n=0$, we have $(x^n)^m = 1^m = 1$, since $1^m =
    1$ for all natural number $m$\footnote{This can easily be proved
      by induction, which we'll not write formally here.}. On the
    other hand, $x^{nm} = x^{0m} = 1$. Thus, both sides are equal, and
    the base case is done.

    Now suppose inductively that $(x^n)^m = x^{nm}$. Then we have:
    \[
      \begin{array}{rcll}
        (x^{n+1})^m  &=& (x^nx)^m & \text{ (by Definition 4.3.9)} \\
                     &=& (x^{n})^m x^m & \text{ (proved in 2. from this
                                         exercise)}\\
                     &=& x^{nm} x^m & \text{ (by inductive
                                      hypothesis)} \\
                     &=& x^{nm+m} & \text{ (proved in 1. from this
                                    exercise)}\\
                     &=& x^{(n+1)m}
      \end{array}
    \]
    This closes the induction.
    
  \item Show that if $n>0$, then $x^n = 0$ iff $x=0$. For that, let's
    induct on $n$. Here the base case starts with $n=1$ since we
    suppose $n>0$. For $n=1$, $x^1 = x$, thus we obviously have $x^1=0
    \, \Leftrightarrow x=0$ since both objects are equal.

    Now suppose inductively that $x^n = 0$ iff $x=0$. We must show
    that $x^{n+1} = 0$ iff $x=0$. Here we'll need the following lemma:
    \begin{lem}Let $x,y$ be rational numbers. Then, if $xy=0$, we have
      either $x=0$ or $y=0$.
    \end{lem}
    \begin{proof}
      Let's denote $x = a \quot b$ and $y = c \quot d$. By Definition
      4.2.2, $xy = (ac) \quot (bd)$. Thus, since $xy = 0$, we have
      $ac=0$ (see Tao's remark p. 83). And, by Proposition 4.1.8, we
      have either $a=0$ or $c=0$. In the first case, this means that
      $x=0$; in the second case this means that $y=0$.
    \end{proof}
    Now go back to the main proof. First, if $x=0$, we have
    $x^{n+1} = x^n x = 0^n \times 0 = 0$. Conversely, if
    $x^{n+1} = 0$, then $x^n x = 0$. According to the previous lemma,
    this means that either $x^n =0$ or $x=0$. In the second case, we
    are done. In the first case, the induction hypothesis also allows
    to conclude that $x^n=0$. This closes the induction.

  \item Show that if $x \geq y \geq 0$, then $x^n \geq y^n \geq
    0$. Let's induct on $n$.

    For the base case $n=0$, $x^0 = y^0 = 1$. Thus in particular we
    have indeed $x^0 \geq y^0 \geq 0$.

    Now suppose inductively that $x^n \geq y^n \geq 0$, and show that
    $x^{n+1} \geq y^{n+1} \geq 0$. We start from $x^n \geq y^n \geq 0$
    and multiply all terms by $x$ (which preserves inequality since
    $x$ is supposed to be positive): we get
    $x^{n+1} \geq xy^n \geq 0$. If we start from $x \geq y \geq 0$ and
    multiply all terms by $y^n$ (which is also positive by induction
    hypothesis), we get $y^nx \geq y^{n+1} \geq 0$. Now combine all
    those inequalities:
    \[x^{n+1} \geq xy^n \geq y^{n+1} \geq 0\]
    This closes the induction.

  \item Show that $\abs{x^n} = \abs{x}^n$. Let's induct on $n$.

    For the base case $n=0$, we have $\abs{x^n} = \abs{x^0} = \abs{1} = 1$; and
    $\abs{x}^n = \abs{x}^0 = 1$. Thus both sides are equal, and the
    base case is done.

    Now suppose that $\abs{x^n} = \abs{x}^n$ and show that
    $\abs{x^{n+1}} = \abs{x}^{n+1}$. We have:
    \[
      \begin{array}{rcll}
        \abs{x^{n+1}} &=& \abs{x^n x} & \text{ (by Definition 4.3.9)} \\
                      &=& \abs{x^n} \cdot \abs{x} & \text{ (by
                                                    Proposition 4.3.3d)}\\
                      &=& \abs{x}^n \cdot \abs{x} & \text{ (by inductive
                                                    hypothesis)} \\
                      &=& \abs{x}^{n+1}
      \end{array}
    \]
    This closes the induction.
  \end{enumerate}
\end{exo}

\begin{exo}{4.3.4}{Prove Proposition 4.3.12.}

  This is essentially the same exercise as 4.3.3, but dealing with
  integer exponents (instead of natural exponents). The claims to
  prove are the following (and once again, they are re-labeled):
  
  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Prove that $x^nx^m = x^{n+m}$. Let's distinguish three cases:
    \begin{itemize}
    \item If $n, m \geq 0$, then this is simply Proposition 4.3.10(a).
    \item If $n, m < 0$, then $n=-p$ and $m=-q$ with $p,q$ positive
      natural numbers. Thus,
      $x^n x^m = (1/x^p) \cdot (1/x^q) = 1/(x^p x^q)$ by Definition
      4.2.2. But since $p,q$ are positive, this is also equal to
      $1/(x^{p+q})$ according to Proposition 4.3.10(a). This can also
      be written $x^{-(p+q)}$ by Definition 4.3.11, which is finally
      equal to $x^{n+m}$.
    \item If $n \geq 0$ and $m < 0$ (or inversely, since they are
      exchangeable), then $m = -q$ with $q$ a positive natural number.
      Thus, $x^n x^m = x^n \times (1 / x^q) = x^n / x^q$. We will
      (once again) split into two cases:
      \begin{itemize}
      \item if $n \geq -m$, i.e. if $n - q \geq 0$, then we can note
        that $x^{n-q} \cdot x^q = x^n$ according to Proposition
        4.3.10(a). Thus, let's multiply both sides of this equality by
        $x^{-q}$ to get $x^{n-q} = x^n x^{-q}$; which can be rewritten
        $x^{n+m} = x^n x^m$ as required.
      \item if $n < -m$, i.e. $q-n>0$, then we can note that
        $x^{q-n} x^n = x^q$ according to Proposition 4.3.10(a). Also,
        since $n-q < 0$, according to Definition 4.3.11, we have
        $x^{n-q} = 1 / x^{q-n}$. Let's multiply both sides by $1/x^n$,
        to get $x^{n-q} / x^n = 1 / (x^{q-n} x^n) = 1 / x^q =
        x^{-q}$. Finally, multiply both sides by $x^n$ to get
        $x^{n+m} = x^n x^m$.
      \end{itemize}
    \end{itemize}
  \item Prove that $(x^n)^m = x^{nm}$.
  \item Show that $(xy)^n = x^n y^n$. If $n \geq 0$, this is simply
    Proposition 4.3.10(a). So let's consider the case $n < 0$. In this
    case, $n = -p$, with $p$ a positive natural number. Thus we have
    successively:
    \[
      \begin{array}{rcll}
        (xy)^n &=& (xy)^{-p} &\\
               &=& 1 / (xy)^p & \text{ (by Definition 4.3.11)}\\
               &=& 1/(x^p y^p) & \text{ (Proposition 4.3.10(a))}\\
               &=& 1/(x^p) \, \times 1/(y^p) & \text{ (Definition
                                               4.2.2)} \\
               &=& x^{-p} \times y^{-p} & \text{ (by Definition
                                          4.3.11)}\\
               &=& x^n \times y^n &
      \end{array}
    \]
  \item Show that if $x \geq y > 0$, then $x^n \geq y^n > 0$ if $n$ is
    positive, and $0 < x^n \leq y^n$ if $n$ is negative.
    \begin{itemize}
    \item If $n > 0$, according to Proposition 4.3.10(c), we already
      have $x^n \geq y^n \geq 0$, so that we just have to show that
      the rightmost inequality is strict, i.e. that $y^n > 0$. To show
      that, we only need to prove $y^n \neq 0$. For the sake of
      contradiction, let's suppose that $y^n = 0$. Our starting
      hypothesis was $x \geq y > 0$, thus we know that $y \neq
      0$. According to Proposition 4.3.10(b), we can't have both
      $y \neq 0$ and $y^n = 0$, this is a contradiction. Thus, we
      indeed have $y^n \neq 0$, which shows the inequality
      $x^n \geq y^n > 0$ as required.
    \item If $n < 0$, this includes an important result, which is that
      taking the inverse reverses order. Indeed, let's begin by
      proving that if $x \geq y > 0$, then $1/x \leq 1/y$. Since both
      $x$ and $y$ are positive, their product $xy$ is also positive,
      and $1/(xy)$ is also positive. Following Proposition 4.2.9(e),
      we can multiply both sides of $x \geq y$ by $1/(xy)$ to get $1/y
      \geq 1/x$. Then, we immediately get $(1/y)^p \geq (1/x)^p$ for
      any positive number $p$ by Proposition 4.3.10(c), which can be
      rewritten $y^n \geq x^n$ with $n = -p$ negative. And since both
      numbers are positive (because $x$ and $y$ are positive), the
      claim follows.
    \end{itemize}
  \item Prove that if $x,y > 0$ and $n \neq 0$, then $x^n = y^n
    \Longrightarrow x = y$. Let's consider two cases: $n > 0$ and $n
    < 0$.

    First, if $n > 0$, suppose for the sake of contradiction that we
    have both $x^n = y^n$ and $x \neq y$. According to the trichotomy
    of rationals (Lemma 4.2.7), this last claim means that we have
    either $x > y$ or $y > x$. Since $x$ and $y$ are exchangeable, we
    only prove the first case here, $x > y$. In this case,
    Proposition 4.3.10(c) leads to $x^n > y^n$, which is obviously not
    compatible with our initial hypothesis $x^n = y^n$. A similar
    contradiction follows in the case $y > x$. Thus, both $x>y$ and
    $y>x$ are impossible, and the only possibility is $x=y$.

    Now, if $n <0$, then $n=-p$, with $p$ a positive natural
    number. Suppose that $x^n = y^n$, i.e. that $x^{-p} = y^{-p}$, or
    finally $1/x^p = 1/y^p$. From this last equality, by multiplying
    both sides by $x^py^p$, we get $y^p = x^p$. We are thus back in
    the previous case, and obtain $x=y$.
  \item Prove that $\abs{x^n} = \abs{x}^n$. If $n \geq 0$, this is
    simply Proposition 4.3.10(d). So let's consider the case $n <
    0$. We'll need a quick lemma:

    \begin{lem}
      For all rationals $x \neq 0$, we have $\abs{1/x} = 1 / \abs{x}$.
    \end{lem}

    \begin{proof}
      If $x>0$, there is nothing to show. If $x<0$, then $1/x$ is also
      negative\footnote{Formally, see Definition 4.2.6, and note that
        $a \quot (-b) = (-a) \quot b$ if $a$ and $b$ are positive
        integers.}. Thus, $1 / \abs{x} = 1 / (-x)$; and
      $\abs{1/x} = -(1/x)$. And we have clearly $1/(-x) = -(1/x)$
      because $1/(-x) + 1/x = 0$.
    \end{proof}

    In this case, $n = -p$, with $p$ a positive natural number. We
    have successively:
    \[
      \begin{array}{rcll}
        \abs{x^n} &=& \abs{x^{-p}} \\
                  &=&\abs{1/(x^p)} & \text{ (by Definition 4.3.11)} \\
                  &=& \abs{(1/x)^p} & \text{ (Proposition 4.3.12(a))} \\
                  &=& \abs{1/x}^p & \text{ (Proposition 4.3.10(d))} \\
                  &=& (\abs{1} / \abs{x})^p & \text{ (lemma introduced
                                              just above)} \\
                  &=& 1 / \abs{x}^p & \text{ (Proposition 4.3.12(a))}
        \\
                  &=& \abs{x}^{-p} & \text{ (Definition 4.3.11)} \\
                  &=& \abs{x}^n
      \end{array}
    \]
  \end{enumerate}
\end{exo}

\begin{exo}{4.3.5}{Prove that $2^N \geq N$ for all positive integers $N$.}

  Let's use induction on $N$. Since we only consider positive
  integers, we have here $N \geq 1$, and in particular, the base case
  starts at $N=1$.

  For the base case $N=1$, the assertion is true, since we have indeed
  $2^1 \geq 1$.

  Now suppose inductively that $2^N \geq N$, and show that $2^{N+1}
  \geq N+1$.  We have $2^{N+1} = 2^N \times 2 \geq N \times 2$ by
  induction hypothesis. But we know that $2N = N+N$ (recall Definition
  2.3.1 for instance), thus we can rewrite this as $2^{N+1} \geq
  N+N$. And since $N \geq 1$, we finally get $2^{N+1} \geq N+1$.
\end{exo}

\bigskip

\begin{exo}{4.4.1}{Prove Proposition 4.4.1.}

  We have to prove that, for any rational number $x$, there exists an
  integer $n$ such that $n \leq x < n+1$. Let's proceed through the
  following four steps:

  \begin{itemize}
  \item Suppose that $x \in \qq_+$. Thus, $x = a/b$, with $a$ and $b$
    natural numbers. According to Proposition 2.3.9, there exists
    $n, r \in \nn$ such that $a=bn+r$, with $0 \leq r < b$. By
    dividing all terms by $b$, this also means that
    $x = a/b = n + r/b$, with $0 \leq r/b < 1$.

    Since $0 \leq r/b < 1$, we have $n \leq n + r/b < n+1$, i.e. $n
    \leq x < n+1$, as required.    
  \item Now suppose that $x \in \qq_{-}^{\star}$. Consequently, $-x
    \in \qq_+$, and we are back in the previous case: there exists a
    natural number $n$ such that $n \leq -x < n+1$, i.e. $-n-1 < x
    \leq -n$. Now we have two possible cases:
    \begin{itemize}
    \item if $x=-n$, then let be $m = -n$. Thus, $m-1 < x \leq m$, and
      then $m \leq x < m+1$, as required.
    \item if $x \neq -n$, then let be $m = -n-1$. Thus,
      $m < x \leq m + 1$, i.e. $m-1 \leq x < m$. And by denoting
      $p=m-1$, we have $p \leq x < p+1$ as required.
    \end{itemize}
  \item Let's prove that this integer $n$ is unique. Suppose that we
    have two integers $m, n$ such that:
    \begin{align}
      n &\leq x < n+1 \label{intpartn} \\
      m &\leq x < m+1 \label{intpartm}
    \end{align}
    From (\ref{intpartm}), we also have $-m-1 < -x \leq -m$. And, by
    adding this inequality to (\ref{intpartn}), we get
    $n-m-1 < 0 < n-m+1$. The left-hand side says that $n < m+1$,
    i.e. that $n \leq m$ (recall Proposition 2.2.12 (e)). Similarly,
    the right-hand side says that $n > m-1$, i.e. that $n \geq
    m$. Thus, we have both $n \leq m$ and $n \geq m$, which means that
    $n=m$.
  \item Finally, this means in particular that there exists a natural
    number $N$ such that $N > x$. Indeed, if $x$ is negative, then
    $N=0$ is suitable; and if $x$ is positive, then $N$ is directly
    given by $N = \floor{x} + 1$.
  \end{itemize}  
\end{exo}

\begin{exo}{4.4.2}{A sequence $a_0, a_1, a_2, \ldots$ of numbers
    (natural numbers, integers, rationals, or reals) is said to be in
    \emph{infinite descent} if we have $a_n > a_{n+1}$ for all natural
    numbers $n$ (i.e., $a_0 > a_1 > a_2 > \ldots$).
  \begin{enumerate}
  \item Prove the principle of infinite descent: that it is not
    possible to have a sequence of natural numbers which is in
    infinite descent.
  \item Does the principle of infinite descent work if the sequence
    $a_1, a_2, a_3, \ldots$ is allowed to take integer values instead
    of natural number values? What about if it is allowed to take
    positive rational values instead of natural numbers? Explain.
  \end{enumerate}}

We follow the hints given by Terence Tao.

\begin{enumerate}
\item Assume for the sake of contradiction that we have a sequence of
  natural numbers $(a_n)$ which is in infinite descent. Let $k$ be a
  natural number, and $P_k$ be the property ``$a_n \geq k$ for all
  natural numbers $n$''. Let's induct on $k$.

  For the base case, $P_0$ is true since $a_n$ are natural numbers for
  all $n$, so that $a_n \geq 0$ for all $n$ by definition.

  Now let's suppose inductively that $P_k$ is true, i.e. that
  $a_0 > a_1 > a_2 > \ldots \geq k$. If we had $a_p = k$ for one given
  natural number $p$, then we would have $k = a_p > a_{p+1}$. But
  also, $a_{p+1} > a_{p+2} > ... > k$ by induction
  hypothesis. However, the inequality $k \geq a_{p+1} > k$ is a
  contradiction, so that $a_n \neq k$ for all $n$. Thus, $P_{k+1}$
  is also true: we have $a_n > k+1$ for all $n$.

  However, having $a_n > k$ for all natural numbers $k,n$ is a
  contradiction. Indeed, for $k = a_0$ and $n=1$, we have $a_1 > a_0$,
  which contradicts the fact that $(a_n)$ is in infinite descent.

  Thus, there are no such sequence of natural numbers.

\item A general note: to prove that the infinite descent principle
  does not work for integers or rationals, it is enough to find
  \emph{one} sequence of such numbers which is actually in infinite
  descent. Instead of a formal proof as in the previous case, a simple
  counterexample will do the trick.
  \begin{itemize}
  \item If the sequence $a_0 > a_1 > \ldots$ can take integer values,
    lets define the sequence by $a_n = -n$. By definition, we have
    $a_n > a_{n+1}$ for all natural number $n$ (since $-n > -n-1$, as
    a simple induction will show).
  \item If the sequence $a_0 > a_1 > \ldots$ can take rational values,
    lets define the sequence by $a_n = 1/n$. Thus, we have $a_n >
    a_{n+1}$ for all natural number $n$, since $1/n > 1/(n+1)$. (This
    can be shown as follows: $1/n - 1/(n+1) = 1 / (n(n+1)) > 0$.)
  \end{itemize}
\end{enumerate}

\end{exo}

\pagebreak
\section{The real numbers}
\begin{exo}{5.1.1}{Prove Lemma 5.1.15, i.e. that every Cauchy sequence
    is bounded.}

  Let $(a_n)_{n=1}^\infty$ be a Cauchy sequence.

  \begin{itemize}
  \item By definition 5.1.8, for every rational $\epsilon > 0$, there
    exists a natural number $N$ such that if $j,k \geq N$, then
    $d(a_j, a_k) \leq \epsilon$. In particular, let's rephrase this
    statement with the arbitrary value $\epsilon = 1$ (valid, since 1
    is a positive rational): there exists a natural number $N$ such
    that if $j,k \geq N$, then $|a_j - a_k| \leq 1$.
    
    Since $N \geq N$, we can take in particular $k=N$ to get yet another
    particular formulation: if $j \geq N$, then $|a_j - a_N| \leq 1$.
    
    According to Proposition 4.3.3(b), we have $|x+y| \leq |x| + |y|$ for
    all rationals $x,y$. Let's consider $x = a_j - a_N$ and $y = a_N$:
    this leads to $|a_j| \leq |a_j + a_N| + |a_N|$, i.e.
    $|a_j| - |a_N| \leq |a_j - a_N|$.
    
    Thus, this means that $|a_j| - |a_N| \leq |a_j - a_N| \leq 1$ as
    soon as $j \geq N$, i.e. that $|a_j| \leq 1 + |a_N|$ for
    $j \geq N$. We have bounded part of the infinite sequence.
    
  \item The other part is simply the finite sequence $a_0, a_1, \cdots,
    a_{N-1}$. By Lemma 5.1.14, this finite sequence is necessarily bounded
    by a rational number $M$.
    
  \item Finally, let's consider the rational number $B = 1 + |a_N| +
    M$. Since we have both $B \geq M$ and $B \geq 1 + |a_N|$, both the
    infinite sequence $(a_n)_{n=N}^\infty$ and the finite sequence
    $a_0, \cdots, a_{N-1}$ are bounded by $B$. Thus, the whole Cauchy
    sequence $(a_n)_{n=1}^\infty$ is bounded by $B$.
  \end{itemize}
  
\end{exo}

\begin{exo}{5.2.1}{Show that if $\seq{a_n}{1}$ and $\seq{b_n}{1}$ are
    eventually $\epsilon$-close, then $\seq{a_n}{1}$ is a Cauchy
    sequence if and only if $\seq{b_n}{1}$ is a Cauchy sequence.}

  First note that $\seq{a_n}{1}$ and $\seq{b_n}{1}$ are exchangeable
  here, so that showing only one direction (``if $\seq{a_n}{1}$ is
  Cauchy, then $\seq{b_n}{1}$ is Cauchy'') will be enough.

  Let be $\epsilon > 0$ a positive rational. Since $\seq{a_n}{1}$ and
  $\seq{b_n}{1}$ are eventually $\epsilon$-close, there exists a
  natural number $N_1$ such that $n \geq N_1 \Longrightarrow |a_n - b_n|
  \leq \frac{\epsilon}{3}$. Furthermore, since $\seq{a_n}{1}$ is a
  Cauchy sequence, there exists a natural number $N_2$ such that $j,k
  \geq N_2 \Longrightarrow |a_j - a_k| \leq \frac{\epsilon}{3}$.

  Let be $N = \max(N_1, N_2)$. If $j,k \geq N$, then we have:
  \begin{align*}
    |b_j - b_k| &= |b_j - a_j + a_j - a_k + a_k - b_k| \\
                &\leq |b_j - a_j| + |a_j - a_k| + |a_k - b_k| \text{
                  \; (by triangle inequality)}\\
                &\leq \frac{\epsilon}{3} + \frac{\epsilon}{3} +
                  \frac{\epsilon}{3} \\
                &\leq \epsilon
  \end{align*}

  which means that $\seq{b_n}{1}$ is a Cauchy sequence.
\end{exo}

\bigskip

\begin{exo}{5.2.2}{Let $\epsilon > 0$. Show that if $\seq{a_n}{1}$ and
  $\seq{b_n}{1}$ are eventually $\epsilon$-close, then $\seq{a_n}{1}$
  is bounded if and only if $\seq{b_n}{1}$ is bounded.}

As in the previous exercise, $\seq{a_n}{1}$ and $\seq{b_n}{1}$ are
exchangeable here, so that showing only one direction will be enough.

\begin{itemize}
\item Since $\seq{a_n}{1}$ is bounded, there exists a rational number
  $M_1$ such that $|a_n| \leq M_1$ for all natural $n$.
\item Since $\seq{a_n}{1}$ and $\seq{b_n}{1}$ are eventually
  $\epsilon$-close, there exists a positive natural number $N$ such
  that $n \geq N \Longrightarrow |a_n - b_n| \leq \epsilon$.
\item Let's decompose $\seq{b_n}{1}$ into a finite and an infinite
  part, and show that both parts are bounded.

  By Lemma 5.1.14, there exists a positive rational $M_2$ such that
  the finite sequence $b_0, \ldots, b_{N-1}$ is bounded by
  $M_2$.

  Furthermore, we know by triangle inequality that, if $n \geq N$, we
  have $|b_n| - |a_n| \leq |b_n - a_n| \leq \epsilon$. Consequently,
  $|b_n| \leq |a_n| + \epsilon \leq M_1 + \epsilon$.

  Finally, let be $M = M_1 + M_2 + \epsilon$: we have indeed $|b_n|
  \leq M$ for all natural $n$.
\end{itemize}
\end{exo}

\begin{exo}{5.3.1}{Prove Proposition 5.3.3.}

  The three laws of equality must be verified.
  
  \begin{enumerate}
  \item Reflexivity: let's prove that $x=x$. By Definition 5.3.1, we
    have $x=x$ if and only if $\formallimit{a_n} = \formallimit{a_n}$,
    i.e. if and only if $\seq{a_n}{1}$ and $\seq{a_n}{1}$ are
    equivalent Cauchy sequences. Let be $\epsilon > 0$ a positive
    rational, and let be $N = 1$. For all $n \geq N$, we have $|a_n -
    a_n| = 0 \leq \epsilon$, QED.
  \item Symmetry: let's suppose that $x=y$, and let's show that
    $y=x$. Let $\epsilon > 0$ be a positive rational. We have:
    \begin{align*}
      x = y & \Longrightarrow \text{$\seq{a_n}{1}$ and $\seq{b_n}{1}$ are
              equivalent Cauchy sequences} \\
            & \Longrightarrow \exists N \geq 1 \text{ such that } |a_n
              - b_n| \leq \epsilon \text{ for } n \geq N \\
            & \Longrightarrow \exists N \geq 1 \text{ such that } |b_n
              - a_n| \leq \epsilon \text{ for } n \geq N \\
            & \Longrightarrow \text{$\seq{b_n}{1}$ and $\seq{a_n}{1}$ are
              equivalent Cauchy sequences} \\
            & \Longrightarrow y = x
    \end{align*}
  \item Transitivity: if $x=y$ and $y=z$. Let be $\epsilon > 0$ a
    positive rational. Since $x=y$, there exists $N_1 \geq 1$ such
    that $|a_n - b_n| \leq \epsilon/2$ for $n \geq N_1$. Since $y=z$,
    there exists $N_2 \geq 1$ such that $|b_n - c_n| \leq \epsilon/2$
    for $n \geq N_2$. Thus, if $n \geq \max(N_1, N_2)$, $a_n$ and
    $b_n$ are $\epsilon-2$-close, and $b_n$ and $c_n$ are
    $\epsilon-2$-close. Thus, according to Proposition 4.3.7(c), $a_n$
    and $c_n$ are $\epsilon$-close, which means that $\seq{a_n}{1}$
    and $\seq{c_n}{1}$ are eventually $\epsilon$-close for all
    $\epsilon$, i.e. are equivalent Cauchy sequences. This closes the
    proof.
  \end{enumerate}
\end{exo}

\begin{exo}{5.3.2}{Prove Proposition 5.3.10.}

  To prove that $xy$ is a real number, we must show that
  $\seq{a_nb_n}{1}$ is a Cauchy sequence. Let $\epsilon > 0$ be a
  positive rational. We must show that there exists a natural number
  $N$ such that $j,k \geq N \Longrightarrow |a_jb_j - a_kb_k| \leq
  \epsilon$.

  We already know that:
  \begin{itemize}
  \item Since $\seq{a_n}{1}$ is a Cauchy sequence, it is bounded by
    a rational number $M_a$. Furthermore, there exists a natural
    number $N_a$ such that
    $j,k \geq N_a \Longrightarrow |a_j - a_k| \leq \frac{\epsilon}{2M_a}$.
  \item In a similar fashion, since $\seq{b_n}{1}$ is a Cauchy
    sequence, it is bounded by a rational number $M_b$. Furthermore,
    there exists a natural number $N_b$ such that
    $j,k \geq N_b \Longrightarrow |b_j - b_k| \leq \frac{\epsilon}{2M_b}$.
  \end{itemize}

  Now let's consider $N = \max(N_a, N_b)$. If $j,k \geq N$, we have:
  \begin{align*}
    |a_jb_j - a_kb_k| &= |a_jb_j - a_jb_k + a_jb_k - a_kb_k| \\
                      &\leq |a_j| \cdot |b_j-b_k| + |b_k| \cdot
                        |a_j-a_k| \\
                      &\leq M_a \frac{\epsilon}{2M_a} + M_b
                        \frac{\epsilon}{2M_b} \\
                      &\leq \epsilon
  \end{align*}
  
  This proves that $\seq{a_nb_n}{1}$ is a Cauchy sequence, as required.
\end{exo}

\bigskip
\begin{exo}{5.3.3}{Let $a, b$ be rational numbers. Show that $a=b$ if
    and only if $\formallimit{a} = \formallimit{b}$ (i.e., the Cauchy
    sequences $a,a,a,a,\ldots$ and $b,b,b,b, \ldots$ are equivalent if
    and only if $a=b$).}
  
  In what follows, we denote $\seq{a_n}{1}$ the constant sequence
  $a,a,a,\ldots$, and $\seq{b_n}{1}$ the constant sequence
  $b,b,b,\ldots$.

  \begin{itemize}
  \item If $a=b$, we have $|a-b| = 0$, i.e. $|a_n-b_n| = 0$ for all
    $n \geq 1$. Thus, $\seq{a_n}{1}$ and $\seq{b_n}{1}$ are
    $\epsilon$-close for all $\epsilon > 0$: they are equivalent Cauchy
    sequences. This means that $a=b$.
  \item If $\formallimit{a} = \formallimit{b}$, let's suppose (for the
    sake of contradiction) that $a \neq b$, and let's denote $\epsilon =
    \frac{|a-b|}{2}$. Since $a\neq b$, we have $\epsilon > 0$., and we
    also have $|a-b| > \epsilon$. In other words, for all $n \geq 1$, we
    have found an $\epsilon$ such that $|a_n-b_n| > \epsilon$: this is a
    contradiction with the fact that $\seq{a_n}{1}$ and  $\seq{b_n}{1}$
    are equivalent Cauchy sequences. Thus, $a=b$.
  \end{itemize}
\end{exo}

\begin{exo}{5.3.4}{Let $\seq{a_n}{1}$ be a sequence of rational
    numbers which is bounded. Let $\seq{b_n}{1}$ be another sequence
    of rational numbers which is equivalent to $\seq{a_n}{1}$. Show
    that $\seq{b_n}{1}$ is also bounded.}

  This exercise is actually very close to Exercise 5.2.2, and the same
  proof could apply. But for short: in Exercise 5.2.2, we showed that
  if two sequences $\seq{a_n}{1}$ and $\seq{b_n}{1}$ are
  $\epsilon$-close for a given positive rational $\epsilon$, then
  $\seq{a_n}{1}$ is bounded if and only if $\seq{b_n}{1}$ is
  bounded. Here, since $\seq{a_n}{1}$ and $\seq{b_n}{1}$ are
  equivalent, they are $\epsilon$-close for any positive $\epsilon$,
  and $\seq{a_n}{1}$ is bounded by hypothesis. Thus, $\seq{b_n}{1}$ is
  also bounded.
\end{exo}

\bigskip
\begin{exo}{5.3.5}{Show that $\formallimit{1/n} = 0$.}

  As a real number, by definition, $0$ is the formal limit of the
  constant sequence $0, 0, 0, \ldots$. Thus, we must show that
  $\formallimit{1/n} = \formallimit{0}$. Still by definition, we must
  prove that the sequence $\seq{1/n}{1}$ is equivalent to the sequence
  $\seq{0}{1}$. This can be achieved by proving that for all
  $\epsilon > 0$, there exists a natural $N \geq 1$ such that
  $n \geq N \Longrightarrow |1/n - 0| \leq \epsilon$, i.e. such that
  $n \geq 1/\epsilon$.

  By Proposition 4.4.1, there always exists a natural number $N$ such
  that $N > 1 / \epsilon$. Then, if $n \geq N$, we have the desired
  proprty, which closes the proof.
\end{exo}

\bigskip

\begin{exo}{5.4.1}{Prove Proposition 5.4.4.}
  
  Let $x$ be a real number.
  \begin{enumerate}
  \item First we show that at most one of the three statements above is
    true. To do this, we show that all those statements are ``pairwise
    incompatible''.
    \begin{itemize}
    \item First suppose that we have both $x = 0$ and $x$ positive. If
      $x = 0$, then $x$ is the formal limit of the sequence
      $0, 0, \ldots$. If $x$ is positive, then $x = \formallimit{a_n}$
      with $a_n \geq c$ for all $n$ and a certain rational $c > 0$. By
      Definition 5.3.1, this implies that both sequences
      $0, 0, \ldots$ and $\seq{a_n}{1}$ must be equivalent Cauchy
      sequences. I.e., for all $\epsilon > 0$, there must exist
      $M \geq 1$ such that $|a_n - 0| \leq \epsilon$ for all
      $n \geq M$. But taking $\epsilon = c/2$ leads to an obvious
      contradiction: we cannot have both $a_n \geq c$ and
      $|a_n| \leq c/2$ for all $n \geq M$. Thus, $x$ cannot be both
      zero and positive.
    \item A similar argument shows that $x$ cannot be both zero and
      negative.
    \item Finally, we show that $x$ cannot be both positive and
      negative. If $x$ is positive, then $x = \formallimit{a_n}$, with
      $\seq{a_n}{1}$ positively bounded away from $0$, i.e.
      $a_n \geq c$ for a certain rational $c > 0$. Similarly, if $x$
      is negative, then $x = \formallimit{b_n}$, with $\seq{b_n}{1}$
      negatively bounded away from $0$, i.e. $b_n \leq -d$, or
      $-b_n \geq d$, for a certain rational $d > 0$. But then,
      according to Definition 5.3.1, $\seq{a_n}{1}$ and $\seq{b_n}{1}$
      should be equivalent Cauchy sequences, i.e. for any rational
      $\epsilon > 0$, there should exist $M \geq 1$ such that
      $|a_n - b_n| \leq \epsilon$ for $n \geq M$. But since $a_n -b_n$
      is positive, this also can be written simply
      $a_n - b_n \leq \epsilon$. But since we have both $a_n \geq c$
      and $-b_n \geq d$, we know that $a_n - b_n \geq c+d$ for all
      natural numbers $n$, an obvious contradiction (take
      $\epsilon = (c+d)/2$).
    \item Thus, at most one of the three statements is true.
    \end{itemize}
  \item Next we show that at least one of the statements ``$x$ is
    zero'', ``$x$ is positive'', ``$x$ is negative'' is
    true. Actually, if $x=0$, we know that the statement ``$x$ is
    zero'' is true, so we're done. We can thus suppose that
    $x \neq 0$, and we have just to show that $x$ is either positive
    or negative.

    If $x \neq 0$, then by Lemma 5.3.14, $x = \formallimit{a_n}$ with
    $\seq{a_n}{1}$ bounded away from $0$, i.e. there exists $c > 0$
    such that $|a_n| \geq c$ for any natural $n$.

    It turns out that, for any Cauchy sequence $\seq{a_n}{1}$, if
    $\seq{a_n}{1}$ is bounded away from $0$, it is either eventually
    positively bounded away from $0$, or eventually negatively bounded
    away from $0$.

    Indeed, suppose that we have at the same time
    $|a_n| \geq \epsilon$ for all $n \geq N$, $a_k \geq \epsilon$ for
    some $k \geq N$ and $a_j \leq -\epsilon$ for some $j \geq
    N$. In such a case, we would have by triangular inequality:
    \[
      |a_k - a_j| \geq ||a_k| - |a_j|| \geq |\epsilon + \epsilon| \geq
      2\epsilon
    \]

    Thus, for all $N$, we could find two indexes $j,k \geq N$ such
    that $|a_k - a_j| > \epsilon$, which contradicts that fact that
    $\seq{a_n}{1}$ is a Cauchy sequence. Consequently, the Cauchy
    sequence $\seq{a_n}{1}$ is either eventually positively bounded
    away from 0, or eventually negatively bounded away from 0.

    In the first case, $x = \formallimit{a_n}$ is a positive
    number\footnote{Actually, we also have to define an equivalent
      sequence $\seq{b_n}{1}$ defined by $a_n = b_n$ if $n \geq N$ and
      $b_n = 1$ otherwise to get what we want.}, and in the second
    case it is a negative number.
  \end{enumerate}
\end{exo}

\begin{exo}{5.4.2}{Prove the remaining claims in Proposition 5.4.7.}

  Let $x, y, z$ be real numbers. Those claims are as follows:
  \begin{enumerate}[label=\emph{(\alph*)}]
  \item (Order trichotomy) Prove that exactly one of the three statements
    $x = y$, $x < y$, or $x > y$ is true.

    This is actually a simple rephrasing of the trichotomy of real
    numbers. Indeed, let's consider the real number $x-y$. According
    to Proposition 5.4.4, this real number is either null (in this
    case, $x = y$), positive (in this case, $x > y$) or negative (in
    this case, $x < y$).
  \item (Order is anti-symmetric) Prove that one has $x < y$ if and
    only if $y > x$.

    The following statements are equivalent:
    \begin{align*}
      x < y & \Longleftrightarrow x - y \text{ is positive} \\
            & \Longleftrightarrow -(x - y) \text{ is negative
              (Prop. 5.4.4)} \\
            & \Longleftrightarrow y - x  \text{ is negative} \\
            & \Longleftrightarrow y > x
    \end{align*}
  \item (Order is transitive) Prove that if $x < y$ and $y < z$, then
    $x < z$.

    Note that $x-z = (x-y) + (y-z)$. In this sum, both terms are
    negative, so that their sum is also negative (this can easily be
    deduced from Proposition 5.4.4). Thus, $x-z$ is negative, which
    closes the proof.
  \item (Addition preserves order) Prove that if $x < y$, then
    $x+z < y+z$.

    Note that if $x<y$, then $x-y$ is negative. Since $x-y = (x+z) -
    (y+z)$, we get the statement required.
  \item is already proven in the main text.
  \end{enumerate}
\end{exo}

\begin{exo}{5.4.4}{Show that for any positive real number $x > 0$
    there exists a positive integer $N$ such that $x > 1/N > 0$.}

  Let's use the archimedean property of the reals (Proposition
  5.4.13), with $\epsilon = 1$. Since $x$ is a positive real number,
  there exists a positive integer $N$ such that $Nx > 1$. Multiplying
  this inequality by the (positive\footnote{According to Proposition
    5.4.8.}) rational $1/N$ leads to $x > 1/N$. Since we have $1/N >
  0$, the claim follows.
\end{exo}

\bigskip
\begin{exo}{5.4.5}{Prove Proposition 5.4.14: Given any two real
    numbers $x < y$, we can find a rational number $q$ such that
    $x < q < y$.}

  Following the hint given by Terence Tao, we can make use of
  Exercise 5.4.4. Actually, we do have a positive real number here:
  since $x < y$, then $y - x$ is positive. Thus, according to Exercise
  5.4.4, we can find a positive integer $N$ such that $y-x > 1/N > 0$.

  Now let's multiply all terms by $N$. Since $N$ is positive, we get
  the following inequality: $Ny - Nx > 1 > 0$. Intuitively: since
  $Ny - Nx > 1$, we should be able to find explicitly an integer
  lying between them. Then, dividing by $N$ will provide the desired
  inequality.

  $Nx$ is a real number. According to Exercise 5.4.3, there exists an
  integer $n$ such that $n+1 > Nx \geq n$. In particular, since $Nx
  \geq n$, we also have $Nx + 1 \geq n + 1$.

  Thus, gathering all the inequalities we know:
  \begin{equation}
    Ny > Nx + 1 \geq n + 1 > Nx
  \end{equation}

  Then let's divide by $N$: we finally get $y > \frac{n+1}{N} > x$,
  which is the required property with $q = \frac{n+1}{N}$.
\end{exo}

\bigskip

\begin{exo}{5.4.6}{Let $x, y$ be real numbers and let $\epsilon > 0$
    be a positive real. Show that $|x-y| < \epsilon$ if and only if $y
    - \epsilon < x < y + \epsilon$; and that $|x-y| \leq \epsilon$ iff
    $y - \epsilon \leq x \leq y + \epsilon$.}
  
  We only give the proof for the strict version; the other one being
  totally similar.

  \begin{itemize}
  \item First suppose that $|x-y| < \epsilon$, and let's consider two
    cases depending on the sign of $x-y$.
    \begin{itemize}
    \item If $x-y \geq 0$, i.e. if $x \geq y$, then $|x-y| = x-y <
      \epsilon$ by hypothesis. If we add $y$ to both sides of this
      inequality, we get $x < y + \epsilon$, which is the first part
      of the required result. Furthermore, we know that $y \leq
      x$. And since $\epsilon$ is positive, we have $y - \epsilon < y
      \leq x$. Thus, by combining all those results, we finally get $y
      - \epsilon < y \leq x \leq y + \epsilon$, as required.
    \item If $x-y < 0$, i.e. if $x < y$, then $|x-y| = y-x < \epsilon$
      by hypothesis. This leads to $y - \epsilon < x$, which is the
      first part of the result. Also, since $x < y$, we have $x < y <
      y+\epsilon$. Combining all those results, we finally have $y -
      \epsilon < x < y < y + \epsilon$ as required.
    \end{itemize}
    
  \item Conversely, suppose that $y-\epsilon < x < y+\epsilon$. Adding
    $(-y)$ to each part leads to $-\epsilon < x-y < \epsilon$. There
    are now three cases depending on the sign of $x-y$:
    \begin{itemize}
    \item If $x-y > 0$, then $|x-y| = x-y < \epsilon$ as required.
    \item If $x-y < 0$, then $|x-y| = y-x$. But we know that
      $y-\epsilon < x$, i.e. $y-x < \epsilon$, as required.
    \item If $x-y = 0$, then by definition, $|x-y| = 0 < \epsilon$, as
      required.
    \end{itemize}
  \end{itemize}
\end{exo}

\begin{exo}{5.4.7}{Let $x$ and $y$ be real numbers. Show that
    $x \leq y + \epsilon$ for all real numbers $\epsilon > 0$ if and
    only if $x \leq y$. Show that $|x-y| \leq \epsilon$ for all real
    numbers $\epsilon > 0$ if and only if $x=y$.}

  \begin{enumerate}
  \item Let's prove the first statement. It is obvious that if
    $x \leq y$, then $x \leq y + \epsilon$ for all $\epsilon >
    0$. Let's thus prove the other direction. Let's use the
    contrapositive statement: suppose that $x > y$. Thus, $x - y >
    0$. Now let $\delta$ be a positive real number defined by
    $\delta = \frac{x - y}{2} > 0$. We have:
    \begin{align*}
      y + \delta &= y + \frac{x}{2} + \frac{x}{2} \\
                 &= \frac{x}{2} + \frac{y}{2} \\
                 &< \frac{x}{2} + \frac{x}{2} = x
    \end{align*}
    Thus, if $x > y$, there exists $\delta > 0$ such that $x > y
    +\delta$. Using the contrapositive, we conclude that if $x \leq y
    + \epsilon$ for all $\epsilon > 0$, then $x \leq y$.
  \item The second statement has a very similar proof. Once again, it
    is obvious that if $x=y$, then $|x-y| \leq \epsilon$, since we
    have $|x-y|=0$. For the other direction, let's use the
    contrapositive once again, and suppose that $x \neq y$. Thus,
    $|x-y| > 0$, and in particular, $|x-y| > \frac{|x-y|}{2} >
    0$. Consequently, if $x\neq y$, there exists $\delta =
    \frac{|x-y|}{2} > 0$ such that $|x-y| > \delta$. The
    contrapositive means that if $|x-y| \leq \epsilon$ for all
    $\epsilon > 0$, then $x=y$, as required.
  \end{enumerate}
\end{exo}

\begin{exo}{5.4.8}{Let $\seq{a_n}{1}$ be a Cauchy sequence of
    rationals, and let $x$ be a real number. Show that if $a_n \leq x$
    for all $n \geq 1$, then $\formallimit{a_n} \leq x$. Similarly,
    show that if $a_n \geq x$ for all $n \geq 1$, then
    $\formallimit{a_n} \geq x$.}

  Suppose, for the sake of contradiction, that we have both
  $a_n \leq x$ for all $n \geq 1$ and $\formallimit{a_n} > x$. Then,
  according to Proposition 5.4.14, there exists a rational $q$ such
  that $x < q < \formallimit{a_n}$. We have thus $a_n \leq x < q$ for
  all $n \geq 1$. According to Corollary 5.4.10 with the constant
  sequence of rationals $\seq{q_n} := q$, we should have
  $\formallimit{a_n} \leq q$.

  Thus, we have both $\formallimit{a_n} \leq q$ and $x < q <
  \formallimit{a_n}$, which is a contradiction and closes the proof.
\end{exo}

\bigskip
\begin{exo}{5.5.1}{Let $E$ be a subset of the real numbers $\rr$, and
    suppose that $E$ has a least upper bound $M$ which is a real
    number, i.e., $M = \sup(E)$. Let $-E$ be the set $-E := \{-x : x
    \in E\}$. Show that $-M$ is the greatest lower bound of $-E$,
    i.e., $-M = \inf(-E)$.}

  According to the definition of the greatest lower bound, we have two
  separate things to show: first, that $-M$ is a lower bound for $-E$,
  and second, that any other lower bound for $-E$ is inferior to $-M$.

  \begin{enumerate}
  \item Let $z$ be an element of $-E$. By definition, we have $z = -x$
    for some $x \in E$. Since $x \in E$, we have $x \leq M$, i.e. $z =
    -x \geq -M$. This means that $-M$ is a lower bound for $-E$.
  \item Let be $-A$ another lower bound for $-E$, and show that
    $-A \geq -M$. Let be $x \in E$. Thus, we have $-x \in -E$,
    and by definition, $-x \geq -A$. This can also be written $x \leq
    A$, meaning that $A$ is an upper bound for $E$. But by definition
    of the least upper bound $M$, we have $A \leq M$, i.e. $-A \geq
    -M$ as required: this closes the proof.
  \end{enumerate}
\end{exo}

\begin{exo}{5.5.2}{Let $E$ be a non-empty subset of $\rr$, let
    $n \geq 1$ be an integer, and let $L < K$ be integers. Suppose
    $K/n$ is an upper bound for $E$, but that $L/n$ is not an upper
    bound for $E$. Without using Theorem 5.5.9, show that there exists
    an integer $L < m \leq K$ such that $m/n$ is an upper bound for
    $E$, but that $(m-1)/n$ is not an upper bound for $E$. (Hint:
    prove by contradiction, and use induction.)}

  This is not an easy exercise, so that we begin by an informal
  draft of the proof. Tao's advice is to prove by contradiction,
  i.e. to suppose that the following statement holds:
  
  $(\mathcal{H})$: there exists no integer $m$ such that
  $L < m \leq K$, where $m/n$ is an upper bound for $E$, but
  $\frac{m-1}{n}$ is not.

  What would be the contradiction if we accept this fact? Let's
  proceed by ``descending induction''. Let's start with $m = K$: we
  already know that $K/n$ is an upper bound, thus according to
  $(\mathcal{H})$, $(K-1)/n$ is necessarily also an upper bound. Now
  let's continue with $m = K-1$: we can see that, necessarily,
  $(K-2)/n$ should also be an upper bound. And so on, until we finally
  reach (after $K-L-1$ steps) $m = L+1$, which will be still supposed
  to be an upper bound at this stage; but according to
  $(\mathcal{H})$, $L/n$ should also be an upper bound, which would be
  a contradiction with the fundamental assumption of this exercise.

  Thus, we have to combine, in some way, an induction reasoning with
  this hypothesis $(\mathcal{H})$ that we would like to reject.

  Actually, if we suppose that $(\mathcal{H})$ is true, we can show by
  induction that for any natural $j$, $(K-j)/n$ is an upper bound for
  $E$:

  \begin{itemize}
  \item The base case $j = 0$ is straightforward: we already know that
    $K/n$ is an upper bound.
  \item Now let's suppose inductively that $(K-j) / n$ is an upper
    bound, and let's show that $(K-j-1) / n$ is also an upper
    bound. We know that $L/n$ is not an upper bound, so there must
    exist some $x_0 \in E$ such that $x_0 > L/n$. But since
    $(K-j) / n$ is an upper bound, we have the following inequalities:
    $L/n < x_0 \leq (K-j) / n \leq K/n$. In particular, this means
    that $L < K-j$; and this also means that $L < K-j \leq K$. Thus,
    we also have necessarily $(K-j-1) / n$ as an upper bound,
    otherwise the integer $(K-j)$ would be a contradiction for
    $(\mathcal{H})$. This closes the induction.
  \end{itemize}

  Now the contradiction appears formally: take the (positive) natural
  number $K-L$, and apply the previous statement proved by
  induction. We should have $(K - (K-L)) / n = L/n$ as an upper bound
  for $E$, which is a contradiction with the main assumption of this
  exercise.
\end{exo}

\bigskip
\begin{exo}{5.5.3}{Let $E$ be a non-empty subset of $\rr$, let
    $n \geq 1$ be an integer, and let $m, m'$ be integers with the
    properties that $m/n$ and $m'/n$ are upper bounds for $E$, but
    $(m-1)/n$ and $(m'-1)/n$ are not upper bounds for $E$. Show that
    $m = m'$. This shows that the integer $m$ constructed in Exercise
    5.5.2 is unique.}

  We will show successively that $m' \leq m$ and $m \leq m'$, which
  will imply that $m = m'$.

  \begin{itemize}
  \item Since $(m-1) / n$ is not an upper bound for $E$, there exists
    $x_0 \in E$ such that:
    \begin{equation}
      \label{eq:x0gm1}
      x_0 > (m-1) / n
    \end{equation}
  \item But since $x_0 \in E$ and $m'/n$ is an upper bound, we have actually:
    \begin{equation}
      \label{eq:x0lm2}
      (m-1) / n < x_0 \leq m'/n
    \end{equation}
  \item Similarly, since $(m'-1) / n$ is not an upper bound for $E$,
    there exists $x_1 \in E$ such that:
    \begin{equation}
      \label{eq:x1gm2}
      x_1 > (m'-1) / n
    \end{equation}
  \item But since $x_1 \in E$ and $m/n$ is an upper bound, we have actually:
    \begin{equation}
      \label{eq:x1lm1}
      (m'-1) / n < x_1 \leq m/n
    \end{equation}
  \item Thus, combining \eqref{eq:x0lm2} and \eqref{eq:x1lm1}, we have
    both $m' - 1 < m$ and $m-1 < m'$. But $m$ and $m'$ are integers:
    recall that for integers, $a - 1 < b$ and $a \leq b$ are equivalent
    (see for instance Proposition 2.2.12 for the naturals). Thus we
    have both $m' \leq m$ and $m \leq m'$, as required.
  \end{itemize}
\end{exo}

\begin{exo}{5.5.4}{Let $q_1, q_2, q_3, \ldots$ be a sequence of
    rational numbers with the property that $|q_n - q_{n'}| \leq 1/M$
    whenever $M \geq 1$ is an integer and $n, n' \geq M$. Show that
    $q_1, q_2, q_3, \ldots$ is a Cauchy sequence. Furthermore, if $S
    := \formallimit{q_n}$, show that $|q_M - S| \leq 1/M$ for every $M
    \geq 1$. (Hint: use Exercise 5.4.8.)}

  \begin{enumerate}
  \item Let $\epsilon > 0$ be a positive rational number. To show that
    $\seq{q_n}{1}$ is a Cauchy sequence, we must prove that there exists  a
    natural number $N \geq 1$ such that $n, n' \geq N \Longrightarrow
    |q_n - q_{n'}| \leq \epsilon$.

    Let's apply the archimedean property\footnote{This has actually
      previously been shown in Exercise 5.4.4.}: since $1$ and
    $\epsilon$ are both positive real numbers, there exists a natural
    number $M$ such that $M \epsilon \geq 1$, i.e. such that $1/M \leq
    \epsilon$.

    Thus, for a given value of $\epsilon$, taking this natural number
    $M$ provides the required result. Indeed, if $n, n' \geq M$, we
    have $|q_n - q_{n'}| \leq 1/M$ by initial hypothesis, and $1/M
    \leq \epsilon$ by archimedean property. Thus $|q_n - q_{n'}| \leq
    \epsilon$, as required.
  \item Let be $S = \formallimit{q_n}$. We want to show that $|q_M -
    S| \leq 1/M$ for all $M \geq 1$.

    Recall that $|q_n - q_{n'}| \leq 1/M$ for any $n, n' \geq M$ by
    initial hypothesis. By fixing $n' := M$ to a given value, we get
    in particular:
    \begin{equation}
      \label{eq:554_fix_n}
      \forall n \geq M \geq 1, \; \; \; \; |q_n - q_{M}| \leq \frac{1}{M}
    \end{equation}

    This is equivalent to:
    \begin{equation}
      \label{eq:554_encadrement_qn}
      \forall n \geq M \geq 1, \; \; \; \; - \frac{1}{M} + q_M \leq q_n
      \leq \frac{1}{M} + q_M
    \end{equation}

    At this point, we cannot immediately apply the insight from
    Exercise 5.4.8 because of this ``$n \geq M \geq 1$'' part (we
    would like to have this property for ``$n \geq 1$'' instead). We
    can overcome this difficulty by defining a new ``instrumental''
    sequence $\seq{a_n}{1}$:
    \begin{equation}
      \label{eq:554_an}
      a_n = \left\{
        \begin{array}{lr}
          q_M & \text{ if } n \leq M \\
          q_n & \text{ if } n > M \\
        \end{array}
      \right.
    \end{equation}
    The sequences $\seq{a_n}{1}$ and $\seq{q_n}{1}$ are equivalent
    since they are eventually equal. Thus,
    $\formallimit{a_n} = \formallimit{q_n}$ by definition of a real
    number.

    And this time, we can adapt the insight from
    \eqref{eq:554_encadrement_qn} by removing the problematic ``$n
    \geq M$" part: we have actually, for all $n \geq 1$,

    \begin{equation}
      \label{eq:554_encadrement_an}
      \forall n \geq M \geq 1, \; \; \; \; - \frac{1}{M} + q_M \leq a_n
      \leq \frac{1}{M} + q_M
    \end{equation}
    so that, according to Exercise 5.4.8, we have $-1/M + q_M \leq S
    \leq 1/M + q_M$, i.e. $|q_M - S| \leq 1/M$.
    
    This is valid for any given $M \geq 1$, and thus closes the proof.
  \end{enumerate}
\end{exo}

\begin{exo}{5.5.5}{Establish an analogue of Proposition 5.4.14, in
    which ``rational'' is replaced by ``irrational''.}

  We have to prove that there exists an irrational number $s$ between
  any real numbers $x, y$. Actually, we only know one concrete example
  of irrational number so far in Tao's text: the number $\sqrt{2}$
  (see Proposition 4.4.4). We thus should use it in this proof.

  Let be $x, y$ two real numbers, and consider the two real numbers $x
  + \sqrt{2}$ and $y + \sqrt{2}$. According to Proposition 5.4.14,
  there exists a rational number $q$ such that $x + \sqrt{2} < q < y +
  \sqrt{2}$; i.e. $x < q - \sqrt{2} < y$.

  But it is easy to show that $q - \sqrt{2}$ cannot be a rational
  number: if it was a rational, then we would have $q - \sqrt{2} =
  q'$, with $q'$ a rational number. And then, we would have $\sqrt{2}
  = q - q' \in \qq$, which would contradict Proposition 4.4.4.

  Thus we can indeed construct an irrational number between any pair
  of real numbers $x,y$.
\end{exo}

\bigskip
\begin{exo}{5.6.1}{Prove Lemma 5.6.6. (Hints: review the proof of
    Proposition 5.5.12; proofs by contradiction will be useful.)}

  The claims to prove are:

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item If $y = x^{1/n}$, then $y^n = x$.

    To prove this one, we can basically go back to Proposition 5.5.12
    and adapt its proof, as suggested by Terence Tao. The general
    sketch is as follows: by Definition 5.6.4, we have
    $y := \sup \{z \in \rr \, | \, z \geq 0, z^n \leq x \}$. We should
    show that both the assertions $y^n > x$ and $y^n < x$ lead to
    contradictions with this definition. What could be such
    contradictions? For instance, it could be the fact that there
    exists a greater number than $y$ in the set
    $\{z \in \rr \, | \, z \geq 0, z^n \leq x \}$, i.e. that $y$ is
    \emph{not} an upper bound. To show that, we must find a small
    number $\zeta > 0$ such that
    $(y+\zeta) \in \{z \in \rr \, | \, z \geq 0, z^n \leq x \}$, or in
    other words, $(y + \zeta)^n \leq x$. But another possible
    contradiction could be to show that $y$ is an upper bound but not
    the \emph{least} upper bound, i.e. that there exists a small
    number $0 < \epsilon < 1$ such that $y - \epsilon$ is also an
    upper bound of the set
    $\{z \in \rr \, | \, z \geq 0, z^n \leq x \}$.

    Starting with each of the two hypotheses $y^n > x$ and $y^n < x$,
    we'll try to obtain one of these two contradictions.

    \begin{itemize}
    \item First suppose that we have $y^n < x$. Here we will refrain
      from using the binomial theorem in the proof, but we will use it
      as an intuition. Let be a small real number $0 < \epsilon <
      1$. First, we will show that if $y^n < x$, then we can find a
      real number $M > 0$ such that
      $(y + \epsilon)^n \leq y^n + M\epsilon$. This would be easiest
      with the binomial theorem, but it can also by shown by
      induction. Indeed, the base case $n=1$ is obvious, since $M=1$
      is okay. Now, let's suppose inductively that there exists a
      natural number $M$ such that we have
      $(y + \epsilon)^n \leq y^n + M \epsilon$. Thus:
      \begin{align*}
        (y + \epsilon)^{n+1} &\leq (y+\epsilon) (y^n + M\epsilon) \\
                             &\leq y^{n+1} + \epsilon(My + y^n +
                               M\epsilon) \\
                             &\leq y^{n+1} + \epsilon \underbrace{(My + y^n +
                               M)}_{:= M'} \text{ (because $\epsilon < 1$)}
      \end{align*}
      i.e. there exists also a natural number $M'$ such that
      $(y + \epsilon)^{n+1} \leq y^{n+1} + M' \epsilon$, which closes
      the induction. And thus, we have:
      $(y + \epsilon)^n \leq y^n + M\epsilon < y^n < x$, for some
      $\epsilon > 0$. This means that $y$ is no longer the supremum of
      the set $\{z \in \rr \, | \, z \geq 0, z^n \leq x \}$, which
      contradicts our initial hypothesis. Thus, $y^n < x$ leads to a
      contradiction.
    \item Then suppose that we have $y^n > x$. A similar approach
      applies. Let $0 < \epsilon < 1$ be a small number. Although not
      detailed here, it is now quite easy to show in a similar fashion
      that there exists a real number $M$ such that
      $(y - \epsilon)^n \geq y^n - M\epsilon$. But since $y^n > x$
      (strictly), we know that there exists a small number $\zeta > 0$
      such that $y^n > y^n - \zeta > x$. If we choose $\epsilon$ so
      that we have $M\epsilon = \zeta$, then we get $(y - \epsilon)^n
      > x$. This means that there exists a smaller number than $y$
      which is also an upper bound for $\{z \in \rr \, | \, z \geq 0,
      z^n \leq x \}$, which contradicts the definition of $y$ as the
      supremum of this set.
    \end{itemize}
    Thus, both the statements $y^n > x$ and $y^n < x$ are impossible,
    which allows us to conclude that $y^n = x$, as required.

    Note that, in other words, we've just showed that for any
    non-negative real $x$, we have:
    \begin{equation}
      \label{eq:566a}
      \left(x^{1/n}\right)^n = x
    \end{equation}
    and this is thus something we can use in the next steps.
  \item Conversely, if $y^n=x$, then $y = x^{1/n}$. (Additional hint:
    use the previous result, and Proposition 4.3.12.)

    Suppose that we have $y^n = x$. Since the $n$-th root is
    well-defined, the $n$-th roots of two equal numbers are also
    equal, i.e. $\left(y^n \right)^{1/n} = x^{1/n}$. Now we can use
    the insight from equation \eqref{eq:566a}. In one hand, we have
    $\left[\left(y^n \right)^{1/n}\right]^n = y^n$; and this is equal
    to $\left(x^{1/n}\right)^n$. But according to Proposition 4.3.12
    (and its counterpart for the real numbers), the equality $y^n =
    \left(x^{1/n}\right)^n$ implies $y = x^{1/n}$ as required.

    Note that, in other words, we've just showed that for any
    non-negative real $x$, we have:
    \begin{equation}
      \label{eq:566b}
      \left(x^n\right)^{1/n} = x
    \end{equation}
  \item $x^{1/n}$ is a non-negative number, and is positive iff $x$ is
    positive.

    First, $x^{1/n}$ is obviously non-negative, since it is defined as
    the supremum of a (non-empty) set of non-negative numbers.

    Now let's prove that it is positive iff $x > 0$.
    \begin{itemize}
    \item If $x^{1/n} > 0$, then we have $\left(x^{1/n}\right)^n > 0^n$
        according to (the counterpart for real numbers of) Proposition
        4.3.12(b). But $0^n = 0$, and $\left(x^{1/n}\right)^n = x$
        according to equation \eqref{eq:566a}. Thus we have indeed $x
        > 0$.
    \item If $x > 0$, let's suppose for the sake of contradiction that
      $x^{1/n} = 0$. Then, still according to equation
      \eqref{eq:566a}, we should have $x = \left(x^{1/n}\right)^n =
      0$, which is a contradiction.
    \end{itemize}
    
  \item We have $x > y \Longleftrightarrow x^{1/n} > y^{1/n}$.
    \begin{itemize}
    \item First suppose that $x^{1/n} > y^{1/n}$. According to
      Proposition 4.3.12(b), we have: $\left(x^{1/n}\right)^n >
      \left(y^{1/n}\right)^n$. Also, by equation \eqref{eq:566a},
      $\left(x^{1/n}\right)^n = x$ and $\left(y^{1/n}\right)^n = y$,
      so we have indeed $x > y$.
      as required.
    \item Now suppose that $x > y$. Let's suppose for the sake of
      contradiction that we have $x^{1/n} \leq y^{1/n}$. We would thus
      use Proposition 4.3.12(b) and equation \eqref{eq:566a} again and
      see that $\left(x^{1/n}\right)^n \leq \left(y^{1/n}\right)^n$,
      i.e. that $x \leq y$, which is a contradiction. Thus we have
      necessarily $x^{1/n} > y^{1/n}$.
    \end{itemize}
  \item If $x > 1$, then $x^{1/k}$ is a decreasing (i.e.
    $x^{1/k} < x^{1/l}$ whenever $k > l$) function of $k$. If
    $0 < x < 1$, then $x^{1/k}$ is an increasing function of $k$. If
    $x=1$, then $x^{1/k}$ for all $k$. Here $k$ ranges over the
    positive integers.

    \begin{itemize}
    \item Let be $x=1$. We know that $1^k = 1$ for any positive
      integer $k$. Now, applying equation \eqref{eq:566b} leads to $1
      = 1^{1/k}$ for any positive integer $k$, as required.
    \item Let be $x>1$, and two positive integers $k>l$. We have to
      show that $x^{1/k} < x^{1/l}$. First, note that if $k > l$, then
      we have $k = l+p$ with $p$ a positive integer (recall Definition
      4.1.10). Let's suppose, for the sake of contradiction, that we
      have $x^{1/k} \geq x^{1/l}$. Thus, we should have
      $(x^{1/k})^{kl} \geq (x^{1/l})^{kl}$ according to Proposition
      4.3.10(c), i.e. $x^l \geq x^k$ (we use equation \eqref{eq:566a}
      for this latest claim). But this last inequality could be
      written $x^l \geq x^{l+p}$, i.e. $1 \geq x^p$ by cancellation
      law. But this is a contradiction: if $x>1$, we cannot have
      $x^p \leq 1$ with $p$ a positive integer\footnote{Just perform a
        quick inductive proof if needed.}. Thus, $x^{1/k}$ is indeed a
      decreasing function of $k$ in this case.
    \item Let be $0<x<1$, and two positive integers $k>l$ (thus, we
      still have $k = l+p$ for a certain positive integer $p$). We
      have to show that $x^{1/k} > x^{1/l}$. A very similar proof
      applies. Let's suppose, for the sake of contradiction, that we
      have $x^{1/k} \leq x^{1/l}$. We should thus have
      $(x^{1/k})^{kl} \leq (x^{1/l})^{kl}$, i.e. $x^l \leq x^k$. This
      means that $x^l \leq x^{l+p}$, i.e. $1 \leq x^p$, which is
      impossible if $0<x<1$. This shows the contradiction and closes
      the proof.
    \end{itemize}
  \item We have $(xy)^{1/n} = x^{1/n}y^{1/n}$.
    \begin{itemize}
    \item On the one hand, we have $\left[(xy)^{1/n}\right]^n = xy$
      according to equation \eqref{eq:566a}.
    \item On the other hand, we have
      $\left[x^{1/n}y^{1/n}\right]^n = (x^{1/n})^n(y^{1/n})^n = xy$,
      where we used successively Proposition 4.3.12(a) and equation
      \eqref{eq:566a}.
    \end{itemize}
    Thus, both expressions are equal.
  \item We have $(x^{1/n})^{1/m} = x^{1/nm}$.
    \begin{itemize}
    \item On the one hand, we have $(x^{1/nm})^{nm} = x$ according to
      equation \eqref{eq:566a}.
    \item On the other hand, $((x^{1/n})^{1/m})^{nm} =
      ((x^{1/n})^{1/m})^{mn} = \left[(x^{1/n})^{1/m})^m\right]^n =
      \left[x^{1/n}\right]^n = x$; where we used several times
      equation \eqref{eq:566a}, and Proposition 4.3.12.
    \end{itemize}
    Thus, both expressions are equal.
  \end{enumerate}
\end{exo}

\begin{exo}{5.6.2}{Prove Lemma 5.6.9.}
  Let $x,y > 0$ be positive reals, and let $q,r$ be rationals. In the
  whole exercise, let's say that $q = a/b$ and $r = a'/b'$, with
  $b, b' > 0$. The claims to prove are:

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item $x^q$ is a positive real.

    By Definition 5.6.7, $x^q = (x^{1/b})^a$. Since
    $x>0$, we know by Lemma 5.6.6(c) that $x^{1/b}$ is a positive
    real. Thus, $x^q = (x^{1/b})^a$ is also positive (by the
    counterpart for reals of Proposition 4.3.12(b)).
  \item $x^{q+r} = x^q x^r$ and $(x^q)^r = x^{qr}$.
    \begin{itemize}
    \item We have $q+r = \frac{ab' + a'b}{bb'}$ (recall Definition
      4.2.2). By Definition 5.6.7, $x^{q+r} = (x^{1/bb'})^{ab'+a'b}$.
      But we also can write $q = ab'/bb'$ and $r = a'b/bb'$. We know
      by Lemma 5.6.8 that our choices of numerators and denominators
      for $q$ and $r$ do not matter as regards $x^q$ and $x^r$. Thus
      we also have $x^q x^r = (x^{1/bb'})^{ab'}(x^{1/bb'})^{a'b}$,
      which is equal to $(x^{1/bb'})^{ab'+a'b}$ by Proposition
      4.3.12(a). Thus, $x^{q+r} = x^q x^r$.
    \item We have:
      \begin{align*}
        ((x^q)^r)^{bb'} &= ((((x^{1/b})^a)^{1/b'})^{a'})^{bb'} \\
                        &= (((x^{1/b})^a)^{1/b'})^{a'bb'} \\
                        &= ((((x^{1/b})^a)^{1/b'})^{b'})^{a'b} \\
                        &= ((x^{1/b})^a)^{a'b} \\
                        &= ((x^{1/b})^b)^{aa'} \\
                        &= x^{aa'}
      \end{align*}
      And, also:
      \begin{align*}
        (x^{qr})^{bb'} &= ((x^{1/bb'})^{aa'})^{bb'} \\
                       &= (x^{1/bb'})^{aa'bb'} \\
                       &= ((x^{1/bb'})^{bb'})^{aa'} \\
                       &= x^{aa'}
      \end{align*}
      Thus, both expressions are equal, and this implies $x^{qr} =
      (x^q)^r$ according to Proposition 4.3.12(c).
    \end{itemize}
    
  \item $x^{-q} = 1/x^q$.

    First, note that Definitions 4.3.11 and 5.6.2 only say that
    $x^{-n} = 1/x^n$ if $n$ is a \textit{positive} integer. But this
    is actually true for any integer $n$: if $n=0$, then both $x^{-n}$
    and $1/x^n$ are equal to $1$ and are thus equal; and if $n < 0$,
    then there exists a positive integer $m$ such that $n = -m$, and
    we have $x^{-n} = x^m$, $1/x^n = 1/x^{-m} = 1/(1/x^m) = x^m$ by
    Definition 5.6.2. Thus in all cases,

    \begin{equation}
      \label{eq:562c}
      x^{-n} = 1/x^n, \; \; \forall n \in \zz
    \end{equation}

    Now the claim is straightforward: if $q = a/b$ with $b>0$,
    then $x^{-q} = (x^{1/b})^{-a} = 1/((x^{1/b})^a) = 1/x^q$ according
    to equation \eqref{eq:562c}.

  \item If $q > 0$, then $x > y$ iff $x^q > y^q$.

    First, note that if $q>0$, then $q=a/b$ with both $a, b$ as
    positive integers.
    \begin{itemize}
    \item If $x > y$, then $x^{1/b} > y^{1/b}$ according to Lemma
      5.6.6(d). And then, $(x^{1/b})^a > (y^{1/b})^a$ according to
      (the counterpart for real numbers of) Proposition 4.3.12(b),
      i.e. $x^q > y^q$.
    \item If $x^q > y^q$, then by definition,
      $(x^{1/b})^a > (y^{1/b})^a$, and both terms are positive. Thus,
      by Lemma 5.6.6(d), we have
      $((x^{1/b})^a)^{1/a} > ((y^{1/b})^a)^{1/a}$, i.e. $x^{1/b} >
      y^{1/b}$. And, by Proposition 4.3.12(b), $x = (x^{1/b})^b >
      (y^{1/b})^b = y$, as required.
    \end{itemize}

  \item If $x > 1$, then $x^q > x^r$ if and only if $q > r$. If
    $x < 1$, then $x^q > x^r$ if and only if $q < r$.

    First, note that we have:
    \begin{equation}
      \label{eq:562e}
      (x^{1/b})^a = (x^a)^{1/b}
    \end{equation}
    because on the one hand,
    $((x^{1/b})^a)^b = (x^{1/b})^{ab} = (x^{1/b})^{ba} =
    ((x^{1/b})^b)^a = x^a$, where we used Proposition 4.3.12(a)
    twice. And on the other hand, $((x^a)^{1/b})^b = x^a$ by Lemma
    5.6.6(a). Thus, we have $((x^{1/b})^a)^b = ((x^a)^{1/b})^b$, which
    implies $(x^{1/b})^a = (x^a)^{1/b}$ by Proposition
    4.3.12(c). (This proof holds for $a \neq 0$, but equation
    \eqref{eq:562e} is obvious if $a=0$.)

    Now we go back to the main claims to prove.
    \begin{itemize}
    \item Let be $x > 1$. First suppose that $q > r$, and let's show
      that $x^q > x^r$. If $q > r$, then we have $a/b > a'/b'$,
      i.e. $ab'/bb' > a'b/bb'$, i.e. $ab' > a'b$. Since both $ab'$ and
      $a'b$ are integers and $x>1$, we thus have $x^{ab'} >
      x^{a'b}$. And, by Lemma 5.6.6(d), we have $(x^{ab'})^{1/bb'} >
      (x^{a'b})^{1/bb'}$, i.e. $x^{ab'/bb'} > x^{a'b/bb'}$, and
      finally $x^q > x^r$ by Lemma 5.6.8.

      Now suppose that $x^q > x^r$ (note that both of them are
      positive since $x > 1$), and let's show that $q > r$, i.e. that
      $ab' > a'b$. Since we can also write $q = ab'/bb'$ and
      $r=a'b/bb'$ (and this does not affect the result by Lemma
      5.6.8), we have $x^{ab'} = (x^q)^{bb'} > (x^r)^{bb'} =
      x^{a'b}$. And, if we multiply both sides by $x^{-a'b}$, which is
      a positive number, we get $x^{ab'-a'b} > 1$. We see that, in this
      inequality, we obviously cannot have $ab'-ab' = 0$. We cannot
      have $ab' - a'b < 0$ either, because in this case, we would have
      $ab' - a'b = -n$ with $n$ a positive integer. I.e., we would
      have $x^{-n}>1$, i.e. $1/x^n > 1$, a fact which is incompatible
      with our initial hypothesis $x>1$. Thus, we only have one
      possibility: $ab' - a'b > 0$, i.e. $q>r$.
    \item Let be $0 < x < 1$. Detailed proof is not given here, but is
      similar to the previous case.
    \end{itemize}
  \item $(xy)^q = x^q y^q$.

    We have:
    \begin{align*}
      (xy)^q &= ((xy)^{1/b})^a \text{ (Definition 5.6.7)} \\
             &= (x^{1/b} y^{1/b})^a \text{ (Lemma 5.6.6(f))} \\
             &= (x^{1/b})^a (y^{1/b})^a \text{ (Proposition
               4.3.12(a))} \\
             &= x^q y^q
    \end{align*}
    as required.
  \end{enumerate}
\end{exo}

\begin{exo}{5.6.3}{If $x$ is a real number, show that
    $|x| = (x^2)^{1/2}$.}

  To show that $(x^2)^{1/2}$ is equal to $|x|$, we should consider
  three cases according to the definition of absolute values, and
  prove that $(x^2)^{1/2} = 0$ if $x=0$, $(x^2)^{1/2} = x$ if $x > 0$,
  and $(x^2)^{1/2} = -x$ if $x < 0$.

  \begin{itemize}
  \item If $x=0$, we have $x^2 = 0$, and thus $(x^2)^{1/2} = 0$
    according to Lemma 5.6.6(c).
  \item If $x>0$, we have $(x^2)^{1/2} = x$ according to equation
    \eqref{eq:566b}, i.e. Lemma 5.6.6(b).
  \item If $x<0$, then $-x > 0$. Also, we know that $x^2 = (-x)^2$ for
    every real $x$. Thus, $(x^2)^{1/2} = ((-x)^2)^{1/2} = -x$ as
    required, still by Lemma 5.6.6(b).
  \end{itemize}
\end{exo}

\pagebreak
\section{Limits of sequences}
\begin{exo}{6.1.1}{Let $\seq{a_n}{0}$ be a sequence of real numbers,
    such that $a_{n+1} > a_n$ for each natural number $n$. Prove that
    whenever $n$ and $m$ are natural numbers such that $m > n$, then
    we have $a_m > a_n$. (We refer to these sequences as increasing
    sequences.)}

  Let be $k = m-n$, so that $k > 0$ represents the difference between
  the two indexes under comparison. Let's induct on $k$ to prove that
  $a_{n+k} > a_n$ for all natural number $n$ and any $k > 0$.

  \begin{itemize}
  \item The base case is $k = 1$, i.e. $m = n+1$. We must show here
    that $a_{n+1} > a_n$, but this is true by our initial hypothesis.
  \item Now suppose inductively that this is true for a certain
    natural $k$, i.e. that we have $a_{n+k} > a_n$ for all $n$. We
    have to show that we have $a_{n+k+1} > a_n$ for all $n$. But we
    know by our initial hypothesis that $a_{n+k+1} > a_{n+k}$, thus we
    have $a_{n+k+1} > a_{n+k} > a_n$, i.e. by transitivity, $a_{n+k+1}
    > a_n$ as required. This closes the induction.
  \end{itemize}
\end{exo}

\begin{exo}{6.1.2}{Let $\seq{a_n}{m}$ be a sequence of real numbers,
    and let $L$ be a real number. Show that $\seq{a_n}{m}$ converges
    to $L$ iff, given any real $\epsilon > 0$, one can find an $N \geq
    m$ such that $|a_n - L| \leq \epsilon$ for all $n \geq N$.}

  \begin{itemize}
  \item First suppose that $\seq{a_n}{m}$ converges to $L$. Let be
    $\epsilon$ a positive real number. By Definition 6.1.5,
    $\seq{a_n}{m}$ is eventually $\epsilon$-close to $L$, i.e., there
    exists a natural $N \geq m$ such that $|a_n - L| \leq \epsilon$,
    as required.
  \item Now show to converse implication. Let be $\epsilon$ a positive
    real. We know that we can find an $N \geq m$ such that
    $|a_n - L| \leq \epsilon$ for all $n \geq N$, and thus
    $\seq{a_n}{m}$ is eventually close to $\epsilon$. This is true for
    all $\epsilon$, so that $\seq{a_n}{m}$ converges to $L$.
  \end{itemize}
\end{exo}

\begin{exo}{6.1.3}{Let $\seq{a_n}{m}$ be a sequence of real numbers,
    let $c$ be a real number, and let $m' \geq m$ be an integer. Show
    that $\seq{a_n}{m}$ converges to $c$ if and only if
    $\seq{a_n}{m'}$ converges to $c$.}

  We will prove each part of this equivalence separately.
  
  \begin{itemize}
  \item First, suppose that $\seq{a_n}{m'}$ converges to $c$. This
    means that, for every $\epsilon > 0$, there exists $N' \geq m'$
    such that $n \geq N' \Longrightarrow |a_n - c| \leq \epsilon$. And
    we want to show that, still for every $\epsilon > 0$, there exists
    $N \geq m$ such that
    $n \geq N \Longrightarrow |a_n - c| \leq \epsilon$. We claim that
    taking $N := N'$ is convenient. Indeed, since $m' \geq m$, we have
    $n \geq m$ as soon as we have $n \geq m'$, so that $N'$ satisfies
    the required condition.
  \item Now suppose that $\seq{a_n}{m}$ converges to $c$. This means
    that:
    \begin{equation}
      \label{eq:613}
      \forall \epsilon > 0, \exists N \geq m \; : \;  n\geq m
      \to |a_n - c| \leq \epsilon
    \end{equation}
    So let be $\epsilon > 0$, and let's take $N' := N + m'$. We have
    both $N' \geq N$ and $N' \geq m'$. Thus, if $n \geq N'$, we also
    have $n \geq N$, which implies $|a_n - c| \leq \epsilon$ according
    to equation \eqref{eq:613}. Thus, we have indeed found a positive
    integer $N' \geq m'$ such that
    $n \geq N' \to |a_n - c| \leq \epsilon$, i.e., we have
    proved that $\seq{a_n}{m'}$ converges to $c$.
  \end{itemize}
\end{exo}

\begin{exo}{6.1.4}{Let $\seq{a_n}{m}$ be a sequence of real numbers,
    let $c$ be a real number, and let $k \geq 0$ be a non-negative
    integer. Show that $\seq{a_n}{m}$ converges to $c$ if and only if
    $\seq{a_{n+k}}{m}$ converges to $c$.}

  This exercise is pretty similar to the previous
  one.\footnote{Actually, it would be possible to use Exercise 6.1.3
    here, but, quite unexpectedly, this would just make the proof a
    little harder, because it would require to use some notions (like
    composition of functions, or intervals) that were very rarely used
    until now. The present proof is easier to write at this point of
    our knowledge.}
  
  \begin{itemize}
  \item First, suppose that $\seq{a_n}{m}$ converges to $c$. Let
    $\epsilon > 0$ be a real number. We must show that there exists
    $M \geq m$ such that
    $n+k \geq M \to |a_{n+k} - c| \leq \epsilon$. We know that
    there exists $N \geq m$ such that
    $n \geq N \to |a_n -c| \leq \epsilon$. But for any
    $k \leq 0$, we have $n + k \geq n$, so that as soon as $n \geq N$,
    we have $n+k \geq n \geq N$, and thus $|a_{n+k} - c| \leq
    \epsilon$. So, choosing $M := N$ is suitable here, and we have
    showed the first part.
  \item Now prove the converse implication: suppose that
    $\seq{a_{n+k}}{m}$ converges to $c$. We want to show that there
    exists $N \geq m$ such that
    $n \geq N \to |a_n -c| \leq \epsilon$. We already know
    that there exists $M \geq m$ such that
    $n \geq M \to |a_{n+k} - c| \leq \epsilon$. Let be
    $N := M+k$. We can see that if $n \geq N$, we have $n \geq M+k$,
    i.e. $n-k \geq M$, and thus $|a_{(n-k)+k} - c| \leq \epsilon$ as
    required. So, $N := M+k$ is suitable, and $\seq{a_n}{m}$ converges
    to $c$.
  \end{itemize}
\end{exo}

\begin{exo}{6.1.5}{Prove Proposition 6.1.12.}

  We must prove that convergent sequences are Cauchy sequences. Let
  $\seq{a_n}{m}$ be a convergent sequence to $c$, and let's prove that
  $\seq{a_n}{m}$ is a Cauchy sequence.

  Let be $\epsilon > 0$ a positive real number. By Definition 6.1.5,
  there exists a natural number $N \geq m$ such that
  $n \geq N \Longrightarrow |a_n - c| \leq \epsilon/2$.

  Now let be $j,k \geq N$ two natural numbers. We have, by triangular
  inequality:
  \begin{align*}
    |a_j - a_k| &= |a_j - c + c - a_k| \\
                & \leq |a_j - c| + |a_k - c| \\
                &\leq \epsilon/2 + \epsilon/2 \\
                &\leq \epsilon
  \end{align*}

  Thus, we have showed that there exists $N \geq m$ such that, for any
  natural numbers $j, k \geq N$, we have $|a_j - a_k| \leq \epsilon$.
  This means that $\seq{a_n}{m}$ is indeed a Cauchy sequence.  
\end{exo}

\bigskip

\begin{exo}{6.1.6}{Prove Proposition 6.1.15; i.e. that formal limits
    are genuine limits.}

  Let $\seq{a_n}{m}$ be a Cauchy sequence of real numbers, and
  $L := \formallimit{a_n}$. We have to show that $\seq{a_n}{m}$
  converges to $L$.

  Now we assume, for the sake of contradiction, that $\seq{a_n}{m}$ is
  not eventually $\epsilon$-close to $L$, i.e. that there exists
  $\epsilon > 0$ such that:

  \begin{equation}
    \label{eq:616-nec}
    \forall N \geq m, \, \exists n \geq N \; : \; |a_n - L| > \epsilon
  \end{equation}

  Precisely, let's consider this positive real $\epsilon$ in what
  follows. Also, recall that $\seq{a_n}{m}$ is a Cauchy sequence, so
  that:
  \begin{equation}
    \label{eq:616-cauchy}
    \exists T \geq m \; : \; j,k \geq T \Longrightarrow |a_j - a_k |
    \leq \epsilon/2
  \end{equation}

  According to \eqref{eq:616-nec}, there exists $t \geq T$ such that
  $|a_t - L| > \epsilon$. And since $t \geq T$, let's also consider
  any $s \geq T$: according to \eqref{eq:616-cauchy}, we have $|a_s -
  a_t| \leq \epsilon /2$. In particular, let's now fix $t$ so that we
  can rephrase this property as:
  \begin{equation}
    \label{eq:616-c}
    \forall s \geq T, \; |a_s - a_t| \leq \epsilon/2 \; \; \; ; \; \; \;
    \text{i.e., } a_t - \epsilon/2 \leq a_s \leq a_t + \epsilon/2
  \end{equation}

  The inequality $|a_t - L| > \epsilon$ opens two possible cases:
  \begin{itemize}
  \item if $a_t > L + \epsilon$, then we have from \eqref{eq:616-c}:
    \[ L + \epsilon - \epsilon/2 < a_t - \epsilon/2 \leq a_s \]
    so that $L + \epsilon/2 \leq a_s$ for all $s \geq T$. According to
    Exercise 5.4.8, we should conclude that $L + \epsilon/2 \leq L$,
    which is clearly a contradiction.
  \item if $a_t < L - \epsilon$, then then we have from \eqref{eq:616-c}:
    \[ a_s \leq a_t + \epsilon/2 \leq L - \epsilon + \epsilon/2\]
    so that $a_s \leq L - \epsilon/2$ for all $s \geq T$. According to
    Exercise 5.4.8, we should conclude that $L \leq L - \epsilon/2$,
    which is also a contradiction.
  \end{itemize}

  Thus, necessarily, $\seq{a_n}{m}$ is eventually $\epsilon$-close to
  $L$ for any $\epsilon > 0$, i.e. $\seq{a_n}{m}$ converges to $L$.
\end{exo}

\bigskip

\begin{exo}{6.1.7}{Show that Definition 6.1.16 is consistent with
    Definition 5.1.12 (i.e., prove an analogue of Proposition 6.1.4
    for bounded sequences instead of Cauchy sequences).}

  Let be $\seq{a_n}{m}$ a sequence of real\footnote{If $\seq{a_n}{m}$ is
    a sequence of rational numbers, there is literally nothing to
    prove, so that we can skip this case.} numbers.

  \begin{itemize}
  \item First suppose that $\seq{a_n}{m}$ is bounded according to
    Definition 5.1.12. It means that there exists a non-negative
    rational $M \geq 0$ such that $|a_n| \leq M$ for all $n \geq m$.
    We have to show that there exists a positive real $M' > 0$ such
    that $|a_n| \leq M'$ for all $n \geq m$. If we just take $M' := M
    +1$, we have $M' > M$ and $M' \in \rr$ because $M' \in \qq$. Thus,
    we have $|a_n| \leq M < M'$ for all $n \geq m$, as required. Thus,
    $\seq{a_n}{m}$ is bounded according to Definition 6.1.16.
  \item Now suppose that $\seq{a_n}{m}$ is bounded according to
    Definition 6.1.16. It means that there exists a positive real
    number $M' > 0$ such that $|a_n| \leq M'$ for all $n \geq m$. We
    have to show that there exists a non-negative rational number
    $M \geq 0$ such that $|a_n| \leq M$ for all $n \geq m$. According
    to Proposition 5.4.12, there exists a positive integer $N$ such
    that $M' \leq N$. This implies that $|a_n| \leq M' \leq N$ for all
    $n \geq m$. And since $N$ is a positive integer, it's also a
    non-negative rational. Thus, $\seq{a_n}{m}$ is bounded according
    to Definition 5.1.12.
  \end{itemize}
\end{exo}

\begin{exo}{6.1.8}{Prove Theorem 6.1.19 about limit laws.}

  We'll prove each statement successively.

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Let be $\epsilon > 0$. We have to prove that there exists a
    natural number $N \geq m$ such that for all $n \geq N$, we have
    $|(a_n + b_n) - (x+y)| \leq \epsilon$.

    Since $\seq{a_n}{m}$ converges to $x$, there exists $N_1 \geq m$
    such that $n \geq N_1 \to |a_n - x| \leq \epsilon/2$.

    Similarly, there exists $N_2 \geq m$ such that
    $n \geq N_2 \to |b_n - y| \leq \epsilon/2$.

    Let be $N := \max(N_1, N_2)$. Thus, by triangular inequality, we
    have for all $n \geq N$:
    \begin{align*}
      |(a_n + b_n) - (x+y)| &\leq |a_n + x| + |b_n + y| \\
                            & \leq \epsilon/2 + \epsilon/2 \\
                            & \leq \epsilon
    \end{align*}
    as required. This closes the proof.
  \item Let be $\epsilon > 0$. We have to prove that there exists a
    natural number $N \geq m$ such that for all $n \geq N$, we have
    $|a_nb_n - xy| \leq \epsilon$.

    Let's start by some algebraic manipulations:
    \begin{align*}
      |a_nb_n - xy| &= |a_nb_n - a_ny + a_ny  - xy| \\
                    &= |a_n(b_n - y) + y (a_n-x)| \\
                    & \leq |a_n| \times |b_n -y| + |y| \times |a_n -x|
    \end{align*}

    Hopefully, there exists an upper bound for each term of this last
    expression, at least eventually. Indeed:

    \begin{itemize}
    \item Since $\seq{a_n}{m}$ is convergent, it is bounded according
      to Corollary 6.1.17. Thus, there exists $M \geq 0$ such that
      $|a_n| \leq M$ for all $n \geq m$.
    \item Since $\seq{b_n}{m}$ converges to $y$, there exists an
      integer $N_b \geq m$ such that
      $n \geq N_b \to |b_n - y| \leq \frac{\epsilon}{2M}$.
    \item Since $\seq{a_n}{m}$ converges to $x$, there exists an
      integer $N_a \geq m$ such that
      $n \geq N_b \to |a_n - x| \leq \frac{\epsilon}{2(|y|+1)}$.
      (Note that we don't choose $\frac{\epsilon}{2|y|}$, because we
      don't know whether $|y| \neq 0$ or not, so we need an additional
      precaution.)
    \end{itemize}

    Let be $N := \max(N_a, N_b)$. For $n \geq N$, we thus have:
    \begin{align*}
      |a_nb_n - xy| & \leq |a_n| \times |b_n -y| + |y| \times |a_n -x|
      \\
                    &\leq M \times \frac{\epsilon}{2M} + |y| \times
                      \frac{\epsilon}{2(|y|+1)} \\
                    &\leq \epsilon/2 + \epsilon/2 \\
                    &\leq \epsilon
    \end{align*}
    as required. This closes the proof.
  \item Here, a direct proof would be possible (and short), for
    instance by using Proposition 4.3.3(d). But following Tao's hint,
    let's use the previous results of this exercise instead. Let's
    consider the constant sequence $\seq{c_n}{m} = c, c, c, \ldots$;
    so that the sequence $\seq{ca_n}{m}$ is actually the product of the
    two sequences $\seq{a_n}{m}$ and $\seq{c_n}{m}$. Obviously,
    $\seq{c_n}{m}$ converges to $c$, so that according to statement
    \emph{(b)}, we have $\limit{ca_n} = \limit{c_n a_n} = \limit{c_n}
    \limit{a_n} = cx$, which closes the proof.
  \item According to \emph{(c)} taking $c = -1$, we have
    $\limit{(-b_n)} = - \limit{b_n} = -y$. Furthermore, according to
    \emph{(a)}, we have $\limit{(a_n + (-b_n))} = \limit{a_n} +
    \limit{(-b_n)} = x - y$, as requested.
  \item Following Tao's hint, we begin by proving an intermediate
    result, which is the following: if $\seq{b_n}{m}$ is a sequence of
    non-zero real numbers, and converges to $y \neq 0$, then
    $\seq{b_n}{m}$ is bounded away from zero. Note that, by the
    ``second formula'' of triangular inequality, we have:
    \begin{equation}
      \label{eq:618e}
      |y| - |b_n| \leq \left| |y| - |b_n| \right| \leq |y - b_n|
    \end{equation}
    Furthermore, since $\seq{b_n}{m}$ converges to $y$, there exists a
    positive integer $M \geq m$ such that, for all $n \geq M$, we have
    $|b_n - y| \leq |y|/2$. This result, along with equation
    \eqref{eq:618e}, implies that $|b_n| \geq |y|/2$ for all $n \geq
    M$, so that $\seq{b_n}{m}$ is eventually bounded away from zero,
    for $n \geq M$.
    But since $b_n \neq 0$ for all $n$, just consider $c = \min(|b_m|,
    |b_{m+1}|, \ldots, |b_{M-1}|, |y|/2)$: we thus have $|b_n| \geq c$ for
    all $n \geq m$, and $c$ is positive. Thus, $\seq{b_n}{m}$ is
    indeed bounded away from zero.

    Note that saying ``$\seq{b_n}{m}$ is bounded away from zero'', or
    $|b_n| \geq c$ for all $n \geq m$, means that $|1/b_n| \leq 1/c$,
    i.e. that $\seq{1/b_n}{m}$ is bounded.

    Let be $\epsilon > 0$ a positive real number. Since $\seq{b_n}{m}$
    converges to $y$, there exists a positive integer $N$ such that
    for all $n \geq N$, we have $|y-b_n| \leq \epsilon|y|c$ (which is
    a positive real number, because $|y| \neq 0$. Now let's
    consider:
    \begin{align*}
      \left| \frac{1}{b_n} - \frac{1}{y} \right| &= \left| \frac{y -
                                                   b_n}{yb_n} \right|
      \\
                                                 &= \left| \frac{1}{y}
                                                   \right| \times
                                                   \left|
                                                   \frac{1}{b_n}
                                                   \right| \times
                                                   \left|y - b_n
                                                   \right| \\
                                                 & \leq \frac{1}{|y|}
                                                   \times
                                                   \frac{1}{c} \times
                                                   |y - b_n| \\
                                                 & \leq \frac{1}{|y|}
                                                   \times
                                                   \frac{1}{c} \times
                                                   \epsilon |y| c
                                                   \; \; \text{ for
                                                   all } n \geq N\\
                                                 &\leq \epsilon
    \end{align*}
    This means that, for any positive real $\epsilon$, one can find a
    positive integer $N \geq m$ such that $\left| \frac{1}{b_n} -
      \frac{1}{y} \right| \leq \epsilon$. Thus, $\seq{1/b_n}{m}$
    converges to $1/y$.
  \item This is a direct consequence of the parts \emph{(b)} and
    \emph{(e)}. Indeed, by part \emph{(b)}, we have: $\limit{(a_n /
      b_n)} = \limit{(a_n \times 1/b_n)} = \limit{a_n} \times \limit{1 /
      b_n}$. And by part \emph{(e)}, we have $\limit{1/b_n} =
    1/\limit{b_n}$, which gives the property we wanted to show.
  \item We must show that $\limit{\max(a_n, b_n)} = \max(x, y)$. We
    immediately see that we have two different cases: if $x \geq y$,
    then $\max(x, y) = x$ and then we must show that $\limit{\max(a_n,
      b_n)} = x$; else if $x < y$, then $\max(x,y) = y$ and we must
    show that $\limit{\max(a_n, b_n)} = y$. Let's consider those two
    cases separately. In what follows, let be $\epsilon > 0$ a
    positive real.
    \begin{itemize}
    \item If $x \geq y$, we actually have to prove that there exists a
      positive integer $N \geq m$ such that for all $n \geq N$, we
      have $|\max(a_n, b_n) - x| \leq \epsilon$. We already know
      that $\seq{a_n}{m}$ converges to $x$, thus:
      \begin{equation}
        \label{eq:618ga}
        \exists N_a \geq m \; : \; n \geq N_a \Longrightarrow |a_n -
        x| \leq \epsilon
      \end{equation}
      Similarly, since $\seq{b_n}{m}$ converges to $y$:
      \begin{equation}
        \label{eq:618gb}
        \exists N_b \geq m \; : \; n \geq N_b \Longrightarrow |b_n -
        y| \leq \epsilon
      \end{equation}
      Now let's consider $N := \max(N_a, N_b)$, which is a positive
      integer. For all $n \geq N$, we have both
      $x - \epsilon \leq a_n \leq \epsilon +x$ by \eqref{eq:618ga},
      and $y - \epsilon \leq b_n \leq \epsilon +y \leq \epsilon +x$ by
      \eqref{eq:618gb}. Combining those two relationships\footnote{We
        also use the property that if $x \leq a$ and $y \leq a$, then
        $\max(x,y) \leq a$.} leads to:
      \[ x-\epsilon \leq a_n \leq \max(a_n, b_n) \leq \epsilon +x\]
      whose the most important part is
      $x-\epsilon \leq \max(a_n, b_n) \leq x+\epsilon$, which is
      equivalent to $|\max(a_n, b_n) - x| \leq \epsilon$, as requested
      initially. This closes the proof for this first case.
    \item If $x < y$, the proof is very similar. We have to prove that
      there exists a positive integer $N \geq m$ such that for all
      $n \geq N$, we have $|\max(a_n, b_n) - y| \leq \epsilon$. Once
      again, we can combine the previous results to get:
      \[ y-\epsilon \leq b_n \leq \max(a_n, b_n) \leq \epsilon +y\]
      i.e. $|\max(a_n, b_n) - y| \leq \epsilon$ as requested.
    \end{itemize}
  \item Taking the inspiration in the way we defined the greatest
    lower bound from the least upper bound (Exercise 5.5.1), we could
    first note that $\min(a,b) = -\max(-a, -b)$. Then, this would be a
    direct consequence from part \emph{(c)} and \emph{(g)}.
  \end{enumerate}
\end{exo}

\begin{exo}{6.1.9}{Explain why Theorem 6.1.19(f) fails when the limit
    of the denominator is $0$.}

  Theroem 6.1.19(f) says that if $\seq{a_n}{m}$ converges to $x$ and
  $\seq{b_n}{m}$ converges to $y \neq 0$ (with $b_n \neq 0$ for all $n
  \geq m$), then $\seq{a_n/b_n}{m}$ converges to $x/y$. If $y = 0$,
  the number $x/y$ simply does not exist, so that the statement is
  pointless.

  Note however that the sequence $\seq{a_n/b_n}{m}$ \emph{may}
  converge even if we have $\lim{b_n} = 0$: think of the situation
  $a_n = b_n = 1/n$, for instance.
\end{exo}

\bigskip

\begin{exo}{6.1.10}{Show that the concept of equivalent Cauchy
    sequence, as defined in Definition 5.2.6, does not change if
    $\epsilon$ is required to be positive real instead of positive
    rational. More precisely, if $\seq{a_n}{0}$ and $\seq{b_n}{0}$ are
    sequences of reals, show that $\seq{a_n}{0}$ and $\seq{b_n}{0}$
    are eventually $\epsilon$-close for every rational $\epsilon >
    0$ if and only if they are eventually $\epsilon$-close for every
    real $\epsilon > 0$.}

  Following Tao's hint, we just adapt the proof of Proposition 6.1.4.
  
  \begin{itemize}
  \item First suppose that $\seq{a_n}{0}$ and $\seq{b_n}{0}$ are
    eventually $\epsilon$-close for every real $\epsilon > 0$. In
    particular, this means that they are $\epsilon$-close for any
    \emph{rational} $\epsilon > 0$, so there is nothing to prove.
  \item Then suppose that $\seq{a_n}{0}$ and $\seq{b_n}{0}$ are
    eventually $\epsilon$-close for every rational $\epsilon > 0$. Now
    let $\epsilon > 0$ be a \emph{real} number. According to
    Proposition 5.4.12, there exists a positive rational $q$ such that
    $q \leq \epsilon$. Since $q$ is a rational, $\seq{a_n}{0}$ and
    $\seq{b_n}{0}$ are $q$-close, according to our initial hypothesis,
    i.e., $|a_n - b_n| \leq q \leq \epsilon$ for all $n$ greater than
    some positive integer $N$. In particular, this means that
    $\seq{a_n}{0}$ and $\seq{b_n}{0}$ are eventually $\epsilon$-close,
    as requested.
  \end{itemize}
\end{exo}

\begin{exo}{6.2.1}{Prove Proposition 6.2.5.}
  
  Hereafter, $x, y, z$ are extended real numbers. Thus, they can be
  either real numbers, or $\pm \infty$.

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item We have to show that $x \leq x$. We have three cases here. If
    $x$ is a real number, this is an obvious statement. If
    $x = + \infty$, then by Definition 6.2.3(b), we have
    $x \leq +\infty$ for all extended real $x$, so that the claim
    $x \leq x$ is still true. Similarly, if $x = - \infty$, we have
    $- \infty \leq x$ for all extended real $x$ according to
    Definition 6.2.3(c).
  \item We have to show the trichotomy of extended real numbers, i.e.
    that we always have exactly one of the statements $x < y$, $x = y$
    or $x > y$. Both $x$ and $y$ can be either real numbers, $+\infty$
    or $- \infty$, so that we have nine cases to study exhaustively.
    \begin{enumerate}[label=(\roman*)]
    \item If both $x, y$ are real numbers, then this is simply
      Proposition 5.4.7(a)\footnote{Actually, the statement (a) from
        Proposition 4.2.9, and applied to reals by Proposition 5.4.7,
        but I'll shorten this for the rest of the exercise.}.
    \item If $x$ is a real number and $y = + \infty$, then we have
      $x \leq y$ by Definition 6.2.3(b), and we also have $x \neq y$
      by Definition 6.2.1. Thus, $x < y$ is true, and the two other
      statements $x = y$ and $x > y$ are false. (It is easy to see
      that $x > y$ is false, because it corresponds to none of the
      cases listed in Definition 6.2.3.)
    \item If $x$ is a real number and $y = - \infty$, then we have $y
      \leq x$ according to Definition 6.2.3(c), and $x \neq y$
      according to Definition 6.2.1. Thus, $x > y$ is true; whereas
      $x=y$ is false, and $x<y$ is also false because it corresponds
      to none of the cases listed in Definition 6.2.3.
    \item If $x = +\infty$ and $y$ is a real number, then we have
      $x \geq y$ by Definition 6.2.3(b), and $x \neq y$ by Definition
      6.2.1. Thus, $x > y$ is true; whereas $x = y$ is false, and
      $x<y$ is also false because it corresponds to none of the cases
      listed in Definition 6.2.3.
    \item If $x = +\infty$ and $y = +\infty$, then we have $x = y$.
      Thus, both statements $x<y$ and $x>y$ are incompatible with this
      one. It means that exactly one statement ($x=y$) is true in this
      case.
    \item If $x = +\infty$ and $y = -\infty$, then we have $y \leq x$
      by Definition 6.2.3(b-c). According to Definition 6.2.1, we also
      have $x \neq y$. Thus, $y > x$ is true; whereas $x=y$ is false,
      and $x > y$ is also false because it corresponds to none of the
      cases listed in Definition 6.2.3.
    \item The three last cases where $x = - \infty$ and $y$ is either
      $- \infty$, a real, or $+ \infty$, can be shown in a similar
      fashion, and are ``symmetrical'' with all previous proofs.
    \end{enumerate}
  \item We have to show that if $x \leq y$ and $y \leq z$, then $x
    \leq z$. We'll choose wisely below some of the cases that really
    make sense in such a siuation.
    \begin{itemize}
    \item If $z = +\infty$, then according to Definition 6.2.3(b),
      $x \leq z$ is always true, regardless of the value of $y$.
    \item If $z = -\infty$, only possible situation makes sense: the
      situation where $x=y=z=-\infty$. Thus, the transitivity
      ($x \leq z$) is still true in this case.
    \item If $z$ is a real number, then $x, y$ cannot be $+ \infty$.
      If $y = -\infty$, then necessarily $x = -\infty$, and we thus
      have $x \leq z$. If $x, y$ are real numbers, then it is simply
      Proposition 5.4.7(c). And if $y$ is a real number and
      $x = -\infty$, then $x \leq z$ by Definition 6.2.3(c).
    \end{itemize}
  \item Finally we have to show that if $x \leq y$, then $-y \leq -x$.
    If $y = +\infty$, then $-y = -\infty$ and thus $-y \leq -x$ for
    all extended real $-x$, thus the statement is true in this case.
    If $y = - \infty$, then we have necessarily $x = -\infty$, and
    thus $-x = -y$, so that the statement still holds.
    Finally, if $y$ is a real number, then the statement is simply
    Proposition 5.4.7 if $x$ is real, and is obvious if $x = -\infty$.
  \end{enumerate}
\end{exo}

\begin{exo}{6.2.2}{Prove Theorem 6.2.11.}

  We have to prove the following statements:

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item For every $x \in E$ we have $x \leq \sup(E)$ and $x \geq
    \inf(E)$.

    \begin{itemize}
    \item First, suppose that $+ \infty \in E$. We thus have
      $\sup(E) = +\infty$ by Definition 6.2.6(b); and by Definition
      6.2.3(b), $x \leq +\infty = \sup(E)$ for all $x \in E$, as
      required.
    \item Now suppose that $+ \infty \notin E$, but $- \infty \in E$.
      There are two possible cases here. If $x = -\infty$, then
      $-\infty = x \leq y$ for all extended real$y$ by Definition
      6.2.3(c); and in particular, with $y = \sup(E)$, we have
      $x \leq \sup(E)$ as required. On the other hand, if $x$ is a
      real number, then $x \in E \setminus \left\{ -\infty \right\}$,
      so that $x \leq \sup(E \setminus \left\{ -\infty \right\}) :=
      \sup(E)$ by Definition 6.2.6(c), as required.
    \item Finally, if $E$ consists only of real numbers, we have $x
      \leq \sup(E)$ by Definition 5.5.10 as long as $E$ has an upper
      bound; otherwise we have $\sup(E) = +\infty$ by Definition
      6.2.6(b), and thus $x \leq \sup(E)$ bu Definition 6.2.3(b).
      Thus, in all cases, we have indeed $x \leq \sup(E)$.
    \item The other statement, $x \geq \inf(E)$, is a direct
      consequence. Indeed, if $x \in E$, then by definition, $-x \in
      -E$, and thus $-x \leq \sup(-E)$ according to our previous
      conclusions. And finally, $-x \leq \sup(-E)$ is equivalent to $x
      \geq -\sup(-E)$, i.e. $x \geq \inf(E)$, according to Proposition
      6.2.5(d) and the definition of the greatest lower bound.
    \end{itemize}
    
  \item Suppose that $M \in \extrr$ is an upper bound for $E$, i.e.,
    $x \leq M$ for all $x \in E$. Then we have $\sup(E) \leq M$.

    \begin{itemize}
    \item If $+ \infty \in E$, then $\sup(E) = + \infty$ by Definition
      6.2.6(b). But the only possible upper bound for $E$ is
      $+\infty$, so that we have necessarily $\sup(E) = M = + \infty$.
      The statement is thus true is this case.
    \item If $E$ consists only of real numbers, there are three
      sub-cases. If $E$ is empty, the $\sup(E) = -\infty$, so that
      $\sup(E) \leq M$ regardless of the value of $M$. If $E$ is
      non-empty and not bounded above, then $\sup(E) = + \infty$ and
      $M$ can only be equal to $+ \infty$, so that $\sup(E) = M$. And
      finally, if $E$ is non-empty but bounded above, then the results
      comes from Definition 5.5.10.
    \item If $+ \infty \notin E$ but $- \infty \in E$, then
      $\sup(E) := \sup(E \setminus \left\{ -\infty \right\})$. But the
      set $E \setminus \left\{ -\infty \right\}$ consists only of real
      numbers, so that we can basically go back to the previous case,
      to get $\sup(E) = \sup(E \setminus \left\{ -\infty \right\})
      \leq M$.
    \end{itemize}
  \end{enumerate}
\end{exo}

\begin{exo}{6.3.1}{Verify the claim in Example 6.3.4: Let $a_n :=
    1/n$; thus $\seq{a_n}{1}$ is the sequence $1, 1/2, 1/3, \ldots$.
    Then $\sup\seq{a_n}{1} = 1$ and $\inf \seq{a_n}{1} = 0$.}

  Let's prove those two statements separately.
  
  \begin{itemize}
  \item First, note that $1$ is an upper bound for $\seq{a_n}{1}$:
    since $n \geq 1$, we always have $1/n \leq 1$. Furthermore, let
    $M$ be an upper bound for $\seq{a_n}{1}$. By definition, we must
    have $M \geq a_n$ for all $n \geq 1$; and in particular
    $M \geq a_1 = 1$. Thus, $1$ is indeed the least upper bound of
    $\seq{a_n}{1}$.
  \item Second, $0$ is a lower bound for $\seq{a_n}{1}$: we obviously
    have $1/n \geq 0$ for all $n \geq 1$. Let's suppose for the sake
    of contradiction that there exists a greater lower bound $m$ of
    $\seq{a_n}{1}$. By definition, this means that $a_n \geq 0$ for
    all $n \geq 1$, and that $m > 0$. But according to the archimedean
    property with $\epsilon = 1$, there exists a natural number $N$
    such that $mN \geq 1$, i.e. $m \geq 1/N$, that is to say $a_N \leq
    m$. This is a contradiction, since $m$ is not a lower bound
    anymore. Thus, $0$ is indeed the greatest lower bound of
    $\seq{a_n}{1}$.
  \end{itemize}
\end{exo}

\begin{exo}{6.3.2}{Prove Proposition 6.3.6.}

  Let $E = \{ a_n \, : \, n \geq m\}$, and $x = \sup \seq{a_n}{m}$. By
  Definition 6.3.1, we thus have $x = \sup(E)$. Let's prove all
  statements from the Proposition.

  \begin{itemize}
  \item Obviously, we have $a_n \leq x$ for all $n \geq m$, according
    to Theorem 6.2.11(a).
  \item Let be $M \in \extrr$ an upper bound for $\seq{a_n}{m}$. This
    is equivalent to say that $M$ is an upper bound for $E$. Thus,
    according to Theorem 6.2.11(b), we have $M \geq x$.
  \item Now let be $y \in \extrr$ such that $y < x$. Suppose, for the
    sake of contradiction, that $y \geq a_n$ for all $n \geq m$. This
    means that $y$ is an upper bound for $\seq{a_n}{m}$, and that $y <
    x$. This contradicts the conclusion from the previous bullet point
    of this exercise. Thus, there exists an $n \geq m$ such that $y <
    a_n$. And since $a_n \in E$, we also have $y < a_n \leq x$, as
    required.
  \end{itemize}
\end{exo}

\begin{exo}{6.3.3}{Prove Proposition 6.3.8. (increasing
    bounded sequences converge).}

  Let $\seq{a_n}{m}$ be a sequence of real numbers. The hypotheses
  are, first, that $a_{n+1} \geq a_n$ for all $n \geq m$; and second,
  that there exists a positive integer $M$ such that $|a_n| \leq M$
  for all $n \geq m$.

  Let be $\ell = \sup \seq{a_n}{m}$. Since $\seq{a_n}{m}$ is bounded,
  $\ell$ is a real number. We will show that $\seq{a_n}{m}$ converges
  to $\ell$.

  Let be $\epsilon > 0$ a real number. First, we already know that:
  \begin{equation}
    \label{eq:633a}
    a_n \leq \ell
  \end{equation}
  for all $n \geq m$. Thus, in particular, we have
  $a_n \leq \ell + \epsilon$ for all $n \geq m$.

  Also, according to the third statement of Proposition 6.3.6, if $y$
  is a real number such that $y < \ell$, there exists at least one
  element of $\seq{a_n}{m}$, say $a_{n_0}$, such that $y < a_{n_0} <
  \ell$. In particular, with $y = \ell - \epsilon$, we thus have:
  \begin{equation}
    \label{eq:633b}
    \ell - \epsilon < a_{n_0} \leq a_n
  \end{equation}
  But recall that the sequence $\seq{a_n}{m}$ is an increasing
  sequence: we have (as a quick induction shows) $a_n \geq a_{n_0}$
  for all $n \geq n_0$. Combining the two equations \eqref{eq:633a}
  and \eqref{eq:633b}, we get $\ell - \epsilon < a_{n_0} \leq a_n \leq
  \ell \leq \ell + \epsilon$ for all $n \geq n_0$.

  Let's summarise:
  \begin{equation}
    \label{eq:633c}
    \forall \epsilon > 0, \exists n_0 \geq m \; \; : \; \; n \geq n_0
    \Longrightarrow \ell - \epsilon \leq a_n \leq \ell + \epsilon
  \end{equation}
  which means precisely that $\seq{a_n}{m}$ converges to $\ell$, as required.
\end{exo}

\begin{exo}{6.3.4}{Explain why Proposition 6.3.10 fails when $x > 1$.
    In fact, show that the sequence $\seq{x^n}{1}$ diverges when
    $x > 1$. Compare this with the argument in Example 1.2.3; can you
    now explain the flaws in the reasoning in that example?}

  First, the proof of Proposition 6.3.10 supposes that the sequence
  $\seq{x^n}{1}$ is decreasing and has a lower bound of 0, which is
  not the case here: the sequence $\seq{x^n}{1}$ is increasing and has
  no real upper bound (or, let's say that its upper bound is $+
  \infty$). So the situation is not identical, and even not
  ``symmetrical''.

  Actually, when $x>1$, the sequence $\seq{x^n}{1}$ diverges to
  $+\infty$. Let's suppose, for the sake of contradiction, that it
  converges to a real number $\ell$ instead. Since $x>1$, we have
  $0 < 1/x < 1$, so that by Proposition 6.3.10, $\seq{1/x^n}{1}$ is a
  sequence that converges to 0. Thus, if we denote
  $a_n = x^n \times 1/x^n$, the sequence $\seq{a_n}{1}$ is the product
  of two convergent sequences, so that if we apply the limit laws
  (Theorem 6.1.19(b)), we would have
  $\limit{a_n} = \ell \times 0 = 0$. But this is impossible, since
  $a_n = 1$ for all $n \geq 1$. It is thus impossible for
  $\seq{x^n}{1}$ to be a convergent sequence if $x>1$.

  Finally, the issue in Example 1.2.3 is that there is a ``hidden''
  assumption in it: it is not explicitly stated, but it is a strong
  one. In this example, we begin with the statement: ``let $L$ be the
  limit $L = \limit{x^n}$'', and then we apply the limit laws (Theorem
  6.1.19) as if we were sure that $\seq{x^n}{1}$ is a convergent
  sequence, i.e. that $L$ is a real number. But in the next steps of
  this example (where we take $x=-1$ or $x=2$), this is absolutely not
  the case: instead this sequence diverges. Thus, it was wrong to
  apply the limit laws, and the whole reasoning is flawed. It is only
  correct in the case where $x\leq 1$, i.e. where $L = 0$ or $x=1$,
  which is also a remark we make during this example.
\end{exo}

\bigskip
\begin{exo}{6.4.1}{Prove Proposition 6.4.5.}
  
  Let $\seq{a_n}{m}$ be a sequence of real numbers, which converges to
  $c$. There are two statements to prove.

  \begin{itemize}
  \item First, let's prove that $c$ is a limit point for
    $\seq{a_n}{m}$. Intuitively this is obvious since being a limit
    point is somewhat weaker than being a limit, but show it
    rigorously this requires some manipulations on quantifiers.

    Let be $\epsilon > 0$ a real number and $N\geq m$ a positive
    integer. We must show that there exists $k \geq N$ such that $|a_k
    - c| \leq \epsilon$.

    Actually, we know that $\seq{a_n}{m}$ converges to $c$. It means
    that there exists $N' \geq m$ such that, for \emph{all}
    $n \geq N'$, we have $|a_n - c| \leq \epsilon$.

    Thus, any positive integer $n \geq \max(N, N')$ will do the trick,
    and in particular $n = \max(N, N')$: we will have $n \geq
    N$ and $|a_n - c|$ as required.
    
  \item Now let's prove that $c$ is the \emph{only} limit point of
    $\seq{a_n}{m}$. Here, drawing a picture will help a lot. Let's
    suppose, for the sake of contradiction, that there exists another
    limit point $c' \neq c$ for $\seq{a_n}{m}$. Let's consider the
    positive real number $\epsilon = |c-c'| / 3$ (we know it is
    positive, because $c-c' \neq 0$ by hypothesis).

    Since $\seq{a_n}{m}$ converges to $c$, there exists a positive
    integer $N \geq m$ such that $|a_n - c| \leq \epsilon$ for all $n
    \geq N$. Also, since $c'$ is a limit point, there exists $n_0 \geq
    N$ such that $|a_{n_0} - c'| \leq \epsilon$. Thus:

    \begin{align*}
      |c-c'| & \leq |c - a_{n_0} + a_{n_0} - c'| \\
             &\leq |a_{n_0} - c| + |a_{n_0} - c'| \\
             & \leq \frac{\epsilon}{3} + \frac{\epsilon}{3} =
      \frac{2\epsilon}{3} = \frac{2}{3} |c-c'|
    \end{align*}

    This is a clear contradiction. Thus, $\seq{a_n}{m}$ has no other
    limit point than $c$.
  \end{itemize}
\end{exo}

\begin{exo}{6.4.2}{State and prove analogues of Exercises 6.1.3 and
    6.1.4 for limit points, limit superior and limit inferior.}

  As stated before, Exercises 6.1.3 and 6.1.4 provided very similar
  statements, so that we'll just prove here the analogues for Exercise
  6.1.3. They can be stated as follows.

  Let $m' \geq m$ two positive integers, and $c$ a real number.

  \begin{enumerate}
  \item Statement for limit points: $c$ is a limit point for
    $\seq{a_n}{m}$ iff $c$ is a limit point for $\seq{a_n}{m'}$.

    Actually, $c$ is a limit point for $\seq{a_n}{m}$ iff:
    \begin{equation}
      \label{eq:642a1}
      \forall \epsilon > 0, \forall N \geq m, \exists n \geq N \; : \;
      |a_n -c| \leq \epsilon
    \end{equation}

    Similarly, $c$ is a limit point for $\seq{a_n}{m'}$ iff:
    \begin{equation}
      \label{eq:642a2}
      \forall \epsilon > 0, \forall N' \geq m', \exists n \geq N' \; : \;
      |a_n -c| \leq \epsilon
    \end{equation}

    \begin{itemize}
    \item First suppose that $c$ is a limit point for $\seq{a_n}{m}$,
      and let's show that it is a limit point for $\seq{a_n}{m'}$.
      Let be $\epsilon > 0$ a positive real and $N' \geq m'$ a positive
      integer. Since $m' \geq m$, we also have $N' \geq m$. Thus, by
      \eqref{eq:642a1}, we know that there exists $n \geq N'$ such that
      $|a_n-c|$, as required. Thus, $c$ is a limit point for
      $\seq{a_n}{m'}$.
    \item Now suppose that $c$ is a limit point for $\seq{a_n}{m'}$,
      and let's show that it is a limit point for $\seq{a_n}{m}$. Let
      be $\epsilon > 0$ a positive real and $N \geq m$ a positive
      integer. We can distinguish two sub-cases here. If $N \geq m'$,
      then \eqref{eq:642a2} indeed provides a $n \geq N$ such that
      $|a_n - c| \leq \epsilon$, as required. Else, if $m \leq N <
      m'$, then according to \eqref{eq:642a2}, there exists an $n \geq
      m'$ such that $|a_n -c| \leq \epsilon$. We thus have $m \leq N <
      m' \leq n$, i.e. in particular $N < n'$, and $|a_n -c| \leq
      \epsilon$, as required. Thus, in both sub-cases, $c$ is a limit
      point for $\seq{a_n}{m}$.
    \end{itemize}
    
  \item Statement for limit superior: $\ell$ is the limit superior of
    $\seq{a_n}{m}$ iff $\ell$ is the limit superior of
    $\seq{a_n}{m'}$.

    Actually, $\ell$ is the limit superior of $\seq{a_n}{m}$ iff:
    \begin{equation}
      \label{eq:642b1}
      \ell = \liminfp{a}{m}
    \end{equation}
    Similarly, $\ell'$ is the limit superior of $\seq{a_n}{m'}$ iff:
    \begin{equation}
      \label{eq:642b2}
      \ell' = \liminfp{a}{m'}
    \end{equation}

    First, note that the sequence $(a_N^+)^\infty_{N=m}$ is
    decreasing. In particular, thanks to Proposition 6.3.8, it means
    that its limit is equal to its greatest lower bound, i.e.,
    $\lim_{N \to +\infty} (a_N^+) = \inf (a_N^+)_{N=m}^\infty$. But we
    already know, thanks to Exercises 6.1.3 and 6.1.4, that this limit
    does not depend on the starting index of the sequence. Thus, we
    indeed have $\ell = \ell'$.
  \item The statement and proof for limit inferior are similar to the
    previous one, since the sequence $(a_N^-)^\infty_{N=m}$ is
    increasing.
  \end{enumerate}
\end{exo}

\begin{exo}{6.4.3}{Prove parts (c), (d) and (e) of Proposition
    6.4.12.}

  Let $\seq{a_n}{m}$ be a sequence of real numbers, $L^+$ its limit
  superior and $L^-$ its limit superior.
  
  \begin{enumerate}[label=\emph{(\alph*)}]
    \setcounter{enumi}{2}
  \item Prove that $\inf \seq{a_n}{m} \leq L^- \leq L^+ \leq \sup
    \seq{a_n}{m}$.

    We will prove each inequality separately.
    \begin{itemize}
    \item First let's prove that $\inf \seq{a_n}{m} \leq L^-$. By
      Definition 6.4.6, $L^- = \sup (a^-_N)_{N=m}^\infty$. Thus, we have
      $L^- \geq a^-_N$ for all $N \geq m$. In particular, for $N = m$,
      we have $L^- \geq a^-_m = \inf \seq{a_n}{m}$, as required.
    \item The proof for $L^+ \leq \sup \seq{a_n}{m}$ is similar. By
      Definition 6.4.6, $L^+ = \inf (a^+_N)_{N=m}^\infty$. Thus, we
      have $L^+ \leq a^+_N$ for all $N \geq m$. In particular, for
      $N = m$, we have $L^+ \leq a^+_m = \sup \seq{a_n}{m}$, as
      required.
    \item Finally, let's prove that $L^- \leq L^+$. Let be
      $\epsilon > 0$ a positive real. First, according to Proposition
      6.3.6, there exists a positive integer $N_1$ such that
      $a_{N_1}^- + \epsilon > L^- \geq a^-_{N_1}$. Similarly, there
      exists a positive integer $N_2$ such that
      $a_{N_2}^+ - \epsilon < L^+ \leq a_{N_2}^+$. Suppose that
      $N_1 \leq N_2$. Given that we have $a_N^- \leq a_N^+$ for all
      $N$, and that $(a^-_N)_{N = m}^\infty$ is an increasing
      sequence\footnote{Both results are easy to prove, although not
        stated explicitly in the main text.}, we get:
      \[ L^- - \epsilon \leq a^-_{N_1} \leq a^-_{N_2} \leq a^+_{N_2} <
        L^+ + \epsilon \]
      which leads to $L^- - L^+ \leq 2 \epsilon$ for all $\epsilon >
      0$. This implies that $L^- - L^+ \leq 0$ (otherwise we would
      have an obvious contradiction).

      The case $N_2 \leq N_1$ can be written in a similar fashion.

      Thus, the whole inequality is proven.
    \end{itemize}
  \item Prove that if $c$ is any limit point of $\seq{a_n}{m}$, then
    we have $L^- \leq c \leq L^+$.

    We only show here the inequality $c \leq L^+$; its counterpart
    $L^- \leq c$ can be proved the same way.

    Let's suppose, for the sake of contradiction, that we have
    $c > L^+$. Let be $\epsilon = \frac{c - L^+}{3}$, which is by
    hypothesis a positive real number. We have $L^+ + \epsilon > L^+$.
    Thus, by Proposition 6.4.2(a), there exists $N \geq m$ such that:
    \begin{equation}
      \label{eq:642d1}
      a_n < L^+ + \epsilon = \frac{2L^+ + c}{3} \text{ for all $n \geq N$}
    \end{equation}
    But this is a contradiction with the fact that $c$ is a limit
    point for $\seq{a_n}{m}$. Indeed, if $c$ is a limit point, then
    there exists $n \geq N$ such that $|a_n - c| \leq \epsilon$,
    i.e.: $c-\epsilon < a_n  < c+\epsilon$, and in particular
    \begin{equation}
      \label{eq:642d2}
      a_n > c - \epsilon = \frac{3c-c+L^+}{3} = \frac{2c+L^+}{3}
    \end{equation}
    But equations \eqref{eq:642d1} and \eqref{eq:642d2} are
    incompatible, since they would lead to $a_n < \frac{2L^+ + c}{3} <
    \frac{2c+L^+}{3} < a_n$, i.e. $a_n < a_n$. Thus, our starting
    hypothesis $c \leq L^+$ is false, and we have necessarily $c >
    L^+$ as required.
  \item Prove that if $L^+$ is finite, then it is a limit point of
    $\seq{a_n}{m}$ (and similarly for $L^-$).

    Once again, we only give the proof for $L^+$, the other one being
    very similar.

    Let be $\epsilon > 0$ a positive real, and $N \geq m$ a positive
    integer. Since $L^+ + \epsilon > L^+$, according to Proposition
    6.4.2(a), there exists $N' \geq m$ such that
    $a_n < L^+ + \epsilon$ for all $n \geq N'$. In particular, if
    $n \geq M := \max(N, N')$, then we have $a_n < L^+ + \epsilon$.

    Also, we have $L^+ - \epsilon < L^+$. Thus, according to
    Proposition 6.4.2(b), there exists $n \geq M$ such that
    $a_n > L^+ - \epsilon$.

    Thus, for any given $\epsilon > 0$ and any given $N \geq m$, there
    exists $n \geq M \geq N$ such that
    $L^+ - \epsilon < a_n < L^+ + \epsilon$, i.e.
    $|a_n - L^+| \leq \epsilon$. $L^+$ is thus a limit point, as
    required.

    
  \item Prove that $\seq{a_n}{m}$ converges to $c$ iff $L^+ = L^- =
    c$.

    \begin{itemize}
    \item First, let's suppose that $L^+ = L^- = c$. According to
      Proposition 6.4.5, if $\seq{a_n}{m}$ is a convergent sequence,
      then its limit is a limit point. But according to Proposition
      6.4.2(d), if $L^- = L^+ = c$, the only possible limit point for
      $\seq{a_n}{m}$ is $c$. However, we have only shown that \emph{if
        $\seq{a_n}{m}$ is a convergent sequence, then it converges to
        $c$}, but we do not know whether or not $\seq{a_n}{m}$ is
      convergent.

      Let be $\epsilon > 0$. According to Proposition 6.4.2(a), if
      $x = L^+ + \epsilon = c + \epsilon > L^+$, then there exists
      $N \geq m$ such that $a_n < c + \epsilon$ for all $n \geq N$.
      Similarly, since $y = L^- - \epsilon = c - \epsilon < L^-$, then
      there exists $N' \geq m$ such that $a_n > c - \epsilon$ for all
      $n \geq N'$.
      
      Thus, for all $n \geq \max(N,N')$, we have $c - \epsilon < a_n <
      c + \epsilon$, i.e. $|a_n -c| \leq \epsilon$. This means that
      $\seq{a_n}{m}$ converges to $c$.
    \item Conversely, let's suppose that $\seq{a_n}{m}$ converges to
      $c$.

      Let be $\epsilon > 0$. First, since $\seq{an}{m}$ converges to
      $c$, there exists $N \geq m$ such that
      $|a_n - c| \leq \epsilon/2$ for all $n \geq N$. Also, since
      $L^-$ is a limit point, there exists $k \geq N$ such that
      $|a_k - L^-| \leq \epsilon/2$. Thus, we have both
      $|a_k - c| \leq \epsilon/2$ and $|a_k - L^-| \leq \epsilon/2$.

      We then derive, by triangular inequality:
      $|L^- - c| \leq |L^- - a_n| + |a_n - c| \leq \epsilon/2 +
      \epsilon/2 = \epsilon$. This means that $|L^- - c| \leq
      \epsilon$ for all $\epsilon > 0$, which is equivalent to $L^- =
      c$.

      Similarly, we could prove that $c = L^+$.

      Finally, we indeed have $L^- = c = L^+$ as required.
    \end{itemize}
\end{enumerate}
\end{exo}

\begin{exo}{6.4.4}{Prove Lemma 6.4.13.}

  Let be $\seq{a_n}{m}$ and $\seq{b_n}{m}$ two sequences of real
  numbers, such that $a_n \leq b_n$ for all $n \geq m$. We will prove
  the four statements of this lemma.

  \begin{enumerate}
  \item Prove that $\sup \seq{a_n}{m} \leq \sup \seq{b_n}{m}$.

    Let be $B = \sup \seq{b_n}{m}$. By definition, $B$ is an upper
    bound for $\seq{b_n}{m}$, so that we have $B \geq b_n \geq a_n$
    for all $n \geq m$. In particular, $B$ is also an upper bound for
    $\seq{a_n}{m}$. And, by Definition 5.5.5 of a least upper bound,
    we thus have $B \geq \sup \seq{a_n}{m}$ as required.
  \item Prove that $\inf \seq{a_n}{m} \leq \inf \seq{b_n}{m}$.

    A very similar argument applies. Let be $A = \sup \seq{a_n}{m}$.
    By definition, $A$ is an lower bound for $\seq{a_n}{m}$, so that
    we have $A \leq a_n \leq b_n$ for all $n \geq m$. In particular,
    $A$ is also a lower bound for $\seq{b_n}{m}$. We thus have
    $A \leq \inf \seq{b_n}{m}$ as required.
  \item Prove that $\limsup a_n \leq \limsup b_n$.

    Let be, for any $N \geq m$, $a_N^+ = \sup \seq{a_n}{N}$, and
    $b_N^+ = \sup \seq{b_n}{N}$. According to the first point of this
    exercise, we have $a_N^+ \leq b_N^+$ for all $N \geq m$. According
    to the second point, we have
    $\inf (a_N^+)_{N=m}^{\infty} \leq \inf (b_N^+)_{N=m}^\infty$, i.e.
    $\limsup a_n \leq \limsup b_n$ as required.
  \item Prove that $\liminf a_n \leq \liminf b_n$.

    Once again, the proof is similar to the previous point.
  \end{enumerate}
\end{exo}

\begin{exo}{6.4.5}{Use Lemma 6.4.13 to prove Corollary 6.4.14.}

  Let $\seq{a_n}{m}, \seq{b_n}{m}, \seq{c_n}{m}$ be sequences of real
  numbers such that $a_n \leq b_n \leq c_n$ for all $n \geq m$; and
  the sequences $\seq{a_n}{m}$ and $\seq{c_n}{m}$ converge to $L$.

  According to Corollary 6.4.14, we have
  $\limsup a_n \leq \limsup b_n \leq \limsup c_n$. But according to
  Proposition 6.4.12(f), when a sequence converges to a real number
  $L$, its limit superior is simply equal to its limit $L$. Thus, we
  have $L = \limsup a_n \leq \limsup b_n \leq \limsup c_n = L$, i.e.
  $\limsup b_n = L$.

  The same statement apply for $\liminf b_n$, which is also equal to
  $L$.

  Thus, still according to Proposition 6.4.12(f), $\seq{b_n}{m}$
  converges to $L$, as required.  
\end{exo}

\bigskip
\begin{exo}{6.4.6}{Give an example of two bounded sequences
    $\seq{a_n}{1}$ and $\seq{b_n}{1}$ such that $a_n < b_n$ for all
    $n \geq 1$, but that $\sup \seq{a_n}{1} \nless \seq{b_n}{1}$.
    Explain why this does not contradict Lemma 6.4.13.}

  The sequences defined by $a_n = -1/n$ and $b_n = 0$ for all $n \geq
  1$ are suitable, since $-1/n < 0$ for all $n \geq 1$, but both least
  upper bounds are equal to 0.

  This does not contradict Lemma 6.4.13 which deals with large
  inequalities; instead, it is even perfectly in accordance with
  Remark 5.4.11 in the previous chapter.
\end{exo}

\bigskip
\begin{exo}{6.4.7}{Prove Corollary 6.4.17.}

  This corollary says that $\seq{a_n}{m}$ converges to $0$ iff
  $\seq{|a_n|}{m}$ converges to $0$. Let's denote $b_n = |a_n|$ in
  what follows.
  
  \begin{itemize}
  \item First suppose that $\limit{|a_n|} = 0$. We know that we have,
    for all $n \geq m$, $-|a_n| \leq a_n \leq |a_n|$. According to the
    squeeze test, we have indeed $\limit{a_n} = 0$.
  \item Now suppose that $\limit{a_n} = 0$. Let $\epsilon > 0$ be a
    positive real number. We have $|b_n - 0| = |b_n| = ||a_n|| = |a_n|
    = |a_n - 0|$. We know, by definition, that there exists $N \geq m$
    such that, for all $n \geq N$, we have $|a_n - 0| \leq \epsilon$,
    and thus $|b_n - 0| \leq \epsilon$. This means that $\seq{b_n}{m}$
    converges to $0$, as required.
  \end{itemize}
\end{exo}

\begin{exo}{6.5.1}{Show that $\limit{1/n^q} = 0$ for any rational $q >
    0$.}

  Since $q$ is a positive rational, let's suppose that $q := a/b$,
  with $a, b > 0$ two positive integers. With a little algebra, we can
  rewrite $1/n^q = (1/n)^q = (1/n)^{a/b} = ((1/n)^{1/b})^a$, using in
  particular Definition 5.6.7, and in a somewhat hidden manner,
  equation \eqref{eq:562e} from this document.
  
  Using Corollary 6.5.1, we know that $\limit{1/n^{1/k}} = 0$ for
  every integer $k \geq 1$. In particular, we have
  $\limit{(1/n)^{1/b}} = \limit{(1/n^{1/b})} = 0$. Thus, using the
  limit laws (Theorem 6.1.19(b), iterated $a$ times), we conclude that
  $ \limit{1/n^q} = \limit{(1/n^{1/b})^a} = 0^a = 0$.
\end{exo}

\begin{exo}{6.5.2}{Prove Lemma 6.5.2.}

  Here, there are a lot of cases to consider.

  \begin{itemize}
  \item First, if $x = 1$, then $x^n = 1$ for all $n \geq 1$, so that
    $(x^n)_n$ is a constant sequence. Thus, $\limit{x^n} = 1$.
  \item Similarly, if $x = 0$, then $\limit{x^n} = 0$.
  \item If $-1 < x < 1$ and $x \neq 0$, we have $0 < |x| < 1$. This
    means, according to Proposition 6.3.10, that $\limit{|x|^n} = 0$.
    But, we can note that we have, for all $n \geq 1$, the inequality
    $-|x^n| \leq x^n \leq |x|^n$. Since
    $\limit{|x|^n} = \limit{-|x|^n} = 0$, then according to the
    squeeze test, we also have $\limit{x^n} = 0$.
  \item If $x = -1$, then the sequence $(x^n)_n$ is alternatively
    equal to $1$ or $-1$. Consequently, it has two limits points,
    which are $1$ and $-1$; it is even possible to show that $L^- =
    -1$ and $L^+ = 1$. Thus, it cannot converge, since a convergent
    sequence has only one limit point, and cannot have $L^- \neq L^+$.
  \item If $x > 1$, then Exercise 6.3.4 says that the sequence
    $(x^n)_n$ is divergent.
  \item Finally, if $x <- 1$, then the exact same reasoning performed
    in Exercise 6.3.4 would also prove that $(x^n)_n$ is divergent.
  \end{itemize}

  Thus, as required, we have shown that $\limit{x^n}$ exists and is
  equal to zero when $|x| < 1$, exists and is equal to 1 when $x=1$,
  and diverges when $x=-1$ or when $|x| > 1$.
\end{exo}

\bigskip

\begin{exo}{6.5.3}{Prove Lemma 6.5.3. (You may need to treat the cases
    $x \geq 1$ and $x < 1$ separately. You might wish to ﬁrst use
    Lemma 6.5.2 to prove the preliminary result that for every
    $\epsilon > 0$ and every real number $M > 0$, there exists an $n$
    such that $M^{1/n} \leq 1 + \epsilon$.)}

  We first prove the preliminary result suggested by Terence Tao. Let
  be $\epsilon > 0$ a positive real number, so that
  $1 + \epsilon > 1$. By Lemma 6.5.2, this implies that the sequence
  $\seq{a_n}{1}$ defined by $a_n = (1+\epsilon)^n$ diverges.
  Furthermore, by Lemma 5.6.9(e), $(1+\epsilon)^n$ is a strictly
  increasing function of $n$. It cannot be bounded because, by
  Proposition 6.3.8, it would imply that $\seq{a_n}{1}$ is a
  convergent sequence. Thus, $\seq{a_n}{1}$ is strictly increasing and
  not bounded above. In other words, for all $M > 0$, there exists a
  natural number $N$ such that $(1+\epsilon)^N \geq M$; and since we
  have an increasing function of $n$, we even get
  $(1+\epsilon)^n \geq M$ for all $n \geq N$. This is equivalent to
  $(1+\epsilon) \geq M^{1/n}$ by Lemma 5.6.6(d), which proves this
  preliminary result.

  \smallskip
  Let's go back to the main claim. We'll distinguish two cases. Let be
  $\epsilon > 0$.

  \begin{enumerate}
  \item If $x \geq 1$, we have $x^{1/n} > 1$ for all $n \geq 1$
    (because if we suppose, for the sake of contradiction, that
    $x^{1/n} < 1$, we would have $(x^{1/n})^n < 1^n$, i.e. $x<1$).
    Thus, we have $0 < x^{1/n} - 1$ for all $n \geq 1$. Furthermore,
    according to the preliminary result, there exists an $N$ such that
    $x^{1/n}-1 \leq \epsilon$ for all $n \geq N$. We thus have $-
    \epsilon \leq 0 \leq x^{1/n} - 1 \leq \epsilon$ for all $n \geq N$,
    i.e. $|x^{1/n} - 1| \leq \epsilon$ for all $n \geq N$. This means
    that $\limit{x^{1/n}} = 1$, as required.
  \item If $x < 1$, we have $1/x > 1$. Thus, when considering $1/x$,
    we are back to the previous case, i.e. we have
    $\limit{(1/x)^{1/n}} = 1$. But, by Lemma 5.6.9(b), we have
    $(1/x)^{1/n} = (x^{-1})^{1/n} = x^{-1/n} = 1/x^{1/n}$. Thus, we
    have $\limit{1/x^{1/n}} = 1$. Finally, by the limit laws (Theorem
    6.1.19(e)), we get $\limit{x^{1/n}} = 1/1 = 1$, as required.
  \end{enumerate}
\end{exo}

\begin{exo}{6.6.1}{Prove Lemma 6.6.4.}

  This lemma states that being a subsequence is reflexive and
  transitive.

  \begin{itemize}
  \item Let's show that $\seq{a_n}{1}$ is a subsequence of
    $\seq{a_n}{1}$. This is obvious: let's take the strictly
    increasing function $f(n) = n$ for all $n \in \nn^*$: this will
    indeed give $a_n = a_{f(n)}$, i.e. $\seq{a_n}{1}$ as a subsequence
    of $\seq{a_n}{1}$.
  \item Now consider that $\seq{b_n}{1}$ is a subsequence of
    $\seq{a_n}{1}$, and that $\seq{c_n}{1}$ is a subsequence of
    $\seq{b_n}{1}$. It means that we have, for all $n \in \nn^*$,
    $b_n = a_{f(n)}$ and $c_n = b_{g(n)}$, with $f, g$ two strictly
    increasing functions from $\nn^*$ to $\nn^*$. The function
    $f \circ g$ is also strictly increasing, as the composition of two
    strictly increasing functions. Thus, we have $c_n = b_{g(n)} =
    a_{f\circ g(n)}$ for all $n \in \nn^*$, i.e. $\seq{c_n}{1}$ as a
    subsequence of $\seq{a_n}{1}$.
  \end{itemize}
\end{exo}

\begin{exo}{6.6.2}{Can you find two sequences $\seq{a_n}{0}$ and
    $\seq{b_n}{0}$ which are not the same sequence, but such that each
      is a subsequence of the other?}

    It might appear counterintuitive, but the answer is yes! One can
    think of the sequences defined by $a_n = (-1)^n$ and $b_n =
    (-1)^{n+1}$. We have, for any natural number $n$, $a_n = b_{n+1}$
    and $b_n = a_{n+1}$. I.e., we have found a strictly increasing
    function $f : n \mapsto n+1$ such that $a_n = b_{f(n)}$ and $b_n =
    a_{f(n)}$ for all $n \in \nn$; and these sequences are not equal.

    Note that any example where $\seq{b_n}{0}$ is simply a ``shift''
    of a periodic sequence $\seq{a_n}{0}$ would do the trick. For
    instance, the sequence $a_n = 0, 0, 1, 1, 0, 0, \ldots$ and the
    sequence $b_n = 1, 1, 0, 0, 1, 1, \ldots$, with the function $f :
    n \mapsto n+2$.
\end{exo}
\bigskip

\begin{exo}{6.6.3}{Let $\seq{a_n}{0}$ be a sequence which is not
    bounded. Show that there exists a subsequence $\seq{b_n}{0}$ of
    $\seq{a_n}{0}$ such that $\limit{1/b_n}$ exists and is equal to
    zero. (Hint: for each natural number $j$, recursively introduce
    the quantity
    $n_j := \min \left\{n \in \nn \, : \, |a_n| \geq j, n > n_j
    \right\}$, omitting the condition $n > n_{j-1}$ when $j = 0$.
    First explain why the set
    $\left\{n \in \nn \, : \, |a_n| \geq j, n > n_j \right\}$ is
    non-empty; then set $b_j := a_{n_j}$. To ensure the existence and
    uniqueness of the minimum, one either needs to invoke the well
    ordering principle (which we have placed in Proposition 8.1.4, but
    whose proof does not rely on any material not already presented),
    or the least upper bound principle (Theorem 5.5.19).)}

  For any natural number $j$, let's denote $A_j := \left\{n \in \nn \, : \,
    |a_n| \geq j, n > n_{j-1}\right\}$, where $n_j$ is recursively defined
  by:
  \[
    \left \{
      \begin{array}{l @{\, := \,} l}
        n_0 & \min \left\{n \in \nn \, : \, |a_n| \geq 0 \right\} \\
        n_j & \min \left\{n \in \nn \, : \, |a_n| \geq j ; n > n_j \right\}
      \end{array}
    \right.
  \]

  \begin{itemize}
  \item For all natural number $j$, the set $A_j$ is non-empty because
    $\seq{a_n}{0}$ is not bounded. Indeed, let's suppose for the sake
    of contradiction that there exists a natural number $j$ such that
    $A_j = \emptyset$. It means that, for all natural numbers
    $n > n_j$, we have $|a_n| < j$. In such a case, $\seq{a_n}{j}$ is
    bounded by $j$, and thus $\seq{a_n}{0}$ is bounded by
    $M := \max(j, |a_0|, \ldots, |a_{j-1}|)$. This contradicts our initial
    hypothesis that $\seq{a_n}{0}$ is not bounded. Thus, $A_j$ is
    non-empty for all $j \in \nn$.
  \item $A_j$ also has a lower bound for all $j \in \nn$. Indeed, by
    definition, $n_{j-1}$ is a lower bound for $A_j$. So, $A_j$ is
    always non-empty and has a lower bound. Thus, by Theorem 5.5.19,
    $A_j$ has a greatest lower bound, that we will denote $\inf(A_j)$.
    (Furthermore, it is unique, by Theorem 5.5.18.)
  \item Let's show that $\inf(A_j) \in A_j$ for all $j \in \nn$. Since
    $\inf(A_j)$ is the greatest lower bound, $\inf(A_j) + 1/2$ is not
    a lower bound for $A_j$ (otherwise we would have an obvious
    contradiction). Thus, there exists $n \in A_j$ such that
    $\inf(A_j) \leq n < \inf(A_j) + 1/2$. Let's suppose, for the sake
    of contradiction, that there exists an $m \in A_j$ such that
    $m < n$. We would have $\inf(A_j) \leq m < n < \inf(A_j) + 1/2$,
    so that we could place two distinct integers within a range of
    width $1/2$, which is impossible\footnote{One may also give a
      proof by contradiction by writing
      $x + 1/2 - x = \underbrace{x+1/2 - m}_{>0} + \underbrace{m -
        n}_{>1} + \underbrace{n - x}_{>0}$, to prove this fact in this
      particular situation.}. Thus, we have $n \leq m$ for all
    $m \in A_j$. It means that $n$ is also a lower bound for $A_j$,
    and thus $n \leq \inf(A_j)$. And since we have both
    $n \leq \inf(A_j)$ and $n \geq \inf(A_j)$, we finally get
    $\inf(A_j) = n \in A_j$, as required\footnote{We actually have
      proven a generalizable lemma: for any non-empty set
      $X \subset \nn$, the greatest lower bound $\inf(X)$ is in $X$.
      This will be useful in Exercise 6.6.5 as well; and will be
      useful in Chapter 8. \label{note-borne-inf-n}}. Thus, the numbers $n_j$ are well-defined.
  \item Finally, let be $\epsilon > 0$ a positive real number, and a
    function $f : \nn \to \nn$ defined by $f(j) = n_j$. It is
    a strictly increasing function by definition of the numbers $n_j$.
    Let's consider the sequence $\seq{b_n}{0}$ defined by
    $b_j := a_{n_j} = a_{f(j)}$ for all $j \in \nn$.

    By definition, we also have $|a_{n_j}| \geq j$ for all
    $j \in \nn$, which is equivalent to $1/|a_{n_j}| \leq 1/j$.

    By the archimedean property (Corollary 5.4.13, and Exercise
    5.4.4), there exists a natural number $j$ such that
    $\epsilon > 1/j > 0$.

    Finally, let be a natural number $k > j$: we thus have $|a_{n_k}|
    \geq k > j$, i.e. $1/|a_{n_k}| < 1/j$.

    Thus, unwrapping all these findings: for any $\epsilon > 0$, there
    exists a natural number $j$ such that, for any $k > j$, we have
    $1/|a_{n_k}| = |b_{k} - 0| \leq 1/j \leq \epsilon$, i.e.,
    $\limit{b_n} = 0$, as required.
  \end{itemize}
\end{exo}

\medskip
\begin{exo}{6.6.4}{Prove Proposition 6.6.5. (Note that one of the two
    implications has a very short proof.)}

  First let's prove a preliminary result: if $f : \mathbb{N}
  \to \mathbb{N}$ is a strictly increasing function, then
  $f(n) \geq n$ for all $n \in \nn$. We can use induction on $n$:
  \begin{itemize}
  \item for the base case $n = 0$, we indeed have $f(0) \geq 0$
    because $f(0) \in \nn$;
  \item now suppose inductively that $f(n) \geq n$. Since $f$ is
    strictly increasing, we have $f(n+1) > f(n) \geq n$, and thus,
    $f(n+1) > n$, i.e. $f(n+1) \geq n+1$. This closes the induction
    for this preliminary result.
  \end{itemize}
 
  For the exercise itself, we must prove that the two statements ``The
  sequence $\seq{a_n}{0}$ converges to $L$'' and ``Every subsequence
  of $\seq{a_n}{0}$ converges to $L$'' are equivalent.

  \begin{itemize}
  \item First suppose that every subsequence of $\seq{a_n}{0}$
    converges to $L$. According to Lemma 6.6.4, $\seq{a_n}{0}$ is a
    subsequence of $\seq{a_n}{0}$, thus in particular, $\seq{a_n}{0}$
    converges to $L$.
    
  \item Now suppose that the sequence $\seq{a_n}{0}$ converges to $L$.
    Let be $\epsilon > 0$, and $f : \nn \to \nn$ a strictly
    increasing function such that $\seq{a_{f(n)}}{0}$ is a subsequence
    of $\seq{a_n}{0}$.

    Since $\seq{a_n}{0}$ converges to $L$, there exists a natural
    number $N$ such that $|a_n - L| \leq \epsilon$ for all $n \geq N$.
    But, according to our preliminary result, we have $f(n) \geq n$,
    and thus by transitivity, $f(n) \geq N$. This means that
    $|a_{f(n)} - L| \leq \epsilon$. Unfolding those findings: there
    exists an $N$ such that $|a_{f(n)} - L| \leq \epsilon$ for all $n
    \geq N$, i.e., $\seq{a_{f(n)}}{0}$ converges to $L$.
  \end{itemize}

  Thus, both statements are indeed equivalent.
\end{exo}

\bigskip

\begin{exo}{6.6.5}{Prove Proposition 6.6.6. (Hint: to show that (a)
    implies (b), deﬁne the numbers $n_j$ for each natural number $j$
    by the formula
    $n_j := \min \left\{n > n_{j-1} \, : \, |a_n - L| \leq 1/j
    \right\}$, with the convention $n_0 := 0$, explaining why the set
    $\left\{n > n_{j-1} \, : \, |a_n - L| \leq 1/j\right\}$ is
    non-empty. Then consider the sequence $a_{n_j}$. To ensure the
    existence and uniqueness of the minimum, one either needs to
    invoke the well ordering principle (which we have placed in
    Proposition 8.1.4, but whose proof does not rely on any material
    not already presented), or the least upper bound principle
    (Theorem 5.5.19).)}

  This exercise is pretty similar to Exercise 6.6.3, and we will
  re-use here a preliminary result shown there---see also note
  \ref{note-borne-inf-n}.


  \begin{enumerate}
  \item First we show that (b) implies (a). Let be $f : \nn
    \to \nn$ a strictly increasing function such that
    $\seq{a_{f(n)}}{0}$ converges to $L$. We must show that $L$ is a
    limit point of $\seq{a_n}{0}$, i.e. that:
    \begin{equation}
      \label{eq:665a}
      \forall \epsilon > 0, \, \forall N \geq 0, \, \exists n \geq N \;
      : \; |a_n - L| \leq \epsilon
    \end{equation}
    So let be $\epsilon > 0$ and $N \geq 0$. If $\seq{a_{f(n)}}{0}$
    converges to $L$, there exists $M \geq 0$ such that
    $n \geq M \to |a_{f(n)} - L| < \epsilon$. We know that $f$
    is a strictly increasing function, so that $f(n) \geq n$ for all
    $n \in \nn$, as previously shown in Exercise 6.6.4. Thus, if one
    considers $p := \max(M, N)$, we have:
    \begin{itemize}
    \item $f(p) \geq p \geq N$
    \item $f(p) \geq p \geq M$, so that $|a_{f(p)} - L| \leq \epsilon$
    \end{itemize}
    Choosing $n := f(p) \geq N$, the condition in formula
    \eqref{eq:665a} is thus verified.
  \item Now we prove that (a) implies (b).
    \begin{itemize}
    \item First, we note that the set
      $\left\{n > n_{j-1} \, : \, |a_n - L| \leq 1/j\right\}$ is
      non-empty for all $j \geq 1$. For instance, with $j = 1$, this
      set is equal to $\left\{n > 0 \, : \, |a_n - L| \leq 1\right\}$:
      this set is non-empty since $L$ is a limit point of
      $\seq{a_n}{0}$. This gives an intuition for the general case.
      Generally speaking, let's suppose for the sake of contradiction
      that the set
      $A_j := \left\{n > n_{j-1} \, : \, |a_n - L| \leq 1/j\right\}$
      is non empty for one given $j \geq 1$. It means that we can
      define $\epsilon := 1/j$ and $N := n_{j-1}$ such that, for all
      $n \geq N$, we have $|a_n - L| > \epsilon$. This is precisely
      the negation of the fact that $L$ is a limit point of
      $\seq{a_n}{0}$ (see formula \eqref{eq:665a}): we have a clear
      contradiction. Thus, this set $A_j$ is non-empty for every
      natural number $j \geq 1$.
    \item Thus, for all $j \geq 1$, this set $A_j$ is non-empty, and
      it has a lower bound (for instance, $0$ is obviously a lower
      bound, since $A_j$ is a subset of $\nn$). By Theorem 5.5.9, we
      thus know that this set has a (unique) greatest lower bound,
      which we can write $\inf(A_j)$. By note \ref{note-borne-inf-n},
      we have $\inf(A_j) \in A_j$, i.e., $\inf(A_j) = \min(A_j) = n_j$
      is well-defined.
    \item Now let be $f : \nn \to \nn$ the strictly increasing
      function defined by $f(j) := n_j$; and let's consider the
      subsequence of $\seq{a_n}{0}$ defined by $a_{f(j)} = a_{n_j}$.
      Let be $\epsilon > 0$. By the archimedean property (or Exercise
      5.4.4), there exists a natural number $j \geq 1$ such that
      $\epsilon > 1/j > 0$. We thus have a natural number $n_j$ such
      that $|a_{n_j} - L| \leq 1/j < \epsilon$. Furthermore, if $k >
      j$, we have $n_k > n_j$, and thus we have: $|a_{n_k} - L| \leq
      1/k \leq 1/j < \epsilon$. Unfolding all these findings:
      \begin{equation}
        \label{eq:665b}
        \forall \epsilon > 0, \exists j \geq 1 \; : \; n \geq j
        \to |a_{f(j)} - L| \leq \epsilon
      \end{equation}
      which means that the subsequence $\seq{a_{f(n)}}{0}$ converges
      to $0$, as required.
    \end{itemize}    
  \end{enumerate}
\end{exo}

\pagebreak
\section{Series}
\begin{exo}{7.1.1}{Prove Lemma 7.1.4. (Hint: you will need to use
    induction, but the base case might not necessarily be at 0.)}

  Recall that, by Definition 7.1.1, a series $\sum_{i=m}^n a_i$ is
  recursively defined by $\sum_{i=m}^n a_i = 0$ for $n<m$,
  and $\sum_{i=m}^{n+1} a_i = \sum_{i=m}^n a_i + a_{n+1}$ for $m \geq
  n$.

  The claims to prove are the following.

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item For all integers $m \leq n < p$, we have $\sum_{i=m}^{n} a_i +
    \sum_{i=n+1}^{p} a_i = \sum_{i=m}^{p} a_i$.

    Let's use induction on $p$, while keeping $m, n$ fixed. Since we
    have $n < p$, the base case is $p = n+1$. For $p=n+1$, we have:
    \[ \sum_{i=m}^{n} a_i + \sum_{i=n+1}^{p} a_i = \sum_{i=m}^{n} a_i
      + \sum_{i=n+1}^{n+1} a_i = \sum_{i=m}^{n} a_i + a_{n+1} =
      \sum_{i=m}^{n+1} a_i = \sum_{i=m}^{p} a_i\] as expected. The
    base case is done. Now let's suppose inductively that
    $\sum_{i=m}^{n} a_i + \sum_{i=n+1}^{p} a_i = \sum_{i=m}^{p} a_i$,
    and let's prove that this equality still holds for $p+1$. We have:
    \begin{align*}
      \sum_{i=m}^{n} a_i + \sum_{i=m}^{p+1} &= \sum_{i=m}^{n} a_i +
                                              \sum_{i=m}^{p} a_i + a_{p+1}
                                              \text { (Definition 7.1.1)}
      \\
                                            &= \sum_{i=m}^p a_i + a_{p+1}
                                              \text{ (induction
                                              hypothesis)} \\
                                            &= \sum_{i=m}^{p+1} a_i
                                              \text{ (Definition 7.1.1)}
    \end{align*}
    which closes the induction and proves the equality for all
    integers $m \leq n < p$.
  \item For $k$ an integer, and $m \leq n$ two integers, we have
    $\sum_{i=m}^{n}a_i = \sum_{j=m+k}^{n+k} a_{j-k}$.

    Let's use induction on $n$, the ``offset'' $k$ being fixed. For
    the base case $n=m$, we have $\sum_{j=m+k}^{n + k} a_{j-k} =
    \sum_{j=m+k}^{m + k} a_{j-k} = a_{m+k-k} = a_m$. On the other hand, we also
    have $\sum_{i=m}^{n}a_i = \sum_{i=m}^{m} a_i = a_m$, which proves
    the base case.

    Now let's suppose inductively that $\sum_{i=m}^{n}a_i =
    \sum_{j=m+k}^{n+k} a_{j-k}$. We thus have:
    \begin{align*}
      \sum_{j=m+k}^{n+k+1} a_{j-k} &= \sum_{j=m+k}^{n+k} a_{j-k} +
                                     a_{n+1} \\
                                   &= \sum_{i=m}^n a_i + a_{n+1}
                                     \text{ (induction hypothesis)} \\
                                   &= \sum_{i=m}^{n+1} a_i
    \end{align*}
    which closes the induction, the property being true for all $n
    \geq m$, with any arbitrary offset $k$.
  \item For $m \leq n$ two integers, we have $\sum_{i=m}^{n} (a_i+b_i)
    = (\sum_{i=m}^{n} a_i) + (\sum_{i=m}^{n} b_i)$.

    Let's use induction on $n$. The base case is $m=n$ and is obvious,
    since we have on the one hand $\sum_{i=m}^{m} (a_i+b_i) = a_m +
    b_m$, and on the other hand $(\sum_{i=m}^{m} a_i) +
    (\sum_{i=m}^{m} b_i) = a_m + b_m$.

    Now let's suppose inductively that
    $\sum_{i=m}^{n} (a_i+b_i) = (\sum_{i=m}^{n} a_i) + (\sum_{i=m}^{n}
    b_i)$. Then we have:
    \begin{align*}
      \sum_{i=m}^{n+1} (a_i+b_i) &= \sum_{i=m}^{n} (a_i+b_i) + (a_{n+1}
                                   + b_{n+1}) \\
                                 &= \left(\sum_{i=m}^{n} a_i +
                                   \sum_{i=m}^{n} b_i\right) + a_{n+1}
                                   + b_{n+1} \text{ (induction
                                   hypothesis)} \\
                                 &= \sum_{i=m}^{n} a_i + a_{n+1} +
                                   \sum_{i=m}^{n} b_i + b_{n+1} \\
                                 &= \sum_{i=m}^{n+1} a_i +
                                   \sum_{i=m}^{n+1} b_i
    \end{align*}
    which closes the induction. The property is thus true for all $n
    \geq m$.
  \item For $m \leq n$ integers, and $c$ a real number, we have
    $\sum_{i=m}^{n}ca_i = c \left(\sum_{i=m}^{n}a_i\right)$.

    Let's induct on $n$, first considering the base case $n = m$. We
    have $\sum_{i=m}^{m} ca_i = c a_m =
    c\left(\sum_{i=m}^{m}a_i\right)$ as required.

    Now let's suppose inductively that
    $\sum_{i=m}^{n}ca_i = c \left(\sum_{i=m}^{n}a_i\right)$. Then we
    have:
    \begin{align*}
      \sum_{i=m}^{n+1}ca_i &= \sum_{i=m}^{n}ca_i + ca_{n+1} \\
                           &= c \left(\sum_{i=m}^{n}a_i\right) +
                             ca_{n+1} \text{ (induction hypothesis)}\\
                           &= c \left(\sum_{i=m}^{n}a_i +
                             a_{n+1}\right)\\
                           &= c \sum_{i=m}^{n+1} a_i
    \end{align*}
    which closes the induction. The property is thus true for all $n
    \geq m$.
  \item For $m \leq n$ integers, prove that $|\sum_{i=m}^{n}a_i| \leq
    \sum_{i=m}^{n} |a_i|$.

    Let's use induction on $n$, first considering the base case $n=m$.
    We have $|\sum_{i=m}^{m}a_i| = |a_m| = \sum_{i_m}^{m} |a_i|$, as
    required.

    Now let's suppose inductively that we have
    $|\sum_{i=m}^{n}a_i| \leq \sum_{i=m}^{n} |a_i|$. Then we have:
    \begin{align*}
      \aval{\sum_{i=m}^{n+1}a_i} & := \aval{\sum_{i=m}^{n} a_i + a_{n+1}} \\
                                & \leq \aval{\sum_{i=m}^{n} a_i} +
                                  |a_{n+1}| \text{ (Proposition
                                  4.3.3(b))} \\
                                 & \leq \sum_{i=m}^{n} |a_i| +
                                   |a_{n+1}| \text{ (induction
                                   hypothesis)} \\
                                 & \leq \sum_{i=m}^{n+1} |a_i|
    \end{align*}
    which closes the induction. The property is thus true for all $n
    \geq m$.
  \item For $m \leq n$ integers, prove that, if $a_i \leq b_i$ for all
    $m \leq i \leq n$, we have $\sum_{i=m}^{n} \leq \sum_{i=m}^{n}
    b_i$.

    Once again, let's use induction on $n$, starting with the base
    case $n = m$. In this case, we have $\sum_{i=m}^{n}a_i := a_m \leq
    b_m := \sum_{i=m}^{n} b_i$, as required.

    Now let's suppose inductively that we have
    $\sum_{i=m}^{n} \leq \sum_{i=m}^{n} b_i$. Then, if $a_{n+1} \leq
    b_{n+1}$, we have:

    \begin{align*}
      \sum_{i=m}^{n+1} a_i & := \sum_{i=m}^{n} a_i + a_{n+1} \\
                           & \leq \sum_{i=m}^n a_i + b_{n+1} \\
                           & \leq \sum_{i=m}^{n} b_i + b_{n+1} \text{
                             (induction hypothesis)} \\
                           & \leq \sum_{i=m}^{n+1} b_i
    \end{align*}
    which closes the induction. The property is thus true for all $n
    \geq m$.
  \end{enumerate}
\end{exo}

\begin{exo}{7.1.2}{Prove Proposition 7.1.11.}

  First recall the main definition: if $X$ is a finite set with $n$
  elements, $f : X \to \rr$ a function, and $g$ a bijection
  from $\intset{1}{n}$ to $X$, then we have
  $\sum_{x \in X}f(x) := \sum_{i=1}^{n}f(g(i))$.

  The statements to prove are:

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item If $X = \emptyset$ and $f$ is the empty function, we have
    $\sum_{x \in X} f(x) = 0$.

    In this case, $X$ has $n=0$ elements, and the empty function $g$
    is a bijection between $X$ and $\intset{1}{0}$, so that by
    definition, we have
    $\sum_{x \in X} f(x) = \sum_{i=1}^{0} f(g(i)) = 0$.
  \item If $X = \{x_0\}$, we have $\sum_{x \in X} f(x) = f(x_0)$.

    In this case, $X$ has $n = 1$ element, and $g : \{1\} \to
    X$ such that $g(1) = x_0$ is a bijection. Thus, by definition, we
    have $\sum_{x \in X} f(x) = \sum_{i=1}^{1} f(g(i)) = f(g(1)) =
    f(x_0)$.
  \item If $X$ is a finite set and $g : Y \to X$ a bijection,
    then $\sum_{x \in X} f(x) = \sum_{y \in Y} f(g(y))$.

    First note that since $g$ is a bijection, $Y$ also has $n$
    elements.

    On the one hand, since $X$ has $n$ elements, there exists a
    bijection $h : \intset{1}{n} \to X$ such that $\sum_{x \in
      X} f(x) = \sum_{i=1}^{n} f(h(i))$.

    On the other hand, let be $k : \intset{1}{n} \to Y$ a
    function defined by $k = g^{-1} \circ h$. Since $k$ is the
    composition of two bijections, it is itself a bijection (cf.
    Exercise 3.3.2). We thus have :
    $\sum_{y \in Y} f(g(y)) = \sum_{i=1}^{n}f \circ g \circ g^{-1}
    \circ h (i) = \sum_{i=1}^{n} f(h(i))$.

    Thus, we have indeed $\sum_{x \in X} f(x) = \sum_{y \in Y}
    f(g(y))$.
  \item For $n \leq m$ two integers and $X = \{i \in \zz \, : \, n
    \leq i \leq m\}$, we have $\sum_{i=n}^{m}a_i = \sum_{i \in X} a_i$.

    Let be $f : \intset{n}{m} \to X$ defined by $f(i) = a_i$ a
    function; so that we have
    $\sum_{i \in X} a_i = \sum_{i \in X} f(i)$. First of all, note
    that $X$ has $m-n+1$ elements. Furthermore, let be
    $g : \intset{1}{m-n+1} \to X$ the bijection defined by
    $g(i) = i+n-1$ (we could show rigorously that this function is
    bijective, but this is straightforward). We thus have, by
    definition:
    $\sum_{i \in X} a_i = \sum_{i \in X} f(i) = \sum_{i=1}^{m-n+1}
    f(g(i)) = \sum_{i=1}^{m-n+1} f(i+n-1) =
    \sum_{i=1}^{m-n+1}a_{i+n-1}$.

    Now we can use Lemma 7.1.4(b), to get $\sum_{i=1}^{m-n+1}a_{i+n-1}
    = \sum_{i=n}^{m} a_i$, so that we have finally showed that
    $\sum_{i \in X} a_i = \sum_{i=n}^{m} a_i$.
  \item If $X, Y$ are sets such that $X \cap Y = \emptyset$, and $f :
    X \cup Y \to \rr$, we have $\sum_{z \in X \cup Y} f(z) =
    \sum_{x \in X} f(x) + \sum_{y \in Y} f(y)$.

    Suppose that $X$ has $n$ elements and $Y$ has $m$ elements. Thus,
    there exist two bijections $g: \intset{1}{n} \to X$ and
    $h: \intset{1}{m} \to Y$. Thus, by definition, we have
    $\sum_{x \in X} f(x) = \sum_{i=1}^{n}f(g(i))$ and
    $\sum_{y \in Y} f(y) = \sum_{i=1}^{m}f(h(i))$.

    By Lemma 7.1.4(b), we have $\sum_{i=1}^{m} f(h(i)) =
    \sum_{i=n+1}^{n+m} f(h(i-n))$.

    Now let's construct a new function $k : \intset{1}{n+m}
    \to X \cup Y$, defined by: $k(i) = g(i) \in X$ if $1 \leq i \leq
    n$ and $k(i) = h(i) \in Y$ if $n+1 \leq i \leq n+m$. In
    particular, $k(i) \in X \cup Y$ for all $i \in \intset{1}{n+m}$.
    Let's prove that $k$ is a bijection.

    \begin{itemize}
    \item Let's suppose that there exists $z \in X \cup Y$ such that
      $k(i) \neq z$ for all $i \in \intset{1}{n+m}$. If $z \in X$,
      this means in particular that there exists one $z \in X$ such
      that $g(i) \neq z$ for all $i \in \intset{1}{n}$, a
      contradiction. A similar contradiction follows if $z \in Y$.
      Thus, $k$ is surjective.
    \item Now suppose that there exist two $i,j \in\intset{1}{n+m}$
      such that $k(i) = k(j)$. If both $i,j \in \intset{1}{n}$, it is a
      contradiction with the fact that $g$ is injective; a similar
      contradiction follows for $h$ if both $i,j \in \intset{n+1}{m}$.
      Finally, if $i \in \intset{1}{n}$ and $j \in \intset{n+1}{m}$
      (or the converse), it is a contradiction with the fact that $X
      \cap Y = \emptyset$. Thus, $k$ is injective.
    \end{itemize}

    Thus, we have:
    \begin{align*}
      \sum_{x \in X \cup Y} f(x) &= \sum_{i=1}^{n+m}f(k(i)) \\
                         &= \sum_{i=1}^{n}f(k(i)) +
                           \sum_{i=n+1}^{n+m}f(k(i)) \text{ (by Lemma
                           7.1.4(a))} \\
                         &= \sum_{i=1}^{n}f(g(i)) +
                           \sum_{i=n+1}^{n+m}f(h(i)) \\
                         &= \sum_{x \in X} f(x) + \sum_{y \in Y} f(y)
    \end{align*}
    as required, which closes the proof.
  \item If $X$ is a finite set, then we have $\sum_{x \in X} (f(x) +
    g(x)) = \sum_{x \in X} f(x) + \sum_{x \in X} g(x)$.

    Suppose that $X$ has $n$ elements, so that there exists a
    bijection $h : \intset{1}{n} \to X$. Then we have:
    \begin{align*}
      \sum_{x \in X} f(x) + g(x) & := \sum_{i=1}^{n} f(h(i)) + g(h(i))
      \\
                                 & = \sum_{i=1}^{n} f(h(i)) +
                                   \sum_{i=1}^{n} g(h(i)) \text{
                                   (Lemma 7.1.4(e))} \\
                                 & := \sum_{x \in X} f(x) + \sum_{x
                                   \in X} g(x)
    \end{align*}
    
  \item If $c$ is a real number, the we have $\sum_{x \in X} cf(x) = c
    \sum_{x \in X} f(x)$.

    If we define a function $g$ as $g(x) := cf(x)$, and $h$ a
    bijection $\intset{1}{n} \to X$, we have:
    
    \begin{align*}
      \sum_{x \in X} cf(x) &= \sum_{x \in X} g(x) = \sum_{i=1}^{n} g(h(i)) = \sum_{i=1}^n cf(h(i)) \\
                           &= c \times \sum_{i=1}^{n} f(h(i)) \text{
                             (Lemma 7.1.4(d))} \\
                           &= c \times \sum_{x \in X} f(x)
    \end{align*}
  \item If $f,g$ are functions such that $f(x) \leq g(x)$ for all $i
    \in \rr$, then we have $\sum_{x \in X} f(x) \leq \sum_{x \in X}
    g(x)$.

    If $X$ has $n$ elements, let $h : \intset{1}{n} \to X$ be
    a bijection. Then we have:
    \begin{align*}
      \sum_{x \in X} f(x) &= \sum_{i=1}^{n} f(h(i)) \\
                     & \leq \sum_{i=1}^{n} g(h(i)) \text{ (Lemma
                       7.1.4(f))} \\
                     &= \sum_{x \in X} g(x)
    \end{align*}
  \item Triangle inequality: we have $\aval{\sum_{x \in X} f(x)} \leq
    \sum_{x \in X} |f(x)|$.

    If we consider the function $k : X \to \rr$ such that
    $k(x) = |f(x)|$ for all $x \in X$; and $h : \intset{1}{n}
    \to X$ a bijection, we have:
    \begin{align*}
      \aval{\sum_{x \in X} f(x)} &= \aval{\sum_{i=1}^{n} f(h(i))} \\
                                 & \leq \sum_{i=1}^{n} |f(h(i))|
                                   \text{ (Lemma 7.1.4(e))} \\
                                 & = \sum_{i=1}^{n} k(h(i)) = \sum_{x
                                   \in X} k(x) \\
                                 &= \sum_{x \in X} |f(x)|
    \end{align*}
  \end{enumerate}
\end{exo}

\begin{exo}{7.1.4}{Deﬁne the factorial function $n!$ for natural
    numbers $n$ by the recursive definition $0! := 1$ and
    $(n + 1)! := n! \times (n + 1)$. If $x$ and $y$ are real numbers,
    prove the binomial formula
    $(x + y)^n = \sum_{j=0}^n \frac{n!}{j!(n - j)!} x^{j}y^{n-j}$ for
    all natural numbers $n$. (Hint: induct on $n$.)}

  First we begin with a small preliminary result, which is that for
  all $n, j$ natural numbers, we have
  $\frac{(n+1)!}{j! (n+1-j)!} = \frac{n!}{(j-1)! (n-j+1)!} +
  \frac{n!}{j! (n-j)!}$. Indeed:
  \begin{align*}
    \frac{n!}{(j-1)! (n-j+1)!} +
    \frac{n!}{j! (n-j)!} &= \frac{n! \times j}{j! (n-j+1)!} + \frac{n!
                           \times (n-j+1)}{j! (n-j+1)!} \\
                         &= \frac{n! \times (n+1)}{j! (n-j+1)!} \\
    &= \frac{(n+1)!}{j! (n+1-j)!}
  \end{align*}


 Now we can go back to the main proof, for which we will induct on $n$.
  \begin{itemize}
  \item Let's start with the base case $n=0$. On the one hand,
    by Definition 5.6.1, we have $(x+y)^0 = 1$. On the other hand, we
    have
    $\sum_{j=0}^{0} \frac{n!}{j!(n - j)!} x^{j}y^{n-j} = \frac{0!}{0!
      \times 0!} x^0 y^0 = 1$, so that the base case is done.

  \item Now suppose inductively that we have
    $(x + y)^n = \sum_{j=0}^n \frac{n!}{j!(n - j)!} x^{j}y^{n-j}$, and
    let's prove that this property is still true for $n+1$. We have:

    \begin{align*}
      (x+y)^{n+1} &= (x+y) \times (x+y)^n \\
                  &= x \left(\sum_{j=0}^n
                    \frac{n!}{j!(n - j)!} x^{j}y^{n-j} \right) + y \left( \sum_{j=0}^n
                    \frac{n!}{j!(n - j)!} x^{j}y^{n-j} \right) \text{ (by induction
                    hypothesis)} \\
                  &= \left(\sum_{j=0}^n
                    \frac{n!}{j!(n - j)!} x^{j+1}y^{n-j} \right) + \left(\sum_{j=0}^n
                    \frac{n!}{j!(n - j)!} x^{j}y^{n-j+1} \right) \\
                  &= \left( x^{n+1} + \sum_{j=0}^{n-1}
                    \frac{n!}{j!(n - j)!} x^{j+1}y^{n-j} \right) +
                    \left( y^{n+1} + \sum_{j=1}^{n}
                    \frac{n!}{j!(n - j)!} x^{j}y^{n-j+1} \right) \\
                  &= \left( x^{n+1} + \sum_{j=1}^{n}
                    \frac{n!}{(j-1)!(n - j +1)!} x^{j}y^{n-j+1} \right) +
                    \left( y^{n+1} + \sum_{j=1}^{n}
                    \frac{n!}{j!(n - j)!} x^{j}y^{n-j+1} \right) \\
                  &= x^{n+1} + \sum_{j=1}^{n}
                    \left(\frac{n!}{(j-1)!(n - j +1)!} +
                    \frac{n!}{j!(n - j)!}\right) x^{j}y^{n-j+1} +
                    y^{n+1} \\
                  &= x^{n+1} + \sum_{j=1}^{n}
                    \frac{(n+1)!}{j! (n +1 - j)!} x^{j}y^{n-j+1} + y^{n+1} \\
                    &= \sum_{j=0}^{n+1} \frac{(n+1)!}{j! (n +1 - j)!} x^{j}y^{n-j+1}
    \end{align*}
    so that the property is true for all natural number $n$.
  \end{itemize}
\end{exo}

\begin{exo}{7.1.5}{Let $X$ be a finite set, let $m$ be an integer, and
    for each $x \in X$ let $\seq{a_n(x)}{m}$ be a convergent sequence
    of real numbers. Show that the sequence
    $\seq{\sum_{x \in X} a_n(x)}{m}$ is convergent, and that
    $\limit{\sum_{x \in X} a_n(x)} = \sum_{x \in X} \limit{a_n(x)}$.}

  Let's suppose that $X$ has $r$ elements. Note that, in particular,
  the property is equivalent to $\limit{\sum_{i=1}^r a_n(h(i))} =
  \sum_{i=1}^r \limit{a_n(h(i))}$ for any bijection $h : \intset{1}{r}
  \to X$.

  Let's induct on $r$, the cardinality of $X$.

  \begin{itemize}
  \item We start with the base case $r=0$, i.e. $X = \emptyset$. In
    this case, by Proposition 7.1.11(a), we have immediately
    $\sum_{x \in X} a_n(x) = 0$, so that $\limit{\sum_{x \in X}
      a_n(x)} = 0$ as the limit of a constant sequence. Similarly, we
    have $\sum_{x \in X} \limit{a_n(x)} = 0$, as a sum over an empty
    set $X$. Thus, the base case is done.
  \item Now suppose inductively that $\limit{\sum_{x \in X} a_n(x)} =
    \sum_{x \in X} \limit{a_n(x)}$ when $X$ has $r$ elements, and
    let's show that this property is still true when $X$ has $r+1$
    elements.

    Let be $h : \intset{1}{r+1} \to X$ a bijection. By
    Definition 7.1.6, we have:
    \begin{align*}
      \sum_{x \in X} a_n(x) &= \sum_{i=1}^{r+1} a_n(h(i)) \\
                            &= \sum_{i=1}^r a_n(h(i)) + a_n(h(r+1))
    \end{align*}

    By the induction hypothesis, $\sum_{i=1}^r a_n(h(i))$ is a
    convergent sequence; and $a_n(h(r+1))$ is a convergent sequence by
    the initial hypothesis; so that we can apply Theorem 6.1.19(a):
    \begin{align*}
      \limit{\sum_{x \in X} a_n(x)} &= \limit{\left( \sum_{i=1}^r a_n(h(i)) +
                                      a_n(h(r+1)) \right)} \\
                                    &= \limit{\sum_{i=1}^r a_n(h(i))}
                                      + \limit{a_n(h(r+1))} \\
                                    &= \sum_{i=1}^r \limit{a_n(h(i))}
                                      + \limit{a_n(h(r+1))} \text{ (by
                                      induction hypothesis)} \\
                                    &= \sum_{i=1}^{r+1}
                                      \limit{a_n(h(i))} \text{
                                      (Definition 7.1.1)} \\
      &= \sum_{x \in X} \limit{a_n(x)} \text{ (by Proposition 7.1.11(c))}
    \end{align*}
    so that the property is also true when $X$ has $n+1$ elements.
    This closes the induction.
  \end{itemize}
\end{exo}

\begin{exo}{7.2.2}{Prove Proposition 7.2.5.}

  We have to prove that the formal series $\sum_{n=m}^\infty a_n$
  converges iff, for any $\epsilon > 0$, there exists an integer $N
  \geq m$ such that $\aval{\sum_{n=p}^q a_n} \leq \epsilon$ for all $p, q
  \geq N$.

  First, note that the second statement is just another way to say
  that the partial sum $S_n = \sum_{i=m}^n a_n$ is a Cauchy sequence.
  Indeed, for $q \geq p \geq N$, we have
  $\aval{S_q - S_p} = \aval{\sum_{n=m}^q a_n - \sum_{n=m}^p a_n} =
  \aval{\sum_{n=p}^q a_n}$ (by Lemma 7.1.4(a)). Thus, the equivalence
  to prove is simply the fact that $\sum_{n=m}^\infty a_n$
  converges iff the sequence of its partial sums $(S_N)_{N=m}^\infty$ is a
  Cauchy sequence. Proposition 6.1.12 and Theorem 6.4.18 immediately
  provide this equivalence.
  
\end{exo}

\bigskip

\begin{exo}{7.2.3}{Prove Corollary 7.2.6.}

  Let's suppose that $\sum_{n=m}^\infty a_n$ is a convergent sequence.
  Thus, according to Proposition 7.2.5 (see also previous exercise),
  for all $\epsilon > 0$, there exists $N \geq 0$ such as $p,q \geq N
  \Longrightarrow \aval{\sum_{n=p}^q a_n} \leq \epsilon$.

  In particular, let's take $p=q$, and we have $|a_p| \leq \epsilon$
  for all $p \geq N$, which says precisely that $\seq{a_n}{m}$
  converges to 0.
\end{exo}
\bigskip

\begin{exo}{7.2.5}{Prove Proposition 7.2.14.}

  We have to prove several statements here:

  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Let's consider the partial sums $S_N := \sum_{n=m}^{N} a_n$
    and $T_N := \sum_{n=m}^{N} b_n$. Saying that the formal series
    $\sum_{n=m}^{\infty} a_n$ and $\sum_{n=m}^{\infty} b_n$ are
    convergent means that the sequences of their partials sums,
    $(S_N)_{N=m}^\infty$ and $(T_N)_{N=m}^\infty$ are convergent,
    towards $x$ and $y$ respectively.

    By Theorem 6.1.19(a), the sequence $(S_N + T_N)_{N=m}^\infty$
    converges to $x+y$. But by definition, we have $S_N + T_N =
    \sum_{n=m}^{N} a_n + \sum_{n=m}^{N} b_n = \sum_{n=m}^{N} a_n +
    b_n$ by Lemma 7.1.4(c). It means that the partial sum of the
    formal series $\sum_{n=m}^\infty a_n + b_n$ converges to $x+y$, so
    that we have proved the result.
    
  \item The proof would be very similar to the previous one; just use
    Lemma 7.1.4(d) and Theorem 6.1.19(c) instead.

  \item For all integers $N \geq m$ and $k \geq 0$, we know by Lemma
    7.1.4(a) that we have
    $\sum_{n=m}^{N}a_n = \sum_{n=m}^{m+k-1}a_n + \sum_{n=m+k}^{N}a_n$.
    If we set $S_N := \sum_{n=m}^{N}a_n$;
    $x := \sum_{n=m}^{m+k-1}a_n$; and $T_N := \sum_{n=m+k}^{N}a_n$, we
    have for all $N \geq m$, the equality $S_N = x + T_N$. As a very
    general fact (not shown in the book, but easy to prove), the
    sequence $(S_N)_{N=m}^\infty$ converges to $L$ iff the sequence
    $(T_N)_{N=m}^\infty$ converges to $L-x$. The statement follows.
    
  \item Let be $\epsilon > 0$ a positive real number. Since the formal
    series $\sum_{n=m}^{\infty}a_n$ converges to $x$, there exists a
    positive integer $M$ such that
    $|\sum_{n=m}^N a_n - x| \leq \epsilon$ for all $N \geq M$. By
    Lemma 7.1.4(b), this is equivalent to
    $|\sum_{n=m+k}^{N+k} a_{n-k} - x| \leq \epsilon$, for $k$ a
    positive integer and for all $N \geq M$.

    Thus, there exists a positive integer $M' := M+k$ such that, for
    all $N \geq M'$, we have $|\sum_{n=m+k}^{N} a_{n-k} - x| \leq
    \epsilon$, which means that $\sum_{n=m+k}^{\infty}a_{n-k}$ also
    converges to $x$.
  \end{enumerate}  
\end{exo}

\begin{exo}{7.2.6}{Prove Lemma 7.2.15.}

  Let be $\seq{a_n}{0}$ a sequence that converges to 0, and let's
  consider the formal series $\sum_{n=0}^{\infty}(a_n - a_{n+1})$. Its
  partials sums are, for any integer $N \geq 0$, $S_N :=
  \sum_{n=0}^{N}(a_n - a_{n+1}) = a_0 - a_{N+1}$. This can be shown by
  an induction on $N \geq 0$:
  \begin{itemize}
  \item Let's start with the base case $N=0$. In this case, we have
    $S_0 = \sum_{n=0}^{0} (a_n - a_{n+1}) = a_0 - a1$, as expected.
  \item Now suppose inductively that the property for a given positive
    integer $N$, and let's show that it is still true for $N+1$. We
    have:
    \begin{align*}
      S_{N+1} & := \sum_{n=0}^{N+1}(a_n - a_{n+1}) \\
              &= \sum_{n=0}^{N} (a_n - a_{n+1}) + (a_{N+1} - a_{N+2})
                \text{ (Definition 7.1.1)} \\
              &= a_0 - a_{N+1} + a_{N+1} - a_{N+2} \text{ (induction
                hypothesis)} \\
              &= a_0 - a_{N+2}
    \end{align*}
    which closes the induction, so that the property is true for all
    $N \geq 0$.
  \end{itemize}

  Now, let be $\epsilon > 0$ a positive real number. Recall that
  $\seq{a_n}{0}$ converges to 0, so that there exists a positive
  integer $M \geq 0$ such that $|a_n| \leq \epsilon$ for all $n \geq
  M$. On the other hand, we have, for all $N \geq 0$, $|S_N - a_0| =
  |a_0 - a_{N+1} - a_0| = |a_{N+1}|$. Thus, there exists a positive
  integer $M' := M-1$ such that, for all $N \geq M'$, we have $|S_N -
  a_0| \leq \epsilon$. This means that $(S_N)_{N = 0}^\infty$
  converges to $a_0$, i.e. that the formal series
  $\sum_{n=0}^{\infty}(a_n - a_{n+1})$ converges to $a_0$, as required.
\end{exo}
\bigskip

\begin{exo}{7.3.1}{Use Proposition 7.3.1 to prove Corollary 7.3.2.}

  First, an important remark: if we have $|a_n| \leq b_n$ for all
  $n \geq m$, we have in particular $b_n \geq 0$ for all $n \geq m$,
  so that the formal series $\sum_{n=m}^{\infty} b_n$ is a series of
  non-negative numbers. Since it is convergent by hypothesis, it is
  thus possible to apply Proposition 7.3.1 to this series: there
  exists a real number $M$ such that $T_N := \sum_{n=m}^{N}b_n \leq M$
  for all $N \geq m$.

  \begin{itemize}
  \item First, let's show the first part of Corollary 7.3.2, that is
    to say that $\sum_{n=m}^{\infty} a_n$ is absolutely convergent as
    soon as $\sum_{n=m}^{\infty} b_n$ is convergent.

    Since we have $|a_n| \leq b_n$ for all $n \geq m$ by hypothesis,
    we have also for all $N\geq m$ the inequality
    $\sum_{n=m}^{N}|a_n| \leq \sum_{n=m}^N {b_n} \leq M$ by Lemma
    7.1.4(f), so that the formal series $\sum_{n=m}^{\infty}|a_n|$ is
    itself convergent by Proposition 7.3.1 again. This proves the
    first statement.
  \item Now let's prove that $\aval{\sum_{n=m}^{\infty}a_n} \leq
    \sum_{n=m}^{\infty} |a_n|$. This is actually simply Proposition
    7.2.9, so there is nothing to add here.
  \item Finally, let's prove that
    $\sum_{n=m}^{\infty}|a_n| \leq \sum_{n=m}^{\infty} b_n$. By
    Proposition 7.2.14(a)-(b), we know that, since
    $\sum_{n=m}^{\infty} |a_n|$ and $\sum_{n=m}^{\infty} b_n$ are
    convergent, then $\sum_{n=m}^{\infty}b_n - |a_n|$ is convergent,
    so that its partial sum $V_N := \sum_{n=m}^{N}b_n - |a_n|$
    converges to some limit $L$.
    Also, we already know that $b_n - |a_n| \geq 0$ for all
    $n \geq m$, so that $V_N \geq 0$ for all $N \geq m$, and thus $L
    \geq 0$ by Proposition 5.4.9.

    To summarize: $\sum_{n=m}^{\infty} (b_n - |a_n|) =
    \sum_{n=m}^{\infty}b_n - \sum_{n=m}^{\infty}|a_n| = L \geq 0$, and
    thus in particular, $\sum_{n=m}^{\infty}b_n \geq
    \sum_{n=m}^{\infty}|a_n|$, as required.

    This closes the proof.
  \end{itemize}  
\end{exo}

\begin{exo}{7.3.2}{Prove Lemma 7.3.3.}

  Let be $x$ a real number and let's consider the formal series
  $\sum_{n=0}^{\infty} x^n$.

  \begin{itemize}
  \item If $|x| \geq 1$, then $\seq{x^n}{0}$ does not converge to $0$,
    by Lemma 6.5.2. Thus, by the zero test (Corollary 7.2.6), the
    formal series $\sum_{n=0}^{\infty}x^n$ is not convergent.
  \item If $|x| < 1$, then let's prove that for all $N \geq 0$, the
    partial sum $S_N$ is equal to $\sum_{n=0}^{N}x^n$. Let's induct on
    $N$, starting with the base case $N=0$. In this case, we have $S_0
    = \sum_{n=0}^{0}x^n = 1$; and on the other side, we have
    $\frac{1-x^{N+1}}{1-x} = \frac{1-x}{1-x} = 1$, so the base case is
    done.

    Now let's suppose inductively that $S_N = \frac{1-x^{N+1}}{1-x}$
    and let's prove that this property still holds for $S_{N+1}$. On
    the one hand we have:
    \begin{align*}
      S_{N+1} & := \sum_{n=0}^{N}x^n + x^{N+1} \\
              &= \frac{1-x^{N+1}}{1-x} + x^{N+1} \text{ (induction
                hypothesis)} \\
              &= \frac{1 - x^{N+1} + (1-x)x^{N+1}}{1-x} \\
              &= \frac{1 - x^{N+2}}{1-x}
    \end{align*}
    as required, so that the property holds for all $N \geq 0$: we
    always have $S_N = \frac{1-x^{N+1}}{1-x}$.

    But, by Lemma 6.5.2 (combined with Exercise 6.1.4), we know that
    $\seq{x^{n+1}}{0}$ converges to 0; so that by the convergence
    laws, $(S_N)_{N=0}^\infty$ converges to $\frac{1}{1-x}$.

    However, this only shows that  $(S_N)_{N=0}^\infty$ is
    conditionally convergent. Actually, it is absolutely convergent.
    Indeed, according to Proposition 4.3.10(d), we have $|x^n| =
    |x|^n$, and the series $\sum_{n=0}^{\infty} |x|^n$ is convergent,
    by the previous result. This closes the proof.
  \end{itemize}
\end{exo}

\pagebreak
\section{Infinite sets}
\begin{exo}{8.1.1}{Let $X$ be a set. Show that $X$ is infinite if and
    only if there exists a proper subset $Y \subsetneq X$ of $X$ which
    has the same cardinality as $X$. (This exercise requires the axiom
    of choice, Axiom 8.1)}

  This exercise is about the characterization of Dedekind-infinite
  sets.

  \begin{itemize}
  \item First suppose that $X$ and $Y$ have the same cardinality, i.e.
    that there exists a bijection $f : Y \to X$ between $X$ and a
    proper subset $Y \subsetneq X$. For the sake of contradiction,
    let's suppose that $X$ is finite. Then, by
    definition\footnote{This is Definition 3.6.10, i.e. the definition
      of Cantor-finite sets.}, there exists $n \in \nn$ such that
    $\# X = n$. On the one hand, since $Y$ is a proper subset of $X$,
    by Proposition 3.6.14 (c), we must have $\#Y < \#X$, i.e.
    $\#Y < n$. On the other hand, since $f$ is a bijection, $X$ and
    $Y$ have the same cardinality, i.e. $\#Y = \#X = n$. Thus we have
    a contradiction; $X$ cannot be finite.
  \item Conversely, suppose that $X$ is infinite, and let's show that
    we can construct a bijection $f: X \to Y$ from $X$ to a proper
    subset $Y \subsetneq X$.

    We begin by defining recursively an infinite collection
    $A_0, A_1, A_2, \ldots$ of non-empty subsets of $X$. Since $X$ is
    infinite, in particular it is non-empty; thus by the lemma of
    single choice we can pick a $x_0 \in X$. We define
    $A_0 := \{a_0\}$. Now since $X$ is infinite, $X \backslash A_0$ is
    clearly non-empty, and thus we can also pick a
    $a_1 \in X \backslash A_0$. We can thus define the non-empty
    subset $A_1 := A_0 \cup \{a_1\}$. Recursively, let's suppose that
    $A_n$ has been defined and is a finite non-empty subset of $X$.
    Thus, the set $X \backslash \bigcup_{i=0}^n A_i$ is non-empty, so
    that we can pick a $a_{n+1}$ in it, and then form the set
    $A_{n+1} := A_n \cup \{a_{n+1}\}$. The axiom of (countable) choice
    ensures that we can repeat this recursive algorithm infinitely
    many times, to finally get the set $A := \bigcup_{n \in \nn} A_n$.

    Now let's define the proper subset $Y := X \backslash \{a_0\}$,
    and the following function $f : X \to Y$
    \[
      \left \{
        \begin{array}{r @{\;  = \;} ll}
          f(x) & x &\text{ if } x \in X \backslash A \\
          f(x) & a_{n+1} &\text{ if } x \in A, x = a_n
        \end{array}
      \right.
    \]

    One can clearly see that $f$ is a surjection, and also an
    injection. This closes the proof.
  \end{itemize}
  
\end{exo}

\begin{exo}{8.1.2}{Prove Proposition 8.1.4. (Hint: you can either use
    induction, or use the principle of inﬁnite descent, Exercise
    4.4.2, or use the least upper bound (or greatest lower bound)
    principle, Theorem 5.5.9.) Does the well-ordering principle work
    if we replace the natural numbers by the integers? What if we
    replace the natural numbers by the positive rationals? Explain.}

  Let be $X \subset \nn$ such that $\# X = p$; let's show that there
  exists $n \in X$ such that $n \leq m$ for all $m \in X$.

  We could indeed show this property by using the greatest lower bound
  principle: we have showed in Exercise 6.6.3 that, for every subset
  $X \subset \nn$, the greatest lower bound $\inf(X)$ belongs to $X$.
  But we will give here another proof, using induction on $p$.

  \begin{itemize}
  \item Let's start with the base case $n=1$ (note that the base case
    is not $n=0$, since $X$ is supposed to be non-empty). In such a
    case, $X$ is a singleton, i.e. there exists $n \in \nn$ such that
    $X = \{n\}$. By reflexivity, we have of course $n \leq n$, i.e. we
    have $n \leq m$ for all $m \in X$, as required.
  \item Now suppose inductively that the property is true for a
    cardinality of $p$, and let's show that it is still true if
    $\# X = p+1$. By Lemma 3.6.9, there exists $x \in \nn$ and a
    subset $Y \subset \nn$ with $\# Y = p$, such that $X = Y \cup
    \{x\}$. By the induction hypothesis, there exists $n \in Y$ such
    that $n \leq m$ for all $m \in Y$.

    Now, let be $n' := \min(n, x)$. We thus have $n' \leq n \leq m$
    for all $m \in Y$ (and thus, in particular, $n' \leq m$); and $n'
    \leq x$ by definition. Thus, we have $n' \leq m$ for all $m \in Y
    \cup \{x\}$, that is to say $n' \leq m$ for all $m \in X$, as
    required. This closes the induction.
  \end{itemize}

  Note that the well ordering principle does not apply for the
  integers, because a non-empty set of integers can have arbitrarily
  small negative numbers: consider for instance the set
  $A = \{\ldots, -3, -2, -1, 0\}$. This is not applicable to the
  positive rationals either: one can think of the set
  $B = \{1/n : n \in \nn^\star\}$, which has an infimum of $0$, but
  has no smallest element in $B$.
\end{exo}

\bigskip
\begin{exo}{8.1.3}{Fill in the gaps marked (?) in Proposition 8.1.5.}

  Those gaps only state a few results that we will better show below.

  \begin{enumerate}
  \item Show that the set $\{x \in X \, : \, x \neq a_m \text{ for all
    } m < n\}$ is infinite.

    By definition, we have
    $X = \{a_0, \cdots, a_{n-1}\} \cup \{x \in X \, : \, x \neq a_m
    \text{ for all } m < n\}$. Obviously, the set $\{a_0, \cdots,
    a_{n-1}\}$ is finite. Let's suppose for the sake of contradiction
    that $\{x \in X \, : \, x \neq a_m \text{ for all
    } m < n\}$ is also finite. Then, by Proposition 3.6.14(b), $X$
    would also be finite as the union of two finite sets, which is a
    contradiction.

  \item Show that $\seq{a_n}{0}$ is strictly increasing.

    By definition, we have:
    \begin{align*}
      a_n &:= \min \{x \in X \, : \, x \neq a_m
            \text{ for all } m < n\} \\
      a_{n+1} &:= \min \{x \in X \, : \,
                x \neq a_m \text{ for all } m < n+1\}
    \end{align*}

    Let's write $A_n := \{x \in X \, : \, x \neq a_m \text{ for all } m <
    n\}$; we thus have $A_{n+1} \subset A_n$ for all natural number
    $n$. Consequently, $\min A_{n+1} \geq \min A_n$ for all $n$; i.e.
    $a_{n+1} \geq a_n$ for all $n$. Furthermore, by definition,
    $a_{n+1} \neq a_n$, so that we finally have $a_{n+1} > a_n$ for
    all $n$, i.e. $\seq{a_n}{0}$ is a strictly increasing sequence.    

  \item Show that $a_n \neq a_m$ for all $n \neq m$.

    Suppose, for the sake of contradiction, that there exists two
    distinct natural numbers $n, m$ such that $a_n = a_m$. This would
    be a contradiction with the fact that $\seq{a_n}{0}$ is a strictly
    increasing sequence.

  \item Show that $a_n \in X$ for all $n \in \nn$.

    By Proposition 8.1.4 (well-ordering principle), the minimum of a
    subset of natural numbers is well-defined: $\min X = \inf X \in X$
    if $X \subset \nn$.

  \item Obvious statement, simple rephrasing of the definition.
    
  \item Show that $a_n \geq n$ for all $n$.

    This can be shown by a simple induction: $\seq{a_n}{0}$ is a
    strictly increasing sequence of natural numbers, so that $a_0 \geq
    0$ (base case), and if we suppose inductively that $a_n \geq n$,
    we thus have $a_{n+1} > a_n \geq n$, i.e. $a_{n+1} \geq n+1$. This
    closes the induction.
  \end{enumerate}
  
\end{exo}

\begin{exo}{8.1.4}{Prove Proposition 8.1.8.}

  Let $Y$ be a set, and $f : \nn \to Y$ a function (non
  necessarily bijective). We have to show that $f(\nn)$ is at most
  countable.

  Let's define the set
  $A := \{ n \in \nn \, : \, f(m) \neq f(n) \text{ for all } 0 \leq m < n
  \}$, intuitively the set of natural numbers $n$ such that $f(n)$
  does not appear in the sequence $f(0), \cdots, f(n-1)$. We write
  $f_{|A}$ the restriction of $f$ to $A$, and let's show that $f_{|A}$
  is a bijection from $A$ to $f(\nn)$.

  \begin{itemize}
  \item First, $f_{|A}$ is injective: let's suppose that we have two
    natural numbers $a, b \in A$ such that $f(a) = f(b)$. By
    definition of $A$, we must have $f(m) \neq f(a)$ for all $m < a$.
    Since $f(a) = f(b)$, we necessarily have $b \geq a$. Similarly, we
    must have $f(m) \neq f(b)$ for all $m < b$, which implies $a \geq
    b$. The two inequalities $a \geq b$ and $b \geq a$ imply $a=b$,
    which shows that $f_{|A}$ is injective.
  \item Now, let's prove that $f_{|A} : A \to f(\nn)$ is
    surjective. Let be $y \in f(\nn)$, and let's suppose, for
    the sake of contradiction, that $f(a) \neq y$ for all $a \in A$.

    By definition of $f(\nn)$, there exists $a_1 \in \nn$ such that
    $f(a_1) = y$. Since we suppose $f(a) \neq y$ for all $a \in A$, we
    have $a_1 \notin A$. By definition of the set $A$, it means that
    there exists a natural number $a_2 < a_1$ such that
    $f(a_2) = f(a_1) = y$, and still $a_2 \notin A$. Similarly, there
    exists a natural number $a_3 < a_2$ such that $a_3 \notin A$ and
    $f(a_3) = f(a_2) = f(a_1) = y$. Actually, we are constructing like
    this a sequence $\seq{a_n}{1}$ of natural numbers which is in
    infinite descent. But this is impossible (see Exercise 4.4.2).
    Thus, for every $y \in f(\nn)$, we necessarily have a $a \in A$
    such that $f(a) = y$; i.e., $f_{|A} : A \to f(\nn)$ is
    surjective.
  \end{itemize}

  Thus, $f_{|A} : A \to f(\nn)$ is bijective. By Corollary
  8.1.6, every subset of $\nn$ is at most countable, so that $A$
  (which is clearly a subset of $\nn$) is at most countable. And since
  $f(\nn)$ has the same cardinality as $A$, this shows that $f(\nn)$
  is at most countable and closes the proof.
\end{exo}

\bigskip
\begin{exo}{8.1.5}{Use Proposition 8.1.8 to prove Corollary 8.1.9.}

  We have to show the following claim: if $X$ is a countable set, and
  $f : X \to Y$ a function, then $f(X)$ is at most countable
  (i.e., any image of a countable set is itself countable).

  By definition, if $X$ is a countable set, there exists a bijective
  function $g : \nn \to X$. Let's consider the function
  $h = f \circ g$, which is a function from $\nn$ to $Y$. We will show
  that $f(X) = h(\nn)$.
  
  \begin{itemize}
  \item First, $f(X) \subseteq h(\nn)$. Indeed, let be $y \in f(X)$.
    By definition, there exists $x \in X$ such that $y = f(x)$. But
    since $g$ is bijective, there exists $n \in \nn$ such that $y=
    f(g(n))$, i.e., there exists $n \in \nn$ such that $y = h(n)$.
    Thus, $y \in h(\nn)$.
  \item Furthermore, $h(\nn) \subseteq f(X)$. Let be $y \in h(\nn)$.
    By definition, there exists $n \in \nn$ such that
    $y = h(n) = f \circ g(n) = f(g(n))$. But since $g(n) \in X$, we
    have $y = f(g(n)) \in f(X)$ as required.
  \end{itemize}

  Thus, we have indeed $f(X) = h(\nn)$, and since $h(\nn)$ is a
  countable set by Proposition 8.1.8, $f(X)$ is indeed countable.
\end{exo}

\bigskip
\begin{exo}{8.1.6}{Let $A$ be a set. Show that $A$ is at most
    countable if and only if there exists an injective map $f : A
    \to \nn$.}

  First suppose that there exists an injective function
  $f : A \to \nn$. By definition, $f$ is thus a bijection
  between $A$ and $f(A)$, and those two sets thus have the same
  cardinality. But since we have $f(A) \subset \nn$, the set $f(A)$ is
  at most countable by Corollary 8.1.6. Thus, $A$ is at most
  countable, as required.

  Now suppose that $A$ is at most countable. We have two options here:
  \begin{enumerate}
  \item If $A$ is countably infinite, then there exists a bijection $f
    : A \to \nn$, and in particular, $f$ is thus injective.
  \item If $A$ is finite, then $A$ has a finite number of
    elements---say $n$ elements. Consequently, there exists a
    bijective function $g : A \to \intset{1}{n}$. Now let be
    $f : A \to \nn$ such that $f(a) = g(a)$ for all $a \in A$.
    In particular, $f$ is injective---but not necessarily surjective.
  \end{enumerate}

  In both cases, we have found an injective map $f : A \to \nn$
  as required. This closes the proof.
\end{exo}

\bigskip
\begin{exo}{8.1.7}{Prove Proposition 8.1.10.}

  We have to prove that if $X$ and $Y$ are countable, then $X \cup Y$
  is countable. We follow the hint given by Terence Tao for this
  proof.

  Since $X$ and $Y$ are countable, there exist two bijections
  $f : \nn \to X$ and $g : \nn \to Y$. Let be
  $h : \nn \to X \cup Y$ a function defined by $h(2n) = f(n)$
  and $h(2n+1) = g(n)$ for all natural numbers $n$. Let's show that we
  have $h(\nn) = X \cup Y$.

  \begin{itemize}
  \item First, the fact that $h(\nn) \subset X \cup Y$ is obvious: for
    all $m \in \nn$, $h(m)$ belongs either to $X$ or $Y$ depending on
    whether $m$ is odd or even, but in both cases,
    $h(m) \in X \cup Y$.
  \item Now let's prove that $X \cup Y \subset h(\nn)$. Let be $z \in
    X \cup Y$. If $z \in X$, then there exists $n \in \nn$ such that
    $f(n) = z$, and thus $h(2n) = z$. This means that $z \in h(\nn)$.
    A similar argument applies if $z \in Y$. Thus, we have indeed $X
    \cup Y \subset h(\nn)$.
  \end{itemize}

  Those two properties show that $X \cup Y = h(\nn)$. According to
  Proposition 8.1.8 or Corollary 8.1.9, $h(\nn)$ is at most countable,
  as the image of the countable set $\nn$. Thus, $h(\nn)$ can be
  either finite or countable. Let's suppose that it is a finite set.
  In this case, $X \cup Y$ is a finite set. By Proposition 3.6.14(c),
  $X$ is also finite, as a subset of a finite set. This is a clear
  contradiction with our initial hypothesis that $X$ is countably
  infinite. Thus, $h(\nn) = X \cup Y$ is countable, as required.  
\end{exo}

\bigskip
\begin{exo}{8.1.8}{Use Corollary 8.1.13 to prove Corollary 8.1.14.}

  We must show that any cartesian product of two countable sets is
  itself countable, i.e., if $X$ and $Y$ are countable, then $X \times
  Y$ is countable.

  By definition, there exist two bijections $f : X \to \nn$
  and $g : Y \to \nn$. Now let be the function $h : X \times Y
  \to \nn \times \nn$ defined by $h(x, y) = (f(x), g(y))$ for
  all $x \in X$ and $y \in Y$. We will show that $h$ is also bijective.

  \begin{itemize}
  \item $h$ is injective: if we suppose that $h(x, y) = h(x', y')$,
    then we have $(f(x), g(y)) = (f(x'), g(y'))$, i.e. $f(x) = f(x')$
    and $g(y) = g(y')$. Since $f$ and $g$ are bijective, this implies
    $x=x'$ and $y=y'$, so that $h$ is injective.
  \item $h$ is also surjective because $f$ and $g$ are surjective: for
    all $n \in \nn$, there exists $x \in X$ such that $n = f(x)$; and
    similarly, for all $m \in \nn$ there exists $y \in Y$ such that
    $m = g(y)$. Thus, for all $(n,m) \in \nn \times \nn$ there exists
    $(x,y) \in X \times Y$ such that $h(x,y) = (n,m)$, i.e., $h$ is
    surjective.
  \end{itemize}

  Thus, $X \times Y$ and $\nn \times \nn$ have the same cardinality.
  By Corollary 8.1.13, this means that $X \times Y$ is countable.
\end{exo}

\bigskip
\begin{exo}{8.1.9}{Suppose that $I$ is an at most countable set, and
    for each $\alpha \in I$, let $A_\alpha$ be an at most countable
    set. Show that the set $\bigcup_{\alpha \in I} A_\alpha$ is also
    at most countable. In particular, countable unions of countable
    sets are countable. (This exercise requires the axiom of choice,
    see Section 8.4.)}

  This statement, although quite intuitive, is actually tricky to
  prove rigorously. There are a bunch of things that make the proof
  even trickier; for instance:
  \begin{itemize}
  \item the sets $I$ and $A_\alpha$ are said to be \emph{at most}
    countable, i.e. either finite or countably infinite: do we have to
    handle those cases separately?
  \item intuitively and informally, we have actually a denumerable
    sequence of sets, and in each set, we can also count the elements.
    For instance, we have a set
    $A_{\alpha_1} = \{a_{11}, a_{12}, \ldots \}$, a set
    $A_{\alpha_2} = \{a_{21}, a_{22}, \ldots \}$, and so on. Each
    element of $\bigcup_\alpha A_\alpha$ thus has two indices (the
    index of its set, and the index of its place in this set), so that
    we can think of a map between $\nn \times \nn$ and
    $\bigcup_\alpha A_\alpha$. But the sets $A_\alpha$ are not
    supposed to be disjoint, so that we do not really see how this map
    could be necessarily bijective (a same object $x$ can belong to
    several $A_\alpha$, and thus, several pairs $(n,k)$ can provide an
    $x = a_{nk}$).
  \end{itemize}

  We thus need to think to a way to overcome these problems. A first
  remark can address (at least part of) them: if there exists an
  injection $f : A \to C$ between a set $A$ and a countable set $C$,
  then $A$ is at most countable (see also Exercise 3.6.7). Indeed, $f$
  is a bijection between $A$ and $f(A)$, so that they have the same
  cardinality; and $f(A)$ is at most countable because it is a subset
  of $C$ (Corollary 8.1.7). Alternatively, if $A$ is at most
  countable, there exists a bijection between $A$ and a subset of
  $\nn$.

  Using the notion of injection instead of bijection seems to be the
  way to go. So, let's begin the main proof!

  \begin{itemize}
  \item Since $I$ is at most countable, there exists a bijection
    $g : N \to I$, where $N$ is a subset of the natural numbers. Thus,
    $(A_\alpha)_{\alpha \in I} = (A_{g(m)})_{m \in N}$.
  \item Also, since each set $A_{g(m)}$ is at most countable, there
    exists an injective function $f_m : A_{g(m)} \to \nn$ for
    each given $m \in N$. So, for each $m \in N$, let be
    $\mathcal{F}_m$ the set of all possible injections from
    $A_{g(m)}$ to $\nn$. By the axiom of choice, we can choose
    simultaneously an injection in each of these sets (although we do
    not know which one exactly), so that we end up with an at most
    countable set of injections $\{f_m\}_{m \in N}$.
  \item Now let's consider
    $x \in \bigcup_{\alpha \in I} A_\alpha = \bigcup_{m \in N}
    A_{g(m)}$. As we said previously, $x$ can belong to one or several
    sets in this union. Thus, let's consider the set
    $\{m \in N \, : \, x \in A_{g(m)} \}$. It's a subset of $\nn$, so
    that by the well-ordering principle (Proposition 8.1.4), there
    exists exactly one minimal element $n$ in this set.
  \item Now let's define
    $\theta : \bigcup_{m \in N} A_{g(m)} \to \nn \times \nn$ the
    function such that, for all $x \in \bigcup_{m \in N} A_{g(m)}$, we
    have $\theta(x) = (n, f_n(x))$ with $n$ the minimal element
    defined above. $\theta$ is injective since $n$ is uniquely defined
    and $f_n$ is injective. Thus, $\bigcup_{m \in N} A_{g(m)}$ is at
    most countable, as required.
  \end{itemize}  
\end{exo}

\begin{exo}{8.2.1}{Prove Lemma 8.2.3.}

  We have to prove that, if $X$ is a countable set, then
  $\sum_{x \in X} f(x)$ is absolutely convergent iff
  $\sup\left\{ \sum_{x \in A} |f(x)| \, : \, A \subseteq X, \text{ $A$
      finite}\right\}$.

  \begin{itemize}
  \item First suppose that
    $\sup\left\{ \sum_{x \in A} |f(x)| \, : \, A \subseteq X, \text{
        $A$ finite}\right\} < \infty$, and let's show that the series
    $\sum_{x \in X} f(x)$ is absolutely convergent.

    A preliminary remark: since $X$ is a countable set, there exists a
    bijection $g : \nn \to X$. Let be $N$ a natural number.
    Since $g$ is a bijection from $\nn$ to $X$, the set
    $A_N := g(\intset{0}{N})$ is a (finite) subset of $X$ for any
    value of $N$. Furthermore, since the restriction
    $g : \intset{0}{N} \to A_N$ is bijective, we have
    $\sum_{x \in A_N} |f(x)| = \sum_{n=0}^N |f(g(n))|$. Thus, by our
    initial hypothesis,
    \begin{align}
      \sup\left\{ \sum_{n=0}^N |f(g(n))| \, : \, N \in \nn\right\}
      &= \sup\left\{ \sum_{x \in A_N} |f(x)| \, : \, N \in \nn\right\}
      \label{eq:821a} \\
      &\leq \sup\left\{\sum_{x \in A} |f(x)| \, : \, A \subseteq X, \text{ $A$
      finite}\right\} < \infty \label{eq:821b}
    \end{align}
    Let's denote $S_N := \sum_{n=0}^{N} |f(g(n))|$. The sequence
    $(S_N)_{N=0}^\infty$ is a sequence of partial sums of non-negative
    numbers, so that it is increasing, and thus converges iff it is
    bounded (Proposition 6.3.8). By equations
    \eqref{eq:821a}--\eqref{eq:821b}, we have
    $\sup (S_N)_{N=0}^\infty < \infty$, which means that
    $(S_N)_{N=0}^\infty$ converges. It means that
    $\sum_{n=0}^{\infty} |f(g(n))|$ converges for some bijection
    $g : \nn \to X$, i.e. that $\sum_{x \in X} f(x)$ is
    absolutely convergent by Definition 8.2.1.
  \item Now suppose that $\sum_{x \in X} f(x)$ is absolutely
    convergent and let's show that we have
    $\sup\left\{ \sum_{x \in A} |f(x)| \, : \, A \subseteq X, \text{
        $A$ finite}\right\} < \infty$.

    Since $\sum_{x \in X} f(x)$ is absolutely convergent, then by
    Definition 8.2.1, there exists some bijection $g : \nn \to X$ such
    that $\sum_{n=0}^\infty f(g(n))$ is absolutely convergent. But by
    Proposition 7.4.1, we know that if one such bijection $g$ exists,
    then the series $\sum_{n=0}^\infty f(h(n))$ is also absolutely
    convergent for any other bijection $h : \nn \to X$.

    So, let's choose a bijection $h$ that suits us. Let $A$ be a
    finite (non-empty) subset of $X$ having $N$ elements; we define
    $h : \nn \to X$ a bijection such that $h(\intset{0}{N-1}) = A$. We
    thus have (by Proposition 7.2.14(c)):
    \begin{equation}
      \sum_{n = 0}^\infty |f(h(n))| = \sum_{n=0}^{N-1} |f(h(n))|
      + \sum_{n = N}^{\infty} |f(h(n))|
    \end{equation}
    which is equivalent to
    \begin{equation}
      \sum_{x \in X} |f(x)| = \sum_{x \in A} |f(x)| + \sum_{n =
        N}^\infty |f(h(n))|
    \end{equation}

    And since $\sum_{n = N}^\infty |f(h(n))|$ converges (Proposition
    7.2.14(d)) to a positive real number (Proposition 5.4.9), we get:
    $\sum_{x \in A} |f(x)| \leq \sum_{x \in X} |f(x)|$ for any subset
    $A$ of $X$.

    Finally, our initial hypothesis was that $\sum_{x \in X} f(x)$ is
    absolutely convergent, i.e. that $\sum_{x \in X} |f(x)|$ is a
    (positive) real number $M$. Thus, there exists $M \in \rr$ such
    that $\sum_{x \in A} |f(x)| \leq M$, which is equivalent to
    $\sup\left\{ \sum_{x \in A} |f(x)| \, : \, A \subseteq X, \text{
        $A$ finite}\right\} < \infty$, as required. This closes the
    proof.
  \end{itemize}
\end{exo}

\begin{exo}{8.2.2}{Prove Lemma 8.2.5.}

  Let's follow the hint, and first consider the number:

  \begin{equation}
    \label{eq:822a}
    M := \sup \left\{ \sum_{x \in A} |f(x)| \, : \, A \subseteq X, A
      \text{ finite} \right\}
  \end{equation}

  which is (by Definition 8.2.4) a finite real number since
  $\sum_{x \in X} f(x)$ is supposed to be absolutely convergent; and
  for each positive integer $n$, the set:

  \[A_n = \left\{x \in X \, : \, |f(x)| > 1/n \right\} \]

  \begin{itemize}
  \item Let's show that all the sets $A_n$ are finite. Suppose, for
    the sake of contradiction, that there exists a natural number $n$
    such that $A_n$ is infinite. Since it is an infinite set, in
    particular there exists a subset finite $A \subset A_n$ such
    that $\# A = 2 Mn$. Thus we have $\sum_{x \in A} |f(x)| >
    \sum_{x \in A} 1/n = 2M$. I.e., we have found a finite subset
    $A \subset A_n \subseteq X$ such that:
    \[\sum_{x \in A} |f(x)| > \sup \left\{ \sum_{x \in A} |f(x)| \, : \, A \subseteq X, A
        \text{ finite} \right\}, \] an obvious contradiction. Thus,
    $A_n$ is finite for all $n > 0$.
  \item Since $A_n$ is a finite subset of $X$, then by equation
    \eqref{eq:822a}, we have $\sum_{x \in A_n} |f(x)| \leq M$.
    But also, we have by definition of $A_n$ (and Proposition
    7.1.11(h)) that $\sum_{x \in A_n} 1/n < \sum_{x\in A_n} |f(x)|$,
    so that by transitivity:
    \begin{equation*}
      M > \sum_{x \in A_n} 1/n = \# A_n \times (1/n)
    \end{equation*}
    and thus $\#A_n < Mn$ for all natural number $n > 0$.
  \item Now, we show that
    \begin{equation}
      \label{eq:822b}
      A := \left\{x \in X \, : \, f(x) \neq 0 \right\} =
      \bigcup_{n=1}^\infty A_n
    \end{equation}
    On the one hand, if $x \in A$, then $f(x) \neq 0$, and in
    particular $|f(x)| > 0$. By Exercise 5.4.4, there exists a
    positive integer $m$ such that $|f(x)| > 1/m > 0$, i.e. such that
    $x \in A_m$.

    Conversely, if $x \in \bigcup_{n=1}^\infty A_n$, then by
    definition there exists a positive integer $m$ such that $x \in
    A_m$, so that $|f(x)| > /m$, and thus $x \in A$.

    Both sets are thus equal.
  \item Finally, by Exercise 8.1.9, a countable union of countable set
    is countable. Thus, $\bigcup_{n=1}^\infty A_n$ is countable, i.e.
    $\left\{x \in X \, : \, f(x) \neq 0 \right\} $ is countable. This
    closes the proof.
  \end{itemize}
\end{exo}

\begin{exo}{8.2.3}{Prove Proposition 8.2.6.}

  All statements can be deduced in a similar fashion from the usual
  series laws given in Chapter 7, so that we won't prove all of them
  in painful details below; we just give an example of proof for one
  of them. Remember that since $X$ is possibly uncountable here, only
  Definition 8.2.4 and Lemma 8.2.5 can be used to prove the
  statements. However, Lemma 8.2.5 allows to reduce them into a case
  where the sum is computed on an at most countable set, so that
  Propositions 7.1.11 and 7.2.14 apply (more or less) immediately.

  For what follows, let's define
  $F := \left\{x \in X \, : \, f(x) \neq 0 \right\}$ and
  $G := \left\{x \in X \, : \, g(x) \neq 0 \right\}$. By Lemma 8.2.5,
  both $F$ and $G$ are at most countable.

  Also, let's define
  $M_f := \sup\{\sum_{x \in A} |f(x)| \, : \, A \subseteq X, A \text{
    finite} \}$, by Definition 8.2.4 we know that $M_f$ is a finite
  real number; similarly we define
  $M_g := \sup\{\sum_{x \in A} |g(x)| \, : \, A \subseteq X, A \text{
    finite} \}$ which is also a finite real number.

  \begin{enumerate}[label=\emph{(\alph*)}]
    \setcounter{enumi}{1}
  \item Let be $c$ a real number. First a general remark: if
    $\sum_{x \in X} f(x)$ is absolutely convergent, then
    $\sum_{x \in X} cf(x)$ is also absolutely convergent. Indeed, we
    know that for all finite subset $A \subseteq X$, we have
    $\sum_{x \in A} |f(x)| \leq M_f$, so that by Proposition 7.1.11(g)
    we have
    $\sum_{x \in A} |cf(x)| \leq |c| \sum_{x \in A} |f(x)| \leq
    |c|M_f$. It means that the set
    $\{\sum_{x \in A} |cf(x)| \, : \, A \subseteq X, A \text{ finite}
      \}$ is bounded, i.e. that $\sum_{x \in X} cf(x)$ is absolutely
      convergent. Now consider several cases.

    If $c=0$ there is almost nothing to prove. On the one hand, we
    have $c \times \sum_{x \in X} f(x) = 0$ (because
    $\sum_{x \in X} f(x)$ is a finite real number); on the other hand
    we have
    $\sum_{x \in X} cf(x) := \sum_{\{x \in X \, : \, cf(x) = 0 \}}
    f(x) = \sum_\emptyset f(x) = 0$ by Proposition 7.1.11(a). Thus, we
    have $\sum_{x \in X} cf(x) = 0 = c \sum_{x \in X} f(x)$, and the
    claim follows.

    Now, suppose instead that $c \neq 0$. Note that, in this case,
    $f(x) = 0 \Longleftrightarrow cf(x) = 0$, so that:
    \begin{equation}
      \label{eq:823b1}
      \{x \in X \, : \, f(x) \neq 0\} = \{x \in X \, : \, cf(x) \neq
      0\}
    \end{equation}

    Also, we know that
    $c \times \sum_{x \in X} f(x) := c \times \sum_{x \in F} f(x)$,
    the set $F$ being at most countable.

    \begin{itemize}
    \item If $F$ is finite, then by Proposition 7.1.11(g), we have
      $c \times \sum_{x \in F} f(x) = \sum_{x \in F} cf(x)$. Thus, we
      have
      $c \times \sum_{x \in X} f(x) := c \times \sum_{x \in F} f(x) =
      \sum_{x \in F} cf(x) =: \sum_{x \in X} cf(x)$ (using equation
      \eqref{eq:823b1} under the hood for the last equality), as
      expected.
    \item If $F$ is countably infinite, since we have already shown
      that $\sum_{x \in X} cf(x) := \sum_{x \in F} cf(x)$ is
      absolutely convergent, we can apply Definition 8.2.1: there
      exists a bijection $g : \nn \to F$ such that
      $\sum_{n = 0}^\infty cf(g(n))$ is absolutely convergent. By
      Proposition 7.2.14(b), we finally have:
      \[\sum_{x \in F} cf(x) := \sum_{n = 0}^\infty cf(g(n)) = c
        \sum_{n = 0}^\infty f(g(n)) =: c \sum_{x \in F} f(x)\]
      as expected.
    \end{itemize}
  \end{enumerate}
\end{exo}

\begin{exo}{8.2.4}{Prove Lemma 8.2.7.}

  Let be $\sum_{n=0}^\infty a_n$ a series which is conditionally but
  not absolutely convergent; and let's define the two sets
  $A_+ := \{n \in \nn \, : \, a_n \geq 0\}$ and
  $A_- := \{n \in \nn \, : \, a_n < 0\}$. We have to prove that
  neither $\sum_{n \in A_+} a_n$ nor $\sum_{n \in A_-} a_n$ are
  conditionally convergent.

  We'll use a proof by contradiction.
  
  \begin{itemize}
  \item First, we are going to suppose something which is a little too
    strong: let's suppose that \emph{both} $\sum_{n \in A_+} a_n$ and
    $\sum_{n \in A_-} a_n$ are conditionally convergent\footnote{This
      hypothesis is too strong because the proper negation which
      should be the starting point for our proof by contradiction
      would be: ``one of $\sum_{n \in A_+} a_n$ or
      $\sum_{n \in A_-} a_n$ is conditionally convergent''. We'll fix
      that later.}.

    In this case, $\sum_{n \in A_+} a_n$ is absolutely convergent
    (because for the positive series, conditional and absolute
    convergence are the same thing). Also, the series
    $\sum_{n \in A_-} (-a_n)$ is convergent by Proposition 7.2.14(b);
    and as it is a positive series, it is absolutely convergent; so
    that $\sum_{n \in A_-} a_n$ itself is absolutely convergent by
    Proposition 8.2.6(b). Thus, for both $\sum_{n \in A_+} a_n$ and
    $\sum_{n \in A_-} a_n$, conditional convergence implies absolute
    convergence.

    Since $\nn = A_+ \sqcup A_-$, we have by Proposition 8.2.6(c) that
    $\sum_{n \in A_+} a_n + \sum_{n \in A_+} a_n = \sum_{n \in A} a_n$
    is absolutely convergent; a contradiction.

    Thus, $\sum_{n \in A_+} a_n$ and $\sum_{n \in A_-} a_n$ cannot be
    both conditionally convergent.
  \item However, we have not really proved Lemma 8.2.7 when doing
    this. Instead, we need to prove that \emph{even only one of them}
    cannot be conditionally convergent.

    Actually, it turns out that when one of them is convergent, the
    other one is also convergent, which closes the proof.

    Indeed, let's suppose that $\sum_{n \in A_+} a_n$ is
    (conditionally, and thus absolutely) convergent. Let's define the
    (positive) series $\sum_{n=0}^\infty b_n$, where $b_n = 0$ whenever
    $a_n < 0$, and $b_n = a_n$ whenever $a_n \geq 0$.

    We obviously have $\sum_{n \in A_+}b_n = \sum_{n \in A_+} a_n$ (so
    that $\sum_{n \in A_+}b_n$ is absolutely convergent);
    and $\sum_{n \in A_-}b_n = 0$ (so that it is also absolutely
    convergent). Thus, by Proposition 8.2.6(c), $\sum_{n=0}^\infty b_n$ is
    absolutely convergent, and is equal to $\sum_{n \in A_+} a_n$.

    Finally, since $\sum_{n=0}^\infty a_n$ and $\sum_{n=0}^\infty b_n$
    are both (at least conditionally) convergent, then
    $\sum_{n=0}^{\infty}(a_n-b_n)$ is also convergent. Since we always
    have $a_n-b_n \leq 0$ for all natural number $n$, conditional
    convergence implies absolute convergence, so that by Proposition
    8.2.6(c), both $\sum_{n \in A_+} (a_n - b_n) = 0$ and $\sum_{n \in
      A_-} (a_n - b_n) = \sum_{n \in A_-} a_n$ are absolutely convergent.

    In particular, we have shown that whenever $\sum_{n \in A_+}a_n$
    is convergent, the other series $\sum_{n \in A_-}a_n$ is also
    convergent, as expected. This closes the proof.
  \end{itemize} 
\end{exo}

\begin{exo}{8.3.1}{Let $X$ be a finite set of cardinality $n$. Show
    that $2^X$ is a finite set of cardinality $2^n$.}

  Let's use induction on $n$, the number of elements of $X$.

  \begin{itemize}
  \item For the base case, if $n=0$, $X$ is simply the empty set. In
    such a case, $2^\emptyset = \{\emptyset\}$ has indeed one single
    element, i.e. has a cardinality of $2^0 = 1$, and is thus finite.
  \item Now suppose inductively that $2^X$ has $2^n$ elements if $X$
    has $n$ elements, and let's show that this property still holds
    for $n+1$.

    Suppose that $\#X = n+1$, and let's pick $x \in X$. If we denote
    $A = X \backslash \{x\}$, then we have $X = A \cup \{x\}$, with
    $\#A = n$. Note that any subset of $X$ consists either of a subset
    of $A$, or of the pairwise union between $\{x\}$ and a subset of
    $A$ (obviously, any such set is a subset of $X$; and conversely,
    any subset of $X$ may or may not contain $x$, and is otherwise
    composed of elements of $A$).

    Thus, we have
    $2^X = \{S \, : \, S \in 2^A\} \sqcup \{S \cup \{x\} \, : \, S \in
    2^A\}$. By the induction hypothesis, $2^A$ has cardinality $2^n$,
    so that, by Proposition 3.6.14(b), we have
    $\#X = 2^n + 2^n = 2^{n+1}$, as expected.
  \end{itemize}  
\end{exo}

\begin{exo}{8.5.2}{Give examples of a set $X$ and a relation $\leq_X$
    such that the relation $\leq_X$ is...}

  We have the cases below:
  \begin{enumerate}[label=\emph{(\alph*)}]
  \item Reflexive and anti-symmetric but not transitive. Consider
    $X = \nn$, and $\leq_X$ defined by $n \leq_X m$ iff
    $0 \leq n-m \leq 1$. This relation is obviously reflexive. It is
    also anti-symmetric, since $n \leq_X m$ and $m \leq_X n$ imply
    that we have both ``$n=m$ or $n=1+m$'' and ``$n=m$ or $m=1+n$'',
    which lets $n=m$ for the only possibility. But it is not
    transitive since $1 \leq_X 2$ and $2 \leq_X 3$ but we do not have
    $1 \leq_X 3$.
  \item Reflexive and transitive but not anti-symmetric. Consider $X =
    \rr^2$ and $\leq_X$ defined by $(x,y) \leq_X (x',y')$ iff $x \leq
    x'$. It is obviously reflexive and transitive, but not
    anti-symmetric since $(2,3) \leq_X (2,4)$ and $(2,4) \leq_X (2,3)$
    but we do not have $(2,3) = (2,4)$.
  \item Anti-symmetric and transitive but not reflexive. Consider $X
    = \rr$ and $\leq_X$ defined by the usual strict inequality $<$.
    Obviously, it is transitive. It might not immediately clear why it
    is also anti-symmetric, however: how could it happen that we have
    $x=y$ after both statements $x<y$ and $y<x$, since each of them
    implies in particular that $x \neq y$? By trichotomy of order, we
    can never have both of them at the same time, so that the
    implication $(x < y) \text { and } (y < x) \Longrightarrow x = y$
    is \emph{vacuously} true. And thus, $<$ is indeed anti-symmetric.
  \end{enumerate}
\end{exo}

\begin{exo}{8.5.3}{Given two positive integers $n, m \in \nn - \{0\}$,
    we say that $n$ divides $m$, and write $n|m$, if there exists a
    positive integer $a$ such that $m = na$. Show that the set
    $\nn - \{0\}$ with the ordering relation $|$ is a partially
    ordered set but not a totally ordered one.}

  To show that this defines a partially order set, we just have to
  prove that the relation $|$ is reflexive, anti-symmetric and
  transitive.

  \begin{itemize}
  \item It is obviously reflexive because we have $n = n \times 1$,
    and $1$ is a positive integer.
  \item It is anti-symmetric because if we suppose that $n|m$, we must
    have $m=na$ for some positive integer $a$. Similarly, if we have
    $m|n$, we must have $n=mb$ for some positive integer $b$.
    Gathering these two statements, we get $n = n(ab)$, i.e. $ab=1$ by
    cancellation law (Corollary 2.3.7). The only possibility for
    $ab=1$ on the natural numbers is that  both $a=1$ and $b=1$, as a
    quick proof by contradiction would show. Thus, we have $n=mb=m$,
    as required.
  \item It is also transitive because if $n|m$ and $m|p$, we have
    $m=na$ and $p=mb$ for some natural numbers $a,b$. Thus, $p=n(ab)$,
    with $ab$ a natural number, so that $n|p$ as required.
  \end{itemize}

  However, this does not define a totally ordered set, since we have
  neither $2|3$ nor $3|2$.  
\end{exo}

\bigskip
\begin{exo}{8.5.4}{Show that the set of positive real numbers, $\rr_+
    = \{ x \in \rr \, : \, x>0 \}$, has no minimal element.}

  This is actually a direct consequence of Exercise 5.4.4, and thus of
  the Archimedean property of $\rr$. Suppose that there exists $m \in
  \rr_+$ such that $m = \min(\rr_+)$. Obviously, we must have $m < 1$,
  since there exists elements such as $1/2 \in \rr_+$. Let's apply the
  Archimedean property with $x = 1$: there exists a positive integer
  $M$ such that $Mm > 1$, i.e. such that $1/M < m$. But $1/M$ is a
  positive rational number, thus a positive real number, which is a
  contradiction.  
\end{exo}

\bigskip
\begin{exo}{8.5.5}{Let $f : X \to Y$ be a function from one set $X$ to
    another set $Y$. Suppose that $Y$ is partially ordered with some
    ordering relation $\leq_Y$. Deﬁne a relation $\leq_X$ on $X$ by
    defining $x \leq_X x'$ if and only if $f(x) <_Y f(x')$ or
    $x = x'$. Show that this relation $\leq_X$ turns $X$ into a
    partially ordered set. If we know in addition that the relation
    $\leq_Y$ makes $Y$ totally ordered, does this mean that the
    relation $\leq_X$ makes $X$ totally ordered also? If not, what
    additional assumption needs to be made on $f$ in order to ensure
    that $\leq_X$ makes $X$ totally ordered?}

  First we prove that $\leq_X$ makes $X$ a partially ordered set, by
  showing that the three properties of ordering relations hold for
  $\leq_X$:
  \begin{itemize}
  \item Reflexivity is obviously okay: $x \leq_X x$ is true iff $f(x)
    <_Y f(x)$ or $x=x$; one of these two statements is clearly true.
  \item $\leq_X$ is anti-symmetric: suppose that we have both $x
    \leq_X y$ and $y \leq_X x$ for $x,y \in X$. Since $x \leq_X y$, we
    have either $x=y$ (and in this case we are done) or $f(x) <_Y
    f(y)$. Let's suppose that $f(x) <_Y f(y)$. By the second
    hypothesis, we have $y \leq_X x$, so that we have either $y=x$
    (and in this case we are done) or $f(y) <_Y f(x)$. But since we
    already have supposed that $f(x) <_Y f(y)$, we cannot have $f(y)
    <_Y f(x)$. Thus, the only possibility is $x=y$, as expected.
  \item $\leq_X$ is also transitive: if we suppose that we have both
    $x \leq_X y$ and $y \leq_X z$, we have actually [$x=y$ or
    $f(x) <_Y f(y)$] and [$y=z$ or $f(y) <_Y f(z)$]; and we must show
    that this implies [$x=z$ or $f(x) <_Y f(z)$]. A cumbersome but
    easy distinction into four pairs of cases would show that $\leq_X$
    is transitive.
  \end{itemize}

  However, the hypothesis that $Y$ is totally ordered does not make
  $X$ a totally ordered set. For instance, let's take $X=Y=\rr$ and
  $f$ the constant function $f(x) = 0 \, \forall x \in \rr$. In this
  case, we have neither $2 \leq_X 3$ (because $2=3$ is false, and
  $f(2) < f(3)$ is false), nor $3 \leq_X 2$ (the same remark applies).
  So, at least, $f$ must not be constant. But it's still not enough!
  Indeed, let's take $f(x) = x^2$. We have neither $-1 \leq_X 1$
  (because $-1=1$ is false, and $f(-1) < f(1)$ is false) nor
  $1 \leq_X -1$ (same remark). Thus, $f$ must be at least injective.
\end{exo}

\bigskip
\begin{exo}{8.5.7}{Let $X$ be a partially ordered set, and let $Y$ be
    a totally ordered subset of $X$. Show that $Y$ can have at most
    one maximum and at most one minimum.}

  Let's suppose that there exist two distinct elements $m\neq m'$ in
  $Y$ such that both $m$ and $m'$ are minimal elements. Since $Y$ is
  totally ordered, we have either $m \leq m'$, or $m' \leq m$. Suppose
  that $m \leq m'$. By Definition 8.5.5, since $m'$ is a minimal
  element, it is impossible that $m < m'$; thus $m=m'$ is the only
  possibility. The same conclusion applies if we suppose that $m' \leq
  m$, so we are done.

  A similar argument shows that $Y$ can have at most one maximal
  element.
\end{exo}

\bigskip
\begin{exo}{8.5.8}{Show that every finite non-empty subset of a totally
    ordered set has a minimum and a maximum. (Hint: use induction.)
    Conclude in particular that every finite totally ordered set is
    well-ordered.}

  Let be $X$ a totally ordered set, and $Y$ a finite non-empty subset
  of $X$. Since $Y$ is finite, we may say that it has $n$ elements.
  Let's induct on $n$.

  \begin{itemize}
  \item For the base case, let's suppose that $n=1$ (we don't start
    from $0$ since $Y$ is supposed to be non-empty). It means that $Y$
    is a singleton set, i.e., $Y = \{x\}$ for some $x \in X$. We can
    say that $x$ is a minimal element, since there is no $y \in Y$
    such that $y < x$ (because there is simply no other element in
    $Y$). Similarly, $x$ is a maximal element, so the base case is
    done.
  \item Now suppose inductively that the property holds for any subset
    $Y$ which has $n$ elements, and let's prove that it is still true
    when $Y$ is supposed to have $n+1$ elements. By Lemma 3.6.9, if we
    suppose $\# Y = n+1$, we can write $Y = A \cup \{x\}$ with
    $\#A = n$. By the induction hypothesis, $A$ has a minimum $m$ and
    a maximum $M$. If we have $x < m$, then $x$ is a minimum for $Y$;
    else (i.e., if $m \leq x$) $m$ is still a minimum for $Y$.
    Similarly, if we have $x > M$, then $x$ is a maximum for $Y$; else
    (i.e., if $M \geq x$) $M$ is still a maximum for $Y$. In all
    cases, $Y$ has a minimum and a maximum, as expected. This closes
    the induction, and proves that every finite non-empty subset of a
    totally ordered set has a minimum and a maximum.
  \end{itemize}

  If $X$ is a finite totally ordered set, all non-empty subsets
  $Y \subseteq X$ are finite. Thus, we have even proved that every
  finite totally ordered set is well-ordered, in the sense of
  Definition 8.5.8.
\end{exo}

\bigskip
\begin{exo}{8.5.9}{Let $X$ be a totally ordered set such that every
    non-empty subset of $X$ has both a minimum and a maximum. Show that
    $X$ is finite.}

   Suppose for sake of contradiction that $X$ is infinite. By the
   initial hypothesis, there exists a minimal element $x_0 \in X$.
   Since $X$ is infinite, the set $X - \{x_0\}$ is non-empty; let be
   $x_1$ its minimum. We have $x_0 \leq x_1$ because $x_1 \in X$ and
   $x_0 = \min(X)$, but we also have $x_0 \neq x_1$ because $x_1 \in X
   - \{x_0\}$ by definition. Thus, we have $x_0 < x_1$. Now let's
   consider the subset of $X$ defined by $X - \{x_0, x_1\}$: it it
   still a non-empty subset (otherwise $X$ could not be infinite), and
   the same argument as above would show that its minimum $x_2$ (wich
   certainly exists) is such that $x_0 < x_1 < x_2$. We can thus
   repeat these steps indefinitely to construct an increasing sequence
   $x_0 < x_1 < x_2 < \cdots$.

   More formally, we can define recursively $x_0 := \min(X)$ and, for
   each natural number $n$, $x_{n+1} := \min(X - \cup_{i=0}^n
   \{x_i\})$; so that $\seq{x_n}{0}$ is an increasing sequence.

   By definition, the set $\{x_0, x_1, \cdots \}$ is an infinite set,
   is thus a non-empty subset of $X$, but has no maximal element. This
   contradicts our initial hypothesis. Thus, $X$ cannot be infinite:
   it is a finite set.
\end{exo}

\bigskip
\begin{exo}{8.5.10}{Prove Proposition 8.5.10.}

  Let be $X$ a totally ordered set, and $P$ a property such that, for
  any $n \in X$, we have the following implication: [$P(m)$ is true
  for all $m \in X$ with $m < n$] $\Rightarrow$ [$P(n)$ is true]. We
  have to prove that $P(n)$ is true for all $n \in X$.

  First, note that, if we denote $0 := \min(X)$ (and this minium
  necessarily exists since $X$ is totally ordered), $P(0)$ must be
  true. Indeed, the statement ``$P(m)$ is true for all $m \in X$ with
  $m < 0$'' is vacuously true, so that $P(0)$ must be true.

  Now suppose, for the sake of contradiction, that the set $Y$ defined
  by
  \[Y := \{ n \in X \, : \, P(m) \text{ is false for some $m \in X$
      with } m \leq n\}\]
  is non-empty. Since $X$ is totally ordered, there exists a minimal
  element $M$ in $Y$, i.e. there exists some $M := \min(Y)$. In
  particular, $M$ is the lowest element of $X$ for which $P(M)$ is
  false.

  It is impossible that $M=0$, because it would imply that $P(0)$ is
  false, which has been excluded. Thus, we have $M \neq 0$, or more
  precisely, $M > 0$.

  Since $M > 0$, for all elements $m \in X$ such that $0 \leq m < M$
  (there is at least one such element, which is $0$), $P(m)$ is true.
  By our initial hypothesis, it would thus imply that $P(M)$ is true;
  a contradiction.

  Thus, $Y$ is empty, and $P(n)$ is true for all $n \in X$.  
\end{exo}

\pagebreak
\section{Continuous functions on $\mathbb{R}$}
\begin{exo}{9.1.1}{Let $X$ be any subset of the real line, and let $Y$
    be a set such that $X \subseteq Y \subseteq \adh{X}$. Show that
    $\adh{Y} = \adh{X}$.}

  We will show that we have $\adh{X} \subseteq \adh{Y}$, and $\adh{Y}
  \subseteq \adh{X}$. Let be $\epsilon > 0$ a positive real number.
  
  \begin{itemize}
  \item Let be $x' \in \adh{X}$. By definition, there exists $x \in X$
    such that $|x - x'| \leq \epsilon$. But since $X \subseteq Y$, we
    also have $x \in Y$. Thus, for any arbitrary $\epsilon > 0$, we
    have indeed an $x \in Y$ such that $|x'-x| \leq \epsilon$, which
    means that $x' \in \adh{Y}$. So, $\adh{X} \subseteq \adh{Y}$.
  \item Let be $y' \in \adh{Y}$. By definition, there exists $y \in Y$
    such that $|y'-y| \leq \epsilon/2$. But since
    $Y \subseteq \adh{X}$, we have $y \in \adh{X}$. It means that we
    can find an $x \in X$ such that $|y-x| \leq \epsilon/2$. Thus, we
    have found an $x \in X$ such that
    $|y'-x| \leq |y'-y| + |y-x| \leq \epsilon/2 + \epsilon/2 \leq
    \epsilon$, for any arbitrary $\epsilon > 0$. It means that
    $y' \in \adh{X}$; so that $\adh{Y} \subseteq \adh{X}$.
  \item We have thus proved that $\adh{X} = \adh{Y}$, as expected.
  \end{itemize}
\end{exo}

\begin{exo}{9.1.2}{Prove Lemma 9.1.11.}
  
  Let $X$ and $Y$ be subsets of $\rr$.
  
  \begin{itemize}
  \item Prove that $X \subseteq \adh{X}$. If $x \in X$, then for any
    $\epsilon > 0$ we always have an $y \in X$ such that $|x-y| \leq
    \epsilon$: let's take $y=x$, so that $|x-y| = 0 \leq \epsilon$.
    
  \item Prove that $\adh{X \cap Y} \subseteq \adh{X} \cap \adh{Y}$.
    Let be $\epsilon > 0$ a real number, and $z' \in \adh{X \cap Y}$.
    By definition, there exists $z \in X \cap Y$ such that
    $|z'-z| \leq \epsilon$. We have $z \in X$ and $z \in Y$. Thus, for
    an arbitrary $\epsilon > 0$, we have found a $z \in X$ such that
    $|z'-z| \leq \epsilon$, i.e. $z' \in \adh{X}$. Similarly,
    $z' \in \adh{Y}$. Thus, $z' \in \adh{X} \cap \adh{Y}$. Thus, we
    have proved $\adh{X \cap Y} \subseteq \adh{X} \cap \adh{Y}$ as
    required.
    
  \item Prove that $\adh{X \cup Y} = \adh{X} \cup \adh{Y}$. Let be
    $\epsilon > 0$ a positive real number, and
    $z' \in \adh{X} \cup \adh{Y}$. We have either $z' \in \adh{X}$ or
    $z' \in \adh{Y}$. Suppose that $z' \in \adh{X}$. By definition,
    there exists $x \in X$ such that $|z'-x| \leq \epsilon$. But since
    $X \subseteq X \cup Y$, we have found an $x \in X \cup Y$ such
    that $|z' - x| \leq \epsilon$, and thus we conclude that
    $z' \in \adh{X \cup Y}$. The same conclusion applies if we suppose
    instead that $z' \in \adh{Y}$. Thus, we have indeed
    $\adh{X} \cup \adh{Y} \subseteq \adh{X \cup Y}$.

    Now let be $z' \in \adh{X \cup Y}$. Suppose that $z' \notin \adh{X}
    \cup \adh{Y}$; this means that $z' \notin \adh{X}$ and $z' \notin
    \adh{Y}$. Thus, there exists $\delta > 0$ such that $|z'-x| >
    \delta$ for all $x \in X$. Similarly, there exists $\gamma > 0$
    such that $|z' - y| > \gamma$ for all $y \in Y$. We conclude that,
    for $\epsilon := \min(\delta, \gamma)$, we have $|z'-x| >
    \epsilon$ for all $x \in X$ and $|z'-y| > \epsilon$ for all $y \in
    Y$; i.e. that $|z'-z| > \epsilon$ for all $z \in X \cup Y$. Thus,
    $z \notin \adh{X \cup Y}$, which obviously contradicts our initial
    hypothesis. It means that whenever $z' \in \adh{X \cup Y}$, we
    have $z' \in \adh{X} \cup \adh{Y}$, i.e. $\adh{X \cup Y} \subseteq
    \adh{X} \cup \adh{Y}$ as required.
    
  \item Prove that if $X \subseteq Y$, then $\adh{X} \subseteq
    \adh{Y}$. Let be $x' \in \adh{X}$, and $\epsilon > 0$ a real
    number. By definition, there exists $x \in X$ such that $|x'-x|
    \leq \epsilon$. But since $X \subseteq Y$, we also have $x \in Y$.
    Thus, for any $\epsilon > 0$, we have an $x \in Y$ such that $|x'
    - x| \leq \epsilon$, which means that $x' \in \adh{Y}$.
  \end{itemize}
\end{exo}

\begin{exo}{9.1.3}{Prove Lemma 9.1.13}

  We will prove all statements in a slightly different order, and will
  use previous results from this chapter.

  First, note that, by Definition 9.1.8, any adherent point to a
  subset $X \subseteq \rr$ is necessarily a real number. It means
  that, for any set $X \subseteq \rr$, we have
  $\adh{X} \subseteq \rr$. This gives our first statement:

  \begin{enumerate}[label=(\roman*)]
  \item The closure of $\rr$ is $\rr$. Indeed, we have $\adh{\rr}
    \subseteq \rr$ by our remark above, and we have $\rr \subseteq
    \adh{\rr}$ by Lemma 9.1.11. The claim follows.
  \item Now we prove that the closure of $\emptyset$ is
    $\emptyset$. Suppose, for the sake of contradiction, that
    $\adh{\emptyset}$ is not empty. Then there exists, by Definition
    9.1.8, a real number $x \in \adh{\emptyset}$. So, for a given
    $\epsilon > 0$, we necessarily have a $z \in \emptyset$ such that
    $|x-z| \leq \epsilon$, but there exists no such $z$. Thus,
    $\adh{\emptyset}$ is empty.
  \item The closure of $\nn$ is $\nn$. Indeed, by Lemma 9.1.1, we
    already know that $\nn \subseteq \adh{\nn}$, so that we just have
    to show that $\adh{\nn} \subseteq \nn$. Let be $n \in
    \adh{\nn}$. Suppose, for the sake of contradiction, that $n
    \notin \nn$, i.e. that $n \in \rr \backslash \nn$. By Exercise
    5.4.3, there exists an integer $m$ such that $m \leq n < m+1$. Let
    be $d_1 = |m-n| > 0$, which is a positive real number since $n
    \notin \nn$ and $m \in \nn$. Similarly, let be $d_2 := |n - (m+1)|
    > 0$. Now, let be $d := \min(d_1, d_2) / 2$, which is also a
    positive real number. Obviously, $n$ is not $d$-adherent to $\nn$,
    so that $n \notin \adh{\nn}$, a contradiction. Thus, we have indeed
    $\nn = \adh{\nn}$.
  \item The proof for $\zz = \adh{\zz}$ is similar.
  \item Finally, let's show that $\adh{\qq} = \rr$. As for the
    previous cases, we only have to show that $\rr \subseteq
    \adh{\qq}$, since we already know that $\adh{\qq} \subseteq
    \rr$. So, let be $z \in \rr$, and let's show that $z \in
    \adh{\qq}$. Let be $\epsilon > 0$ a positive real number. By
    Proposition 5.4.14, there always exists a rational $y \in \qq$
    such that $z-\epsilon < y < z+\epsilon$, i.e. such that $|y-z| <
    \epsilon$. Thus, $z$ is $\epsilon$-adhrent to $\qq$ for any
    $\epsilon > 0$. This means that $z \in \adh{\qq}$, as expected.
  \end{enumerate}
\end{exo}

\begin{exo}{9.1.4}{Give an example of two subsets $X, Y$ of the real
    line such that $\adh{X \cap Y} \neq \adh{X} \cap \adh{Y}$.}

  We already know, from Lemma 9.1.11, that
  $\adh{X \cap Y} \subseteq \adh{X} \cap \adh{Y}$. Thus, we have to
  find $X, Y \subseteq \rr$ such that $\adh{X} \cap \adh{Y}$ fails to
  be a subset of $\adh{X \cap Y}$.

  Let be $X = ]1, 2[$ and $Y = ]2, 3[$. We have (by Lemma 9.1.12)
  $\adh{X} = [1,2]$ and $\adh{Y} = [2,3]$, so that $\adh{X} \cap
  \adh{Y} = \{2\}$. On the other hand, we have $X \cap Y = \emptyset$,
  so that $\adh{X \cap Y} = \emptyset$ (by Lemma 9.1.13). Thus, we
  indeed have $\adh{X \cap Y} \neq \adh{X} \cap \adh{Y}$, as expected.
\end{exo}

\bigskip
\begin{exo}{9.1.5}{Prove Lemma 9.1.14.}

  Let $X$ be a subset of $\rr$, and let be $\ell \in \rr$. We have to
  prove that the following two statements are equivalent: (a) There
  exists a sequence $\seq{a_n}{1}$ whose all elements lie in $X$ and
  which converges to $\ell$. (b) $\ell \in \adh{X}$.

  \begin{itemize}
  \item First, we prove that (a) implies (b). Suppose that we
    have a sequence $\seq{a_n}{1}$ that converges to $\ell \in \rr$
    and such that $a_n \in X$ for all $n \geq 1$, and let be $\epsilon
    > 0$. By definition, there exists a positive integer $N$ such that
    $|a_n - \ell| \leq \epsilon$ for all $n \geq N$; and in
    particular, $\ell$ is $\epsilon$-adherent to $X$ since $|a_N -
    \ell| \leq \epsilon$ with $a_N \in X$. Thus, $\ell \in \adh{X}$.
  \item Now prove that (b) implies (a). Let be $\ell \in \adh{X}$. For
    any given positive integer $n$, let be the set
    $A_n := \{ x \in X \, : \, |x - \ell| \leq 1/n\}$. By definition,
    $A_n$ is non empty for all $n \geq 1$, i.e. there exists a real
    number $a_n \in A_n$ for all $n \geq 1$. By the axiom of choice,
    we can thus define a sequence $\seq{a_n}{1}$ where $a_n \in A_n$
    for all $n \geq 1$. This means that for all $n \geq 1$, we have
    $\ell - 1/n \leq a_n \leq \ell + 1/n$. By the squeeze test,
    $\seq{a_n}{1}$ converges to $\ell$.
  \item Thus, both statements are equivalent, as expected.
  \end{itemize}
\end{exo}

\begin{exo}{9.1.6}{Let $X$ be a subset of $\rr$. Show that $\adh{X}$
    is closed. Furthermore, show that if $Y$ is any closed set that
    contains $X$, then $Y$ also contains $\adh{X}$.}

  First we show that $\adh{X}$ is closed. We already know, by Lemma
  9.1.11, that we have $\adh{X} \subseteq \adh{\adh{X}}$. Thus, we
  juste have to show that $\adh{\adh{X}} \subseteq \adh{X}$. Let be
  $x'' \in \adh{\adh{X}}$, and $\epsilon > 0$ any positive real
  number. By definition, there exists $x'\in \adh{X}$ such that we
  have $|x'' - x'| \leq \epsilon$/2. And since $x' \in \adh{X}$, then
  by definition, there exists $x \in X$ such that we have $|x'-x| \leq
  \epsilon/2$. Thus, by triangular inequality, we have $|x'' - x| \leq
  |x'' - x'| + |x' - x| \leq 2 \epsilon /2 \leq \epsilon$. Thus, for
  any $\epsilon > 0$, there exists $x \in X$ such that $|x'' - x| \leq
  \epsilon$, which show that $x'' \in \adh{X}$, and thus that
  $\adh{\adh{X}} \subseteq \adh{X}$, as expected.

  Now let be $Y$ a closed set, i.e. a set such that $Y = \adh{Y}$. By
  Lemma 9.1.11, if $X \subseteq Y$, then we have
  $\adh{X} \subseteq \adh{Y}$. But since $\adh{Y} = Y$, we have
  $\adh{X} \subseteq Y$, as expected. Thus, $\adh{Y}$ is the smallest
  closed set that contains $X$.  
\end{exo}

\bigskip
\begin{exo}{9.1.7}{Let $n > 1$ be a positive integer, and let $X_1,
    \ldots, X_n$ be closed subsets of $\rr$. Show that $X_1 \cup
    \ldots \cup X_n$ is also closed.}

  Let's use induction on $n$. To show the base case, $n=2$, we must
  show that $X_1 \cup X_2$ is closed whenever $X_1$ and $X_2$ are
  closed. By Lemma 9.1.11, we have $\adh{X_1 \cup X_2} = \adh{X_1}
  \cup \adh{X_2}$, and this is equal to $X_1 \cup X_2$ since $X_1,
  X_2$ are closed. Thus the base case is done.

  Now suppose inductively that $X_1 \cup \ldots \cup X_n$ is closed
  for some positive integer $n$, and let's show that $X_1 \cup
  \ldots \cup X_{n+1}$ is also closed. We have:
  \begin{align*}
    \adh{X_1 \cup \ldots \cup X_n \cup X_{n+1}} &= \adh{(X_1 \cup
                                                  \ldots \cup X_n)
                                                  \cup X_{n+1}} \\
                                                &= (\adh{X_1 \cup
                                                  \ldots \cup X_n})
                                                  \cup \adh{X_{n+1}}
                                                  \text{ (Lemma 9.1.11)} \\
                                                &= (\adh{X_1} \cup
                                                  \ldots \cup \adh{X_n})
                                                  \cup \adh{X_{n+1}} \text{ (by
                                                  induction
                                                  hypothesis)} \\
                                                &= \adh{X_1} \cup
                                                  \ldots \cup
                                                  \adh{X_n} \cup
                                                  \adh{X_{n+1}} \\
                                                &= X_1 \cup \ldots
                                                  \cup X_n
                                                  \cup X_{n+1} \text{
                                                  (because all $X_i$'s
                                                  are closed)}
  \end{align*}

  This closes the induction.
\end{exo}

\bigskip
\begin{exo}{9.1.8}{Let $I$ be a set (possibly infinite), and for each
    $\alpha \in I$ let $X_\alpha$ be a closed subset of $\rr$. Show
    that the intersection $\bigcap_{\alpha \in I} X_\alpha$ is also closed.}

  Recall that $\bigcap_{\alpha \in I} X_\alpha$ is the set such that,
  for any real $x$, we have $x \in \bigcap_{\alpha \in I} X_\alpha$
  iff $x \in X_\alpha$ for all $\alpha \in I$.

  We already know by Lemma 9.1.11 that we have $\bigcap_{\alpha \in I}
  X_\alpha \subseteq \adh{\bigcap_{\alpha \in I} X_\alpha}$; thus, to
  show that $\bigcap_{\alpha \in I} X_\alpha$ is closed, we just have
  to show that $\adh{\bigcap_{\alpha \in I} X_\alpha} \subseteq
  \bigcap_{\alpha \in I} X_\alpha$.

  Let be $x' \in \adh{\bigcap_{\alpha \in I} X_\alpha}$, and
  $\epsilon > 0$ any positive real. By definition, there exists
  $x \in \bigcap_{\alpha \in I} X_\alpha$ such that
  $|x' - x| \leq \epsilon$. By definition of an intersection, we have
  $x \in X_\alpha$ for all $\alpha \in I$, so that we also have
  $x' \in \adh{X_\alpha}$ for all $\alpha \in I$. Thus,
  $x' \in \bigcap_{\alpha \in I} \adh{X_\alpha}$. But since each
  $X_\alpha$ is closed, we finally get
  $x' \in \bigcap_{\alpha \in I} X_\alpha$, as expected.
\end{exo}

\bigskip
\begin{exo}{9.1.9}{Let $X$ be a subset of the real line, and $x$ be a
    real number. Show that every adherent point of $X$ is either a
    limit point or an isolated point of $X$, but cannot be both.
    Conversely, show that every limit point and every isolated point
    of $X$ is an adherent point of $X$.}

  Let's begin by the last assertion. First we prove that any isolated
  point of $X$ is an adherent point of $X$. Let be $x \in X$ an
  isolated point. The claim is obvious since, by Lemma 9.1.11, we have
  $X \subseteq \adh{X}$, so that $x \in \adh{X}$. Also, we prove that
  any limit point of $X$ is adherent to $X$. If $x$ is a limit point
  of $X$, then $x \in \adh{X - \{x\}}$. It means that, for all
  $\epsilon > 0$, there exists some $y \in X - \{x\}$ such that $|x-y|
  \leq \epsilon$. But since $X -\{x\} \subseteq X$, there exists
  actually some $y \in X$ such that $|x-y| \leq \epsilon$ for all
  $\epsilon > 0$, which means that $x \in \adh{X}$ as expected.

  Now suppose that $x \in \adh{X}$ and let's show that it is either a
  limit point or an isolated point. Having $x \in \adh{X}$ means that:

  \begin{equation*}
    \forall \epsilon > 0, \exists y \in X \, : \, |x-y| \leq \epsilon
  \end{equation*}

  There are two cases which are mutually exclusive: either the $y \in
  X$ we can find for any given value of $\epsilon$ always lies in $X -
  \{x\}$, or it is not the case. In the first case, we have:
  \begin{equation*}
    \forall \epsilon > 0, \exists y \in X - \{x\} \, : \, |x-y| \leq \epsilon
  \end{equation*}
  i.e., $x$ is a limit point of $X$. In the other case, let's take the
  negation to get:
  \begin{equation*}
    \exists \epsilon > 0 \, : \, \forall y \in X - \{x\}, |x-y| > \epsilon
  \end{equation*}
  i.e., $x$ is an isolated point of $X$. The claim follows.
\end{exo}

\bigskip
\begin{exo}{9.1.10}{If $X$ is a non-empty subset of $\rr$, show that
    $X$ is bounded if and only if $\inf(X)$ and $\sup(X)$ are finite.}

  First suppose that $X$ is bounded. Thus, by definition, there exists
  a positive real number $M$ such that $X \subseteq [-M, M]$. Thus, we
  have $\sup(X) \leq M$ (because $M$ is an upper bound of $X$, and
  $\sup(X)$ is the least upper bound), so that $\sup(X)$ is finite.
  Similarly for $\inf(X) \geq -M$.

  Now suppose that both $\inf(X)$ and $\sup(X)$ are finite. We thus
  have $\inf(X) = a$ and $\sup(X) = b$ for some real numbers $a,b$. By
  definition, we have $a \leq x \leq b$ for all $x \in X$. It means
  that $X \subseteq [a,b]$. Let's pick $M := \max(|a|, |b|)$; we thus
  have $X \subseteq [-M, M]$ as expected.  
\end{exo}

\bigskip
\begin{exo}{9.1.11}{Show that if $X$ is a bounded subset of $\rr$,
    then the closure $\adh{X}$ is also bounded.}

  If $X$ is bounded, we have $X \subseteq [-M,M]$ for some positive
  real number $M$. The interval $[-M,M]$ is a closed subset, thus its
  closure is also $[-M,M]$. Now let's use Exercise 9.1.6, with
  $Y := [-M,M]$ being the closed subset that contains $X$; we thus have
  $X \subseteq \adh{X} \subseteq [-M,M]$. It means that $\adh{X}$ is
  bounded, as expected.
\end{exo}

\bigskip
\begin{exo}{9.1.13}{Prove Theorem 9.1.24 (Heine-Borel theorem).}

  We have to prove that these two statements are equivalent for any
  subset $X$ of $\rr$: (a) $X$ is closed and bounded; (b) from any
  sequence of elements of $X$, one can get a subsequence that
  converges to a real number $L \in X$.

  \begin{itemize}
  \item First we prove that (a) implies (b). Let be $X$ a subset of
    $\rr$ which is closed and bounded, and let be $\seq{a_n}{0}$ a
    sequence such that $a_n \in X$ for all $n \geq 0$. Since $X$ is
    bounded, there exists a real number $M > 0$ such that
    $X \subseteq [-M, M]$. The sequence $\seq{a_n}{0}$ is bounded: we
    have necessarily $|a_n| \leq M$ (because $a_n \in X$) for all
    $n \geq 0$. Since $\seq{a_n}{0}$ is bounded, there exists a
    subsequence of $\seq{a_n}{0}$ which converges to a real number
    $L \in \rr$ (Bolzano-Weierstrass theorem). But since $X$ is
    closed, we have $L \in X$ by Corollary 9.1.17. The claim follows.
  \item Now we prove that (b) implies (a). We start from (b), and
    suppose for the sake of contradiction that $X$ is not closed.
    Thus, there exists a sequence $\seq{a_n}{0}$ such that $a_n \in X$
    for all $n \geq 0$, which converges to a real number $L \notin X$
    (by negation of Corollary 9.1.17). But according to (b), from the
    sequence $\seq{a_n}{0}$, we can extract a subsequence that
    converges to $L' \in X$. It is a contradiction, since it implies
    that $L \neq L'$, which is impossible by Proposition 6.6.5. Thus,
    $X$ is closed.

    Furthermore, $X$ is bounded. Indeed, 
  \end{itemize}
\end{exo}


\begin{exo}{9.1.14}{Show that any finite subset of $\rr$ is closed and
    bounded.}

  Let be $A_n$ a finite subset of $\rr$. We can use induction on $n$,
  the number of elements of $A_n$.

  \begin{itemize}
  \item For the base case, $A_1$ is simply a singleton set; say that
    $A_1 := \{a_1\}$ with $a_1 \in \rr$. Obviously, $A_1$ is closed,
    because $a_1$ is an adherent point of $A_1$, and no other real can
    be $\epsilon$-adherent to $A_1$ for all $\epsilon > 0$ (if
    $x \neq a_1$, then $x$ is not $\epsilon$-adherent to $A_1$ for
    $\epsilon = |x-a_1|/2$, for instance). Furthermore, $A_1$ is
    bounded, since $|x| \leq a_1$ for all $x \in A_1$.
  \item Now suppose inductively that any set $A_n$ is closed and
    bounded if $A_n$ has $n$ elements, and let's show that any set
    $A_{n+1}$ with $n+1$ elements is also closed and bounded. If
    $A_{n+1}$ has $n+1$ elements, then we have $A_{n+1} = A_n \cup
    \{a_{n+1}\}$, where $A_n$ has $n$ elements (e.g., Proposition
    3.6.14 (a)). But, by the base case, $\{a_{n+1}\}$ is closed and
    bounded; and by the induction hypothesis, $A_n$ is closed and
    bounded. Thus, by Exercise 9.1.7, $A_n \cup \{a_{n+1}\}$ is also
    closed. This union set is also bounded: if $A_n$ is bounded by
    $M$, then $A_{n+1}$ is bounded by $\max(M, |a_{n+1}|)$.

    Now let's show that $X$ is bounded. Suppose for the sake of
    contradiction that $X$ is not bounded. In particular, either $X$
    has no upper bound, or no lower bound (or both). Suppose that $X$
    has no upper bound; the proof is similar if it has no lower bound.
    Saying that $X$ is not bounded above means that, for all $n \geq
    0$, the set $A_n := \{x \in X \, : \, x > n \}$ is not empty.
    Thus, by the axiom of (countable) choice, we can define a sequence
    $\seq{a_n}{0}$ such that $a_n \in A_n$ for all $n \geq 0$. In
    particular, we have $a_n > n$ for all $n \geq 0$. But this
    sequence has no limit point: indeed, saying that $\seq{a_n}{0}$
    has a finite limit point $L$ means that:
    \begin{equation}
      \label{exo9.1.13}
      \forall \epsilon > 0, \forall N \geq 0, \exists n \geq N \, :
      \, L - \epsilon \leq a_n \leq L + \epsilon
    \end{equation}
    But this is impossible: let's take $\epsilon = 1$, and any
    $n > L+1$; we thus have $a_n > L + 1$ by definition, which is not
    compatible with \eqref{exo9.1.13}. And according to Proposition
    6.6.6, if $\seq{a_n}{0}$ has no limit point, then we cannot
    extract a convergent subsequence from $\seq{a_n}{0}$; a
    contradiction with our initial hypothesis (a). This closes the
    proof.
  \end{itemize}
\end{exo}

\begin{exo}{9.2.1}{Let $f, g, h$ be functions from $\rr$ to $\rr$:
    which of the following statements are true?}

  The first statement, $(f+g) \circ h = (f \circ h) + (g \circ h)$,
  is true. Indeed, we have for all $x \in \rr$:
  \begin{align*}
    ((f+g) \circ h) (x) &= (f+g) (h(x)) \\
                        &= f(h(x)) + g(h(x)) \\
                        &= (f \circ h) (x) + (g \circ h) (x)
  \end{align*}

  The second statement, $f \circ (g+h) = (f \circ g) + (f \circ h)$,
  is false. Indeed, let's consider $f(x) = x^2$, $g(x) = x$ and $h(x)
  = -x$. On the one hand we have $f \circ (g+h) (1) = f(1 - 1) = f(0)
  = 0$; and the other hand we have $(f \circ g + f \circ h) (1) = f(1)
  + f(-1) = 1 + 1 = 2$.

  The third statement, $(f+g) \times h = (f \times h) + (g \times h)$,
  is true. Indeed, we have for all $x \in \rr$:
  \begin{align*}
    ((f+g) \times h)(x) &= (f+g)(x) \times h(x) \\
                        &= (f(x) + g(x)) \times h(x) \\
                        &= f(x)h(x) + g(x)h(x)
  \end{align*}

  The last statement, $f \times (g+h) = (f \times g) + (f \times h)$,
  is true. Indeed, we have for all $x \in \rr$:
  \begin{align*}
    (f \times (g+h))(x) &= f(x) \times (g+h)(x) \\
                        &= f(x) \times (g(x) + h(x)) \\
                        &= f(x)g(x) + f(x)h(x)
  \end{align*}  
\end{exo}

\begin{exo}{9.3.1}{Prove Proposition 9.3.9.}

  We must prove that these two statements are equivalent: (a) $f$
  converges to $L$ at $x_0$ in $E$; (b) for every sequence
  $\seq{a_n}{0}$ which consists entirely of elements of $E$ and
  converges to $x_0$, the sequence $\seq{f(a_n)}{0}$ converges to $L$.

  \begin{itemize}
  \item First we prove that (a) implies (b). Suppose that $f$
    converges to $L$ at $x_0$, and let be $\seq{a_n}{0}$ a sequence of
    elements of $E$ that converges to $x_0$. We must show that:
    \begin{equation}
      \label{eq:931a}
      \forall \epsilon > 0, \exists N \geq 0 \, : \, n \geq N
      \Longrightarrow |f(a_n) - L| \leq \epsilon
    \end{equation}

    Let be $\epsilon > 0$. We know that there exists a $\delta > 0$
    such that $|x - x_0| < \delta \Rightarrow |f(x) - L| \leq
    \epsilon$. Consider this positive real $\delta$. Since
    $\seq{a_n}{0}$ converges to $x_0$, there exists a natural number
    $N$ such that $n \geq N \Rightarrow |a_n - x_0| \leq \delta$.
    Thus, for this number $N$, we have:
    \[n \geq N \Longrightarrow |a_n - x_0| \leq \delta \Longrightarrow
      |f(a_n) - L| \leq \epsilon\]
    so that this natural number $N$ is suitable for the property in
    equation \eqref{eq:931a}. This closes the first part of the proof.
  \item Conversely, let's prove that (b) implies (a). Suppose for the
    sake of contradiction that we have (b), but $f$ does not converges
    to $L$ at $x_0$. It means that:
    \begin{equation}
      \label{eq:931b}
      \exists \epsilon > 0 \, : \, \forall \delta > 0, \exists x \in E,
      |x-x_0| < \delta \text{ and } |f(x) - L| > \epsilon
    \end{equation}

    And in particular:
    \begin{equation}
      \label{eq:931c}
      \exists \epsilon > 0 \, : \, \forall n \geq 0, \exists a_n \in E,
      |a_n - x_0| < \frac{1}{n+1} \text{ and } |f(a_n) - L| > \epsilon
    \end{equation}
    
    Consider this positive real $\epsilon > 0$. Using equation
    \eqref{eq:931c}, we build a sequence\footnote{We ``secretly'' use
      the axiom of choice here.} $\seq{a_n}{0}$ of elements of $E$
    such that, for all $n \geq 0$, we have
    $x_0 - \frac{1}{n+1} < a_n < x_0 + \frac{1}{n+1}$. According to
    the squeeze test, it implies that $\seq{a_n}{0}$ converges to
    $x_0$. But at the same time, $f(a_n)$ is never $\epsilon$-close to
    $L$, still according to equation \eqref{eq:931c}. This is a
    contradiction with the hypothesis (b). The claim follows.
  \end{itemize}
\end{exo}

\begin{exo}{9.3.2}{Prove the remaining claims in Proposition 9.3.14.}

  All the claims can be proved in a very similar fashion, and each of
  them is itself very similar to the proof of the first claim given in
  the book. We will just prove another one, namely that $fg$ has a
  limit $LM$ at $x_0$ in $E$.

  Since $x_0$ is adherent to $E$, there exists a sequence
  $\seq{a_n}{0}$ of elements of $E$ that converges to $x_0$ (Lemma
  9.1.14). By Proposition 9.3.9, we thus know that $\seq{f(a_n)}{0}$
  converges to $L$. Similarly, $\seq{g(a_n)}{0}$ converges to $M$. By
  Theorem 6.1.19(b), we have
  \[\lim_{n \to \infty} \seq{(f \times g)(a_n)}{0} =
    \lim_{n \to \infty} \seq{f(a_n)}{0} \times \lim_{n \to \infty}
    \seq{g(a_n)}{0} = LM.\] Thus, since $\seq{a_n}{0}$ is an arbitrary
  sequence, we have showed that for any sequence $\seq{a_n}{0}$ of
  elements of $E$ that converges to $x_0$, the sequence
  $\seq{(fg)(a_n)}{0}$ converges to $LM$. Thus, by Proposition 9.3.9,
  $fg$ has a limit $LM$ at $x_0$ in $E$.
\end{exo}

\bigskip
\begin{exo}{9.3.3}{Prove Lemma 9.3.18.}

  Let be $\delta > 0$ a positive real number. We have the following
  equivalent statements:

  \begin{align*}
    & \lim_{x \to x_0 \, ; \, x \in E \cap ]x_0 - \delta, x_0 + \delta[}
      f(x) = L \\
    & \Longleftrightarrow \left( \forall \epsilon > 0, \exists \alpha > 0 \,
      : \, x \in \{z \in E \cap ]x_0 - \delta, x_0 + \delta[ \, : \,
      |z - x_0| < \alpha\} \Rightarrow |f(x) - L| < \epsilon \right) \\
    & \Longleftrightarrow \left( \forall \epsilon > 0, \exists \alpha > 0 \,
      : \, x \in \{z \in E \cap ]x_0 - \min(\delta, \alpha), x_0 +
      \min(\delta, \alpha)[\} \Rightarrow |f(x) - L| < \epsilon
      \right) \\
    & \Longleftrightarrow \left( \forall \epsilon > 0, \exists \gamma > 0 \,
      : \, x \in \{z \in E \cap ]x_0 - \gamma, x_0 + \gamma[ \}
      \Rightarrow |f(x) - L| < \epsilon \right) \\
    & \Longleftrightarrow \lim_{x \to x_0 \, ; \, x \in E} f(x) = L 
  \end{align*}
\end{exo}

\begin{exo}{9.4.1}{Prove Proposition 9.4.7.}

  We will prove the following implications: (a) implies (c), (c)
  implies (d), (d) implies (b), and (b) implies (a).

  \begin{itemize}
  \item First we prove that (a) implies (c). Let be $\epsilon > 0$ a
    positive real. If $f$ is continuous at $x_0$, then by Definition
    9.4.1, we have $\lim_{x \to x_0} f(x) = f(x_0)$. Thus, for any
    $\epsilon' > 0$, there exists $\delta > 0$ such that
    $|x-x_0| < \delta \Rightarrow |f(x)-f(x_0)| \leq \epsilon'$. Let's
    take $\epsilon' := \epsilon/2$, and we have
    $|x-x_0| < \delta \Rightarrow |f(x)-f(x_0)| \leq \epsilon' <
    \epsilon$, as expected for (c).
  \item Then, it is simply obvious that (c) implies (d), since (c) is
    simply one of the possible cases of (d).
  \item Now we show that (d) implies (b). Let be $\seq{a_n}{0}$ a
    sequence that converges to $x_0$. Also, let $\epsilon > 0$ be a
    positive real number. Then, by (d), there exists $\delta > 0$ such
    that $|x - x_0| \leq \delta \Rightarrow |f(x) - f(x_0)| \leq
    \epsilon$. Let's consider this number $\delta > 0$. Since
    $\seq{a_n}{0}$ converges to $x_0$, there exists $N \geq 0$ such
    that $n \geq N \Rightarrow |a_n - x_0| \leq \delta$.

    Gathering all those implications, for any arbitrary $\epsilon >
    0$, we have found a natural number $N \geq 0$ such that, if $n
    \geq N$, then we have $|a_n - x_0| \leq \delta$, and thus $|f(a_n)
    - f(x_0)| \leq \epsilon$. It means that $\seq{f(a_n)}{0}$
    converges to $f(x_0)$, as expected.
  \item And finally, we have to prove that (b) implies (a). This is a
    direct application of Proposition 9.3.9.
  \end{itemize}
\end{exo}

\begin{exo}{9.4.2}{Let $X$ be a subset of $\rr$, and let $c \in \rr$.
    Show that the constant function $f : X \to \rr$ defined by
    $f(x) := c$ is continuous, and show that the identity function
    $g : X \to \rr$ defined by $g(x) := x$ is also continuous.}

  The remarks made in the textbook page 224, along with the Examples
  9.4.2 and 9.4.3, would suffice to show this property. But we will
  ignore those paragraphs and give a proper proof, mainly using
  Proposition 9.3.9.

  \begin{itemize}
  \item First we show that the constant function $f(x)=c$ is
    continuous. Let be $x_0$ any real number. Let be $\seq{a_n}{0}$
    any sequence of real numbers that converges to $x_0$. By
    Proposition 9.3.9, the sequence $\seq{f(a_n)}{0}$ must converge to
    $L$, which is the limit $L := \lim_{x \to x_0} f(x)$. But the
    sequence $\seq{f(a_n)}{0}$ is the constant sequence
    $c,c,c,\ldots$, which necessarily converges to $c$. Thus, by
    Proposition 9.3.9, we have $L = c$. This shows that $f$ is
    continuous at any real number $x_0$.
  \item Now we show that the identity function $f(x) = x$ is
    continuous. Let be $x_0$ any real number. Let be $\seq{a_n}{0}$
    any sequence of real numbers that converges to $x_0$. By
    Proposition 9.3.9, the sequence $\seq{f(a_n)}{0}$ must converge to
    $L$, which is the limit $L := \lim_{x \to x_0} f(x)$. But the
    sequence $\seq{f(a_n)}{0}$ is the sequence $\seq{a_n}{0}$, which
    is known to converge to $x_0$. Thus, by Proposition 9.3.9, we have
    $L = x_0$. This shows that $f$ is continuous at any real number
    $x_0$.
  \end{itemize}
\end{exo}

\begin{exo}{9.4.3}{Prove Proposition 9.4.10. (Hint: you can use Lemma
    6.5.3, combined with the squeeze test (Corollary 6.4.14) and
    Proposition 6.7.3.)}

  Let be $a >0$ a positive real, and we must show that $f : \rr \to
  \rr$ defined by $f(x) := a^x$ is continuous. In other words, we must
  show that, for any real number $x_0$, we have:
  \begin{equation}
    \label{eq:943a}
    \lim_{x \to x_0} a^x = a^{x_0},
  \end{equation}
  By Proposition 9.4.7, one way to show that is to prove that for any
  sequence $\seq{r_n}{0}$ of \emph{real} numbers that converges to
  $x_0$, we have
  \begin{equation}
    \label{eq:943b}
    \lim_{n \to \infty} a^{r_n} = a^{x_0}.
  \end{equation}
  This result is not immediate because we just know similar results
  for sequences of \emph{rational} numbers (e.g., Definition 6.7.2).

  In what follows, as in the proof of Lemma 6.7.1, we should consider
  three distinct cases: $a>1$, $a=1$ and $a<1$. We will only prove the
  first one, because the second one is obvious and the third one is
  very similar.

  Thus, let be $\seq{r_n}{0}$ a sequence of \emph{real} numbers
  that converges to $x_0$. We must show \eqref{eq:943b}.

  By Proposition 5.4.14, there exists a \emph{rational} number
  $\alpha_n$ in the interval $]r_n - 1/n, r_n[$ for all $n > 0$.
  Similarly, there exists a \emph{rational} number $\beta_n$ in the
  interval $]r_n, r_n + 1/n[$ for all $n > 0$. Thus, using the axiom
  of countable choice, we can build two sequences of rational numbers,
  $\seq{\alpha_n}{0}$ and $\seq{\beta_n}{0}$, such that we have
  \begin{equation}
    \label{eq:943c}
    r_n - 1/n < \alpha_n < r_n < \beta_n < r_n + 1/n
  \end{equation}
  for all $n > 0$ (there is a tiny problem for $n=0$, but we could
  have chosen $1/(n+1)$ instead of $1/n$ to solve it). Also, it is
  obvious that $\seq{\alpha_n}{0}$, $\seq{r_n}{0}$ and
  $\seq{\beta_n}{0}$ are all equivalent sequences, and thus they all
  converge to $x_0$.

  Thus, starting from \eqref{eq:943c} and using Lemma 5.6.9(e) applied
  to real numbers, we have in particular, since $a > 1$ by hypothesis:
  \begin{equation}
    \label{eq:943d}
    a^{\alpha_n} < a^{r_n} < a^{\beta_n}
  \end{equation}
  for all $n > 0$. But, by Definition 6.7.2, we know that
  $\lim_{n \to \infty} a^{\alpha_n} = a^{x_0}$ and
  $\lim_{n \to \infty} a^{\beta_n} = a^{x_0}$. Thus, by the squeeze
  test, we also have $\lim_{n \to \infty} a^{r_n} = a^{x_0}$, as
  expected. This closes the proof.
\end{exo}

\bigskip
\begin{exo}{9.4.4}{Prove Proposition 9.4.11. (Hint: from limit laws
    (Proposition 9.3.14) one can show that $\lim_{x\to 1} x^n = 1$ for
    all integers $n$. From this and the squeeze test (Corollary
    6.4.14) deduce that $\lim_{x \to 1} x^p = 1$ for all real numbers
    $p$. Finally, apply Proposition 6.7.3.)}

  We follow the hint to show that:

  \begin{enumerate}
  \item $\lim_{x\to 1} x^n = 1$ for all integers $n$. If $n=0$, the
    statement is obvious. If $n$ is a positive integer, then a quick
    induction shows the result: for the base case $n=1$, we know that
    $\lim_{x \to 1} x = 1$ by Example 9.4.3 (for instance), and then we
    get the result for all $n > 0$ since $x^{n+1} = x^n \times x$,
    using the limit laws. A similar argument applies if $n < 0$,
    because we know (for instance by the limit laws) that $\lim_{x \to
      1} 1/x = 1$, and that $1/x^{n+1} = (1/x) \times (1/x^n)$.
  \item (TODO) $\lim_{x \to 1} x^p = 1$ for all real numbers $p$.
  \item (TODO) Finally, we can conclude that the function
    $f : ]0, \infty[ \to \rr$ defined by $f(x) := x^p$ is continuous.
    We must show that $\lim_{x \to a} x^p = a^p$ for all $a \in \rr$.
    Let be $\epsilon > 0$. By the previous result, there exists
    $\alpha > 0$ such that $|x - 1| < \alpha \Rightarrow |x^p - 1| <
    \epsilon/a^p$. Multiplying this last inequality by $a^p$ (which
    preserves order since $a > 0$), we get:
    \[ \forall \epsilon > 0, \exists \alpha > 0 \, : \, |x-1| < \alpha
      \Rightarrow |x^p - | < \epsilon\]
  \end{enumerate}
\end{exo}

\begin{exo}{9.4.5}{Prove Proposition 9.4.13.}

  To show the result, by Proposition 9.4.7(b), we have to prove that,
  for any sequence $\seq{a_n}{0}$ of elements of $X$ that converges to
  $x_0$, the sequence $\seq{g \circ f (a_n)}{0}$ converges to
  $g \circ f (x_0)$.

  Thus, let be $\seq{a_n}{0}$ a sequence of elements of $X$ that
  converges to $x_0$. Because $f$ is continuous at $x_0$, the sequence
  $\seq{f(a_n)}{0}$ converges to $f(x_0)$. And since $g$ is continuous
  at $f(x_0)$, the sequence $\seq{g(f(a_n))}{0}$ converges to
  $g(f(x_0))$.

  Thus, for any sequence $\seq{a_n}{0}$ of elements of $X$ that
  converges to $x_0$, the sequence $\seq{g \circ f (a_n)}{0}$
  converges to $g \circ f (x_0)$, i.e., by Proposition 9.4.7, $g \circ
  f$ is continuous at $x_0$, as expected.
\end{exo}
\bigskip

\begin{exo}{9.4.6}{Let $X$ be a subset of $\rr$, and let
    $f: X \to \rr$ be a continuous function. If $Y$ is a subset of
    $X$, show that the restriction $f|_Y : Y \to \rr$ of $f$ to $Y$ is
    also a continuous function.}

  Let be $x_0 \in X$. Since $f$ is continuous on $X$, it is continuous
  in $x_0$, and then we have:
  \begin{equation}
    \label{eq:946a}
    \forall \epsilon > 0, \exists \delta > 0 \, : \, x \in ]x_0 - \delta,
    x_0 + \delta[ \cap X \Longrightarrow |f(x) - f(x_0)| < \epsilon
  \end{equation}

  Now let be $y_0 \in Y$. In particular, $y_0 \in X$. Let be the
  $\delta > 0$ given by equation \ref{eq:946a}. Then for any $y \in ]y_0 - \delta,
    y_0 + \delta[ \cap Y$, we also have $y \in ]y_0 - \delta,
    y_0 + \delta[ \cap X$, so that we have indeed $|f(y) - f(y_0)| <
    \epsilon$ still be equation \ref{eq:946a}. Since $y_0$ is
    arbitrary, $f|_Y$ is continuous.
\end{exo}

\bigskip
\begin{exo}{9.5.1}{Let $E$ be a subset of $\rr$, let $f : E \to \rr$
    be a function, and let $x_0$ be an adherent point of $E$. Write
    down a definition of what it would mean for the limit
    $lim_{x \to x_0 ; x \in E} f(x)$ to exist and equal $+ \infty$ or
    $- \infty$. If $f : \rr - \{0\} \to \rr$ is the function
    $f (x) := 1/x$, use your definition to conclude $f(0+) = +\infty$
    and $f(0-) = - \infty$.}

  We can state the following definition. We have
  $\lim_{x \to x_0 ; x > x_0} f(x) = + \infty$ iff for any positive
  real $A > 0$, there exists $\delta > 0$ such that $f(x) > A$ for all
  $x \in ]x_0, x_0 + \delta[$. We have
  $\lim_{x \to x_0 ; x < x_0} f(x) = + \infty$ iff for any positive
  real $A > 0$, there exists $\delta > 0$ such that $f(x) > A$ for all
  $x \in ]x_0 - \delta, x_0[$. We have
  $\lim_{x \to x_0} f(x) = + \infty$ iff
  $\lim_{x \to x_0 ; x > x_0} f(x) = + \infty = \lim_{x \to x_0 ; x <
    x_0} f(x)$.

  (A similar definition can be written for $- \infty$.)

  In particular, let's consider the function $f(x) := 1/x$ defined on
  $\rr - \{0\}$. Let be $A > 0$ a positive real number. Then, let be
  $\delta := 1/(A+1) > 0$. For any $x \in ]0, \delta[$, we have
  $|x-0| = |x| < 1/(A+1)$, i.e. $x < 1/(A+1)$, and thus $1/x > A+1 >
  A$. Thus, $f(0+) = \infty$ according to the above definition.

  A similar proof can be given to show that $f(0-) = -\infty$.
\end{exo}
\bigskip

\begin{exo}{9.6.1}{Give examples of: (a) a function $f: ]1,2[ \to \rr$
    which is continuous and bounded, attains its minimum somewhere,
    but does not attain its maximum anywhere; (b) a function
    $f:[0,\infty[ \to \rr$ which is continuous and bounded, attains
    its maximum somewhere, but does not attain its minimum anywhere;
    (c) a function $f:[-1,1]\to \rr$ which is bounded but does not
    attain its minimum anywhere or its maximum anywhere; (d) a
    function $f:[-1,1]\to \rr$ which has no upper bound and no lower
    bound. Explain why none of the examples you construct violate the
    maximum principle.}

  We can find the following examples:

  \begin{enumerate}[label=(\alph*)]
  \item $f(x) = |x - 1.5|$ is an example of such a function. It does
    not contradict the maximum principle since $]1,2[$ is not closed.
  \item $f(x) = 1/(x+1)$ is an example. It does not contradict the
    maximum principle since $]0, +\infty[$ is not closed.
  \item $f(x)$ defined by $f(x) = |x|$ if $x \not \in \{-1, 0, 1\}$
    and $f(x) = 0.5$ if $x \in \{-1,0,1\}$ is an example.  It does
    not contradict the maximum principle since it is not continuous.
  \item $f(x)$ defined by $f(x) = 1/x$ if $x \neq 0$ and $f(0) = 0$ is
    an example. It does not contradict the maximum principle since it
    is not continuous.
  \end{enumerate}
\end{exo}

\begin{exo}{9.7.1}{Prove Corollary 9.7.4.}
  
  Since $f$ is continuous on $[a,b]$, then by the maximum principle
  (Proposition 9.6.7), there exists $x_{max} \in [a,b]$ such that
  $f(x_{max}) = M$, and $x_{min} \in [a,b]$ such that
  $f(x_{min}) = m$.

  We can suppose without loss of generality that $x_{min} < x_{max}$;
  because the case $x_{max} < x_{min}$ can be proved similarly, and
  there is almost nothing to prove if $x_{min} = x_{max}$ ($f$ would
  be constant, so picking any $c \in [a,b]$ would be sufficient).

  By Exercise 9.4.6, since $f$ is continuous on $[a,b]$, then $f$ is
  also continuous on $[x_{min}, x_{max}]$. We can thus apply the
  intermediate value theorem on this interval to get the result: for
  any $y \in [m,M]$, there exists indeed a $c \in [x_{min}, x_{max}]$
  such that $f(c) = y$.

  Also, we know that for any $y \in f([a,b])$, we have both $y \leq M$
  and $y \geq m$ by definition, so that $f([a,b]) \subseteq [m,M]$.
  And by the result we have just shown, we also know that
  $[m,M] \subseteq f([a,b])$, thus we are done.  
\end{exo}

\bigskip
\begin{exo}{9.7.2}{Let $f : [0,1] \to [0,1]$ be a continuous function.
    Show that there exists a real number $x$ in $[0,1]$ such that
    $f(x) = x$. This point $x$ is known as a fixed point of $f$.}

  Let be the function $g : [0,1] \to \rr$ defined by $g(x) := f(x) -
  x$.

  \begin{itemize}
  \item This function $g$ is continuous on $[0,1]$, since $f$ is
    continuous by hypothesis, the identity function $x \mapsto x$ is
    also continuous (Exercice 9.4.2), and the difference of two
    continuous functions is still continuous (Proposition 9.4.9).
  \item Furthermore, note that $f(x) = x$ iff $g(x) = 0$. We thus have
    to prove that there exists a $x \in [0,1]$ such that $g(x) = 0$.
  \item We have $g(0) = f(0) \in [0,1]$; and $g(1) = f(1) - 1 \in
    [-1,0]$. Thus, we have in particular $g(1) \leq 0 \leq g(0)$, and
    $g$ is continuous. The intermediate value theorem thus says that
    there exists a $x \in [0,1]$ such that $g(x) = 0$, as desired.
  \end{itemize}
\end{exo}

\begin{exo}{9.8.1}{Explain why the maximum principle remains true if
    the hypothesis that $f$ is continuous is replaced with $f$ being
    monotone, or with $f$ being strictly monotone. (You can use the
    same explanation for both cases.)}

  Let be $f : [a,b] \to \rr$ an increasing function. By definition, we
  have $f(x) \leq f(y)$ for all $x,y \in [a,b]$ such that $x \leq y$.
  In particular, since $x \leq b$ for all $x \in [a,b]$, we have $f(x)
  \leq f(b)$ for all $x \in [a,b]$. And thus, since $b \in [a,b]$, $f$
  attains its maximum at $b$ on $[a,b]$. Similarly, it attains its
  minimum at $a$.

  The proof is similar if $f$ is supposed to be strictly increasing,
  or decreasing, or strictly decreasing.
\end{exo}

\bigskip
\begin{exo}{9.8.2}{Give an example to show that the intermediate value
    theorem becomes false if the hypothesis that $f$ is continuous is
    replaced with $f$ being monotone, or with $f$ being strictly
    monotone. (You can use the same counterexample for both cases.)}

  Let's simply consider the (strictly increasing function
  $f : [0,2] \to \rr$ defined by $f(x) = x$ if $x \in [0,1[$ and
  $f(x) = x+1$ if $x \in [1,2]$. Then, for instance, we have
  $f(0) = 0$ and $f(2) = 3$, but there is no real $x \in [0,2]$ such
  that $f(x) = 3/2$.
\end{exo}
\bigskip

\begin{exo}{9.8.3}{Let $a < b$ be real numbers, and let
    $f : [a, b] \to \rr$ be a function which is both continuous and
    one-to-one. Show that $f$ is strictly monotone.}

  (This one may be more a detailed sketch of a proof rather than an
  actual rigorous proof.) We divide the proof into three cases:

  \begin{enumerate}
  \item If we suppose $f(a) = f(b)$, then we have immediately a
    contradiction, since $f$ is not injective. This case is thus
    simply impossible. (More generally, $f$ cannot be constant on any
    interval $[c,d] \subseteq [a,b]$, since it would obviously not be
    injective in such a case. Thus, $f$ can only be strictly
    increasing or strictly decreasing on such intervals.)
  \item If we suppose $f(a) > f(b)$, let's suppose for the sake of
    contradiction that $f$ is not strictly monotone increasing on
    $[a,b]$. Actually, $f$ must at least be strictly increasing on a
    subset of $[a,b]$, since $f(a) > f(b)$ (otherwise we have an
    obvious contradiction), but this hypothesis means that $f$ is not
    strictly increasing on the whole interval $[a,b]$. Thus, there
    must exist three real numbers $c,d,e$, such that
    $a \leq c < d < e \leq b$, and we have yet another time several
    possible cases:
    \begin{itemize}
    \item $f$ is strictly increasing on $[c,d]$ and strictly
      decreasing on $[d,e]$, i.e., we have $f(c) < f(d)$ and
      $f(d) > f(e)$. One can show that\footnote{Actually, this is
        yet another division into cases, depending on whether
        $f(c) > f(e)$ or $f(c) \leq f(e)$, but this is easily shown,
        and even more easily understandable by drawing a picture.}
      $m := \frac{f(c) + f(e)}{2}$ belongs to both intervals
      $[f(c), f(d)]$ and $[f(d), f(e)]$. Thus, applying the
      intermediate value theorem on each interval $[c,d]$ and $[d,e]$
      shows that there exists $x_1 \in [c,d]$, $x_2 \in [d,e]$ such
      that $f(x_1) = f(x_2) = m$, although $x_1 \neq x_2$. (The only
      possibility for $x_1$ and $x_2$ to be equal to each other would
      be that $x_1 = x_2 = d$, which would imply that $f$ is constant
      on both $[c,d]$ and $[d,e]$, a contradiction.) Thus $f$ would
      not be injective, a contradiction.
    \item A similar argument applies if $f$ is strictly decreasing on
      $[c,d]$ and then increasing on $[d,e]$.
    \end{itemize}
  \item If we suppose $f(a) < f(b)$, a direct adaptation of the second
    case shows immediately that $f$ must be strictly monotone
    decreasing.
  \end{enumerate}
\end{exo}

\begin{exo}{9.9.1}{Prove Lemma 9.9.7.}

  We have to prove that two sequences $\seq{a_n}{1}$ and
  $\seq{b_n}{1}$ are equivalent if and only if
  $\lim_{n \to \infty} (a_n - b_n) = 0$.

  \begin{itemize}
  \item If these two sequences are equivalent (in the sense of
    Definition 9.9.5), then let be $\epsilon > 0$. By definition,
    there exists $N \geq 1$ such that, for all $n \geq N$, we have
    $|a_n - b_n| \leq \epsilon$, i.e., $|(a_n - b_n) - 0| \leq
    \epsilon$. This means precisely that $\lim_{n \to \infty} (a_n -
    b_n) = 0$.
  \item All these steps can be reversed to show that if $\lim_{n \to
      \infty} (a_n - b_n) = 0$, then $\seq{a_n}{1}$ and $\seq{b_n}{1}$
    are equivalent.
  \end{itemize}
\end{exo}

\begin{exo}{9.9.2}{Prove Proposition 9.9.8.}

  Recall the two statements:
  \begin{enumerate}[label=(\alph*)]
  \item $f$ is uniformly continuous on $X$
  \item For any two equivalent sequences $\seq{x_n}{1}$ and
    $\seq{y_n}{1}$ of elements of $X$, the sequences $\seq{f(x_n)}{1}$
    and $\seq{f(y_n)}{1}$ are also equivalent.
  \end{enumerate}

  Let's prove each implication separately.

  \begin{itemize}
  \item First, we show that (a) implies (b). Let be $\seq{x_n}{1}$ and
    $\seq{y_n}{1}$ two equivalent sequences of elements of $X$. Let be
    $\epsilon > 0$. Since $f$ is uniformly continuous, there exists
    $\delta > 0$ such that $|f(x) - f(y)| \leq \epsilon$ whenever
    $|x-y| \leq \delta$ (for $x,y \in X$).

    But since $\seq{x_n}{1}$ and $\seq{y_n}{1}$ are equivalent, there
    exists $N \geq 1$ such that $n \geq N$ implies $|x_n - y_n| \leq
    \delta$.

    Thus, if $n \geq N$, we have $|x_n - y_n| \leq \delta$, and thus
    $|f(x_n) - f(y_n)| \leq \epsilon$. This means that
    $\seq{f(x_n)}{1}$ and $\seq{f(y_n)}{1}$ are equivalent.
  \item Now we show that (b) implies (a). We will use contradiction
    here\footnote{Note that we use the same approach as in Exercise
      9.3.1.}. Thus, we suppose that (b) is true, but that $f$ is not
    uniformly continuous. For $f$, not being uniformly continuous
    means that:
    \begin{equation}
      \label{eq:992a}
      \exists \epsilon > 0, \exists y_0 \in X \, : \; \forall \delta
      \leq 0, \: |f(x) - f(y_0)| \geq \epsilon, \text{ although } |x-y_0|
      < \delta
    \end{equation}
    If we consider a sequence $\seq{x_n}{1}$ of elements of $X$ that
    converges to $y_0$, then the sequences $\seq{x_n}{1}$ and
    $\seq{y_0}{1}$ are equivalent. This is thus a clear contradiction
    with \eqref{eq:992a}.
  \end{itemize}
\end{exo}
\pagebreak

\section{Differentiability}
\begin{exo}{10.1.2}{Prove Proposition 10.1.7.}

  We have to prove the principle of Newton's approximation, i.e. that
  (a) $f$ is differentiable at $x_0$ iff (b) we have a linear
  approximation of $f$ at $x_0$:
  \begin{equation}
    \label{eq:10.1.2a}
    \forall \epsilon > 0, \exists \delta > 0 \, : \, |x-x_0| \leq \delta
    \Longrightarrow |f(x) - (f(x_0) + L(x-x_0))| \leq \epsilon|x-x_0|
  \end{equation}

  \begin{itemize}
  \item First consider the case $x \neq x_0$. We know that the
    following statements are logically equivalent:
    \begin{align*}
      & f \text{ is differentiable at } x_0 \in X
      & \\
      \Longleftrightarrow & \lim_{x \to x_0; x \in X - \{x_0\}} \frac{f(x)-f(x_0)}{x-x_0} = L &\\
      \Longleftrightarrow & \forall \epsilon > 0, \exists \delta > 0
                            \, : \, |x - x_0| \leq \delta \Longrightarrow
                            \left|\frac{f(x) - f(x_0)}{x-x_0} - L\right| \leq \epsilon &\\
      \Longleftrightarrow & \forall \epsilon > 0, \exists \delta > 0
                            \, : \, |x - x_0| \leq \delta
                            \Longrightarrow |f(x) - f(x_0) - L(x-x_0)|
                            \leq \epsilon |x-x_0|&
    \end{align*}
  \item If $x=x_0$, there is almost nothing to prove, since all the
    terms implied here are null.
  \end{itemize}

  This closes the proof in both cases.
\end{exo}

\bigskip
\begin{exo}{10.1.3}{Prove Proposition 10.1.10.}

  We have to show that differentiability implies continuity. Let be
  $f : X \to \rr$ a function which is continuous at $x_0 \in X$. It
  means that we have
  \begin{equation}
    \label{eq:10.1.3a}
    \lim_{x \to x_0; x \in X - \{x_0\}} \frac{f(x)-f(x_0)}{x-x_0} =
    L
  \end{equation}
  where $L$ is a real number. Let be $\epsilon > 0$. We have to prove
  that there exists a $\delta > 0$ such that $|x-x_0| < \delta
  \Longrightarrow |f(x)-f(x_0)| < \epsilon$.

  Since $f$ is supposed to be differentiable at $x_0$, by
  \eqref{eq:10.1.3a} we know that there exists a $\alpha > 0$ such
  that
  $|x - x_0| < \alpha \Longrightarrow \left| \frac{f(x)-f(x_0)}{x-x_0}
    - L \right| < \epsilon$.

  In other words (this is Proposition 10.1.7),
  \begin{equation}
    \label{eq:10.1.3b}
    \exists \alpha > 0, \, |x - x_0| < \alpha \Longrightarrow |f(x) -
    f(x_0) - L(x-x_0)| < \epsilon |x-x_0|.
  \end{equation}
  Thus, by triangular inequality, we have
  \begin{equation}
    \label{eq:10.1.3c}
    \exists \alpha > 0, \, |x-x_0| < \alpha \Longrightarrow |f(x)-f(x_0)| < |x-x_0| (|L| + \epsilon)
  \end{equation}

  Now, let be $\delta := \min(\alpha, \frac{\epsilon}{|L| +
    \epsilon})$. If $|x-x_0| < \delta$, we have $|f(x) - f(x_0)| <
  \epsilon$ as expected. This closes the proof.
\end{exo}

\bigskip
\begin{exo}{10.1.4}{Prove Theorem 10.1.13.}

  Let's prove the different statements of this theorem.

  \begin{enumerate}[label=(\alph*)]
  \item If $f(x) = c$ for all $x \in \rr$, then at any point $x_0 \in
    \rr$, the quotient $\frac{f(x) - f(x_0)}{x - x_0}$ is equal to $0$.
    Thus, we have in particular $\lim_{x \to x_0} \frac{f(x) -
      f(x_0)}{x - x_0} = \lim_{x \to x_0} 0 = 0$. This means that
    $f'(x_0) = 0$ for all $x_0 \in \rr$, as expected.
  \item Similarly, if $f(x) = x$ for all $x \in \rr$, then at any
    point $x_0 \in \rr$, the quotient $\frac{f(x) - f(x_0)}{x - x_0}$
    is equal to $1$. Thus, the same argument leads to $f'(x_0) = 1$
    for all $x_0 \in \rr$.
  \item We have:
    \begin{align*}
      \frac{(f+g)(x) - (f+g)(x_0)}{x - x_0} &= \frac{f(x) + g(x) -
                                              f(x_0) - g(x_0)}{x -
                                              x_0}  \\
                                            &= \frac{f(x) - f(x_0)}{x
                                              - x_0} + \frac{g(x) -
                                              g(x_0)}{x - x_0}
    \end{align*}
    and thus, in particular, since both terms of the right-hand side
    converge by hypothesis, we have by Proposition 9.3.14:
    \begin{align*}
      \lim_{x \to x_0} \frac{(f+g)(x) - (f+g)(x_0)}{x - x_0}
      &= \lim_{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0} + \lim_{x \to
        x_0} \frac{g(x) - g(x_0)}{x - x_0} \\
      &= f'(x_0) + g'(x_0)
    \end{align*}
    as expected.
  \item We have:
    \begin{align*}
      \frac{(fg)(x) - (fg)(x_0)}{x - x_0}
      &= \frac{f(x)g(x) - f(x_0)g(x_0)}{x-x_0} \\
      &= \frac{f(x)g(x) - f(x_0)g(x) + f(x_0)g(x) -
        f(x_0)g(x_0)}{x-x_0} \\
      &= g(x)\frac{f(x) - f(x_0)}{x-x_0} + f(x_0) \frac{g(x)-g(x_0)}{x-x_0}
    \end{align*}
    and since $f,g$ are differentiable (and thus continuous) by
    hypothesis, we have by Proposition 9.3.14
    \begin{align*}
      \lim_{x \to x_0} \frac{(fg)(x) - (fg)(x_0)}{x - x_0}
      &= \lim_{x \to x_0} \left(g(x)\frac{f(x) - f(x_0)}{x-x_0} +
        f(x_0) \frac{g(x)-g(x_0)}{x-x_0} \right) \\
      &= \lim_{x\to x_0} \left(g(x)\frac{f(x) - f(x_0)}{x-x_0}\right)
        + \left( f(x_0) \frac{g(x)-g(x_0)}{x-x_0} \right) \\
      &= g(x_0) f'(x_0) + f(x_0) + g'(x_0)
    \end{align*}
    as expected.
  \item Obvious using limit laws and/or Proposition 9.3.14.
  \item Obvious by combining (c) and (e), setting $c := - 1$.
  \item We have:
    \begin{equation*}
      \frac{1/g(x) - 1/g(x_0)}{x-x_0}
      = \frac{g(x_0) - g(x)}{g(x)g(x_0)(x-x_0)}
      = \frac{1}{g(x)g(x_0)} \times \frac{g(x_0) - g(x)}{x-x_0}
    \end{equation*}
    Since $g$ is differentiable (and thus continuous), we have
    $\lim_{x \to x_0} \frac{1}{g(x) g(x_0)} = \frac{1}{g^2(x_0)}$; and
    we also have $\lim_{x \to x_0} \frac{g(x) - g(x_0)}{x-x_0} =
    g'(x_0)$. Thus, since both terms converge, we can apply
    Proposition 9.3.14 to get:
    \begin{align*}
      \lim_{x \to x_0} \frac{1/g(x) - 1/g(x_0)}{x-x_0}
      &= \lim_{x \to x_0} \left( \frac{1}{g(x)g(x_0)} \times
        \frac{g(x_0) - g(x)}{x-x_0}\right) \\
      &= \lim_{x \to x_0} \frac{1}{g(x)g(x_0)} \times \lim_{x \to x_0}
        \frac{g(x_0) - g(x)}{x-x_0} \\
      &= \frac{-g'(x_0)}{g^2(x_0)}
    \end{align*}
    as expected.
  \item Obvious by combining (g) and (d).
  \end{enumerate}
\end{exo}

\begin{exo}{10.1.5}{Let $n$ be a natural number, and let
    $f : \rr \to \rr$ be the function $f (x) := x^n$. Show that $f$ is
    differentiable on $\rr$ and $f'(x) = nx^{n-1}$ for all
    $x \in \rr$.}

  Let's use induction on $n$.
  \begin{itemize}
  \item The case $n=0$ corresponds to the constant function $f(x) =
    1$; see Exercise 10.1.4(a).
  \item We really start at $n=1$; in this case we have $f(x) = x$. We
    have shown in Exercise 10.1.4(b) that $f'(x) = 1 = 1 \times x^0$,
    as expected.
  \item Now suppose inductively that the property is true for some
    natural number $n \in \nn$, and let's show that it is still true
    for $n+1$. If we set $f(x) := x^{n+1}$, we can write $f(x) = x
    \times x^n$. By the induction hypothesis, $x \to x^n$ is
    differentiable on $\rr$; and we know that the identity function $x
    \to x$ is also differentiable on $\rr$. Thus $f$ is differentiable
    on $\rr$, and we can use the product rule:
    \begin{equation*}
      f'(x) = 1 \times x^n + x \times nx^{n-1} = (n+1)x^n
    \end{equation*}
    as expected. This closes the proof.
  \end{itemize}
\end{exo}

\begin{exo}{10.1.6}{Let $n$ be a negative integer, and let $f : \rr -
    \{0\} \to \rr$ be the function $f(x) := x^n$. Show that $f$ is
    differentiable on $\rr$ and $f'(x) = nx^{n-1}$ for all $x \in \rr
    - \{0\}$.}

  Here, we suppose that $n < 0$. Thus, if we set $m := -n$, then $m$
  is a positive integer, and we have $f(x) = 1/x^m$ by Definition
  5.6.2.

  We know that $x \to x^m$ is differentiable on $\rr$, and thus on
  $\rr - \{0\}$. By Theorem 10.1.13(g), the function $x \to 1/x^m$ is
  differentiable on $\rr - \{0\}$ and we have:
  \begin{equation*}
    f'(x) = \left( 1/x^m \right)' = - \frac{mx^{m-1}}{x^{2m}} = -m x^{-m-1} = nx^{n-1},
  \end{equation*}
  (using also Exercise 10.1.5,) as expected.
\end{exo}
\bigskip

\begin{exo}{10.2.1}{Prove Proposition 10.2.6.}

  We will prove the proposition for the case of a local maximum; the
  proof is similar for a local minimum. First, if $f$ attains a local
  maximum at $x_0$, there exists a $\delta > 0$ such that:
  \begin{equation}
    \label{eq:10.2.1a}
    \forall x \in ]a,b[ \, \cap \, ]x_0 - \delta, x_0 + \delta[, \; f(x_0) \geq f(x)
  \end{equation}

  Now, recall $f$ is differentiable at $x_0$, so that we have
  $f'(x_0) = \lim_{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0}$. Since
  this limit does exist, the left limit and the right limit must match
  (if they don't, a quick proof by contradiction would show that $f$
  is not differentiable at $x_0$); i.e. we must have:
  \begin{equation}
    \label{eq:10.2.1b}
    \lim_{x \to x_0; \, x \in ]x_0 - \delta, x_0[} \frac{f(x) -
      f(x_0)}{x - x_0} = \lim_{x \to x_0; \, x \in ]x_0, x_0 + \delta[} \frac{f(x) -
      f(x_0)}{x - x_0} = f'(x_0)
  \end{equation}

  In both cases, we have $f(x) \leq f(x_0)$ since $x_0$ is a local
  maximum, so that the numerator is negative. But in the case of the
  left limit, we have $x-x_0 \leq 0$, so that
  \begin{equation}
    f'(x_0) = \lim_{x \to x_0; \, x \in ]x_0 - \delta, x_0[}
    \frac{f(x) - f(x_0)}{x - x_0} \geq 0
  \end{equation}
  (taking the limit of a positive quantity leads to a positive limit),
  and similarly, for the right limit, we have
  \begin{equation}
    f'(x_0) = \lim_{x \to x_0; \, x \in ]x_0, x_0 + \delta[}
    \frac{f(x) - f(x_0)}{x - x_0} \leq 0
  \end{equation}

  But since left and right limits are equal, the only possibility is
  that they are both equal to zero, so that the limit $f'(x_0)$ itself
  is equal to zero. Thus, we have indeed $f'(x_0) = 0$, as expected.
\end{exo}

\bigskip
\begin{exo}{10.2.2}{Give an example of a function
    $f : ]-1, 1[ \to \rr$ which is continuous and attains a global
    maximum at $0$, but which is not differentiable at $0$. Explain
    why this does not contradict Proposition 10.2.6.}

  The function $f$ defined by $f(x) = x+1$ if $x \in ]-1, 0]$ and
  $f(x) = -x+1$ if $x \in ]0, 1[$ attains a global maximum of $1$ at
  $x=0$, but is not differentiable at $0$ (since the left limit
  $\lim_{x \to 0^-} \frac{f(x)-f(0)}{x-0}$ is equal to $1$ whereas the
  right limit $\lim_{x \to 0^+} \frac{f(x)-f(0)}{x-0}$ is equal to
  $-1$).

  This does not contradict Proposition 10.2.6 because this proposition
  only deals with functions that are supposed to be differentiable.
\end{exo}
\bigskip

\begin{exo}{10.2.3}{Give an example of a function
    $f : ]-1, 1[ \to \rr$ which is differentiable, and whose
    derivative equals $0$ at $0$, but such that $0$ is neither a local
    minimum nor a local maximum. Explain why this does not contradict
    Proposition 10.2.6.}

  The function $f$ defined by $f(x) := x^3$ is an example of such a
  function. Indeed, by Exercise 10.1.5, $f$ is differentiable and we
  have $f'(x) = 3x^2$; so that $f'(0) = 0$. However, $f$ is increasing
  on $]0, 1[$ (see Lemma 5.6.9(d)); and $f$ is also increasing on
  $]-1,0]$ because if we have $x < y \leq 0$, then we have $x^2 > y^2
  \geq 0$, and thus $x^3 < y^3 \leq 0$. Thus, $f$ is increasing on the
  whole interval $]-1,1[$, so that $0$ cannot be a local extremum.

  This does not contradict Proposition 10.2.6 because this proposition
  only says that \emph{if $f$ attains a local extremum at $x_0$, then
    $f'(x_0) = 0$}; it does not say that ``if $f'(x_0) = 0$, then $f$
  attains a local extremum at $x_0$''.
\end{exo}
\bigskip

\begin{exo}{10.2.4}{Prove Theorem 10.2.7.}
  
  We suppose that $g : [a, b] \to \rr$ is a continuous function,
  differentiable on $]a, b[$, and such that $g(a) = g(b)$. We must
  show that there exists an $x \in ]a, b[$ such that $g'(x) = 0$.

  Intuitively, if $g(a) = g(b)$, either $f$ is totally ``flat'' (i.e.,
  constant), or $f$ is not constant and must be increasing and then
  decreasing (or decreasing and then increasing) somewhere to go back
  back to its starting point. Let's consider those cases separately.

  \begin{itemize}
  \item If $g$ is constant, then $g'(x) = 0$ for all $x \in ]a,b[$
    (see Theorem 10.1.13(a)). Thus the claim is trivial: any $x \in
    ]a,b[$ is a good pick.
  \item If $g$ is not constant on $[a,b]$, then there exists a $x_0
    \in ]a,b[$ such that $x_0 \neq g(a)$ (and also $x_0 \neq g(b)$).
    Since $g$ is continuous on $[a,b]$, then by the maximum principle
    (Proposition 9.6.7), there exists a $x_{max} \in [a,b]$ and a
    $x_{min} \in [a,b]$ that are respectively the global maximum and
    minimum of $g$ on $[a,b]$. Once again, there are several
    (sub-)cases:
    \begin{itemize}
    \item If $x_{max} \in ]a,b[$, then by Proposition 10.2.6, we have
      $g'(x_{max}) = 0$: the claim follows.
    \item If $x_{max} = a$, then $g$ attains a local maximum at $x=a$
      (and thus also at $x=b$). Since $g$ is supposed to be
      non-constant, we have $x_{max} \neq x_{min}$. In particular, we
      thus have $x_{min} \neq a$ and $x_{min} \neq b$, i.e. $x_{min}
      \in ]a,b[$. Using Proposition 10.2.6, the claim follows.
    \end{itemize}
  \end{itemize}
\end{exo}

\begin{exo}{10.2.5}{Use Theorem 10.2.7 to prove Corollary 10.2.9.
    (Hint: consider a function of the form $f (x) - cx$ for some
    carefully chosen real number $c$.)}

  Our goal here is to choose the number $c$ so that the function
  $g : [a,b] \to \rr$ defined by $g(x) := f(x) - cx$ will obey to the
  requirements of Rolle's theorem. Of course, since $f$ is continuous
  on $[a,b]$ and differentiable on $]a,b[$, $g$ is also continuous and
  differentiable on the same intervals. Thus, we only have to choose
  $c$ so that we have $g(a) = g(b)$.

  We have respectively $g(a) = f(a) - ca$, and $g(b) = f(b) - c(b)$,
  so that $g(a) = g(b)$ iff $c = (f(b) - f(a)) / (b-a)$. Thus, let's
  define the function $g$ by $g(x) := f(x) - \frac{f(b)-f(a)}{b-a}x$.
  We can apply Rolle's theorem to this function $g$, i.e., we know
  that there exists $x_0 \in ]a,b[$ such that $g'(x_0) = 0$.

  But we have $g'(x) = f'(x) - \frac{f(b)-f(a)}{b-a}$. Thus, for this
  number $x_0$, we have actually $f'(x_0) = \frac{f(b)-f(a)}{b-a}$, as
  expected.
\end{exo}

\bigskip
\begin{exo}{10.2.6}{Let $M > 0$, and let $f : [a, b] \to \rr$ be a
    function which is continuous on $[a, b]$ and differentiable on
    $]a, b[$, and such that $|f'(x)| \leq M$ for all $x \in ]a, b[$.
    Show that for any $x, y \in [a, b]$, we have the inequality
    $|f(x) - f(y)| \leq M |x - y|$.}

  The proposition is obvious when $x = y$ since both sides of the
  inequality are equal to $0$; so that we can suppose that we have
  $a \leq x < y \leq b$ (if $y > x$, we just have to switch their
  roles in the arguments below).

  Since $f$ is continuous on $[a,b]$ and differentiable on $]a,b[$,
  then in particular its restriction $f|_{[x,y]}$ is continuous on
  $[x,y]$ and differentiable on $]x,y[$. We can thus apply the mean
  value theorem to this restriction $f|_{[x,y]}$; it tells us that
  there exists a real number $c \in ]x,y[$ such that $f'(c) =
  \frac{f(x)-f(y)}{x-y}$. But since $f'$ is bounded by $M$, we have
  $|f'(c)| \leq M$, i.e. $|f(x) - f(y)| \leq M|x-y|$, as expected.
\end{exo}
\bigskip

\begin{exo}{10.2.7}{Let $f : \rr \to \rr$ be a differentiable function
    such that $f'$ is bounded. Show that $f$ is uniformly continuous.}

  First, saying that $f'$ is bounded means that there exists a real
  number $M>0$ such that $|f'(x)| \leq M$ for all $x \in \rr$. Since
  $f'$is bounded, then from the previous exercise (10.2.6) we know
  that we have $|f(x) - f(y)| \leq M |x-y|$ for all $x,y \in \rr$.

  Now let be $\epsilon > 0$. If we set $\delta := \epsilon/M$, then
  for all $x,y \in \rr$ such that $|x-y| \leq \delta$, we have
  \[ |f(x)-f(y)| \leq M|x-y| \leq \epsilon\]
  so that $f$ is uniformly continuous, as expected.
\end{exo}

\bigskip
\begin{exo}{10.3.1}{Prove Proposition 10.3.1.}

  Let $f : X \to \rr$ be a function which is differentiable at $x_0
  \in X$. First suppose that $f$ is monotone increasing, and let's
  show that we have $f'(x_0) \geq 0$.

  Since $f$ is differentiable at $x_0$, then we have
  \[\lim_{x \to x_0 ; x \in X -\{x_0\}} \frac{f(x)-f(x_0)}{x-x_0} =
    f'(x_0)\] But $f$ is monotone increasing, so that
  $\frac{f(x)-f(x_0)}{x-x_0}$ is always a non-negative quantity (if
  $x<x_0$ then $f(x) \leq f(x_0)$; and if $x>x_0$ then
  $f(x) \geq f(x_0)$). Thus, since the limit of a non-negative
  quantity cannot be negative, we have $f'(x_0) \geq 0$, as expected.

  A similar argument show that if $f$ is monotone decreasing, then
  $f'(x_0) \leq 0$.
\end{exo}
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
