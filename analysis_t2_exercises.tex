\documentclass[11pt]{article}
\title{Propositions of solutions for \textit{Analysis II} by Terence Tao}
\author{Frédéric Santos}
% General packages:
\usepackage{a4wide}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc}
\usepackage{titlesec}
\titlelabel{\thetitle.\quad}
\usepackage{enumitem}
% Fonts and math packages:
\usepackage{lmodern}
\usepackage{amsmath}
\numberwithin{equation}{section}
\usepackage[matha,mathb]{mathabx}
\usepackage{mbboard}
\usepackage{stmaryrd}
\usepackage{hyperref}
% Macros:
\newcommand{\successor}[1]{#1 \! +\!\!\!+}
\newcommand{\aval}[1]{\left\lvert #1 \right\rvert}
\newcommand{\intset}[2]{\llbracket #1, #2 \rrbracket}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\rr}{\mathbb{R}}
\newcommand{\partsof}[1]{\mathcal{P}\left( #1 \right)}
\newcommand{\minus}{\, \textrm{---}\!\textrm{--} \:}
\newcommand{\quot}{\, \textrm{/}\!\textrm{/} \:}
\newcommand{\nn}{\mathbb{N}}
\newcommand{\zz}{\mathbb{Z}}
\newcommand{\qq}{\mathbb{Q}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\formallimit}[1]{\text{LIM}_{n \to \infty} #1}
\newcommand{\seq}[2]{(#1)_{n=#2}^\infty}
\newcommand{\limit}[1]{\text{lim}_{n \to \infty} #1}
\newcommand{\extrr}{\overline{\rr}}
\newcommand{\adh}[1]{\overline{#1}}
\newcommand{\liminfp}[2]{\inf (#1^+_N)_{N=#2}^{\infty}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\renewcommand{\P}{\mathbf{P}}
\newcommand{\Q}{\mathbf{Q}}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\infint}[2]{\underline{\int}_{#2} \, #1}
\newcommand{\supint}[2]{\overline{\int}_{#2} \, #1}
\newcommand{\ddisc}{d_{\text{disc}}}
\newcommand{\inter}{\text{int}}
\newcommand{\ext}{\text{ext}}
% Lemmas:
\usepackage{amsthm}
\newtheorem*{lem}{Lemma}
\newtheorem*{theorem}{Theorem}
% Environment:
\newenvironment{exo}[2]{\noindent \textsc{Exercise #1}. ---
  \textit{#2} \vspace{3mm}}

%%%%%%%%%%%%%%
%%% Begin doc:
\begin{document}
\maketitle
\tableofcontents

\vskip 15mm

\noindent \textbf{Remarks.} The numbering of the Exercises follows the
fourth edition of \textit{Analysis II}. In order to make the
references to \textit{Analysis I} easier, we consider that we begin
with Chapter 12 here, as in earlier editions of the textbook. Thus, in
particular, a reference to ``Exercise 4.3.3'' (for instance) will
always mean ``Exercise 4.3.3 from \textit{Analysis I}''.

\pagebreak
\setcounter{section}{11}
\section{Metric spaces}
\label{sec:metric-spaces}
\begin{exo}{12.1.1}{Prove Lemma 12.1.1}

  Consider the sequence $\seq{a_n}{m}$ defined by
  $a_n := d(x_n, x) = |x_n - x|$ for all $n \geq m$. We have to prove
  that $\lim_{n \to \infty} a_n = 0$ if and only if
  $\lim_{n \to \infty} x_n = x$.

  \begin{itemize}
  \item Let be $\epsilon > 0$. If $\lim_{n \to \infty} a_n = 0$, then
    there exists an $N \geq m$ such that $|a_n| < \epsilon$ whenever
    $n \geq N$. Thus, there exists an $N \geq m$ such that
    $|x_n - x| < \epsilon$ whenever $n \geq N$, which means that
    $\lim_{n \to \infty} x_n = x$.
  \item Let be $\epsilon > 0$. Conversely, if $\lim_{n \to \infty} x_n
    = x$, then there exists an $N \geq m$ such that $|x_n - x| <
    \epsilon$ whenever $n \geq N$. But since $|a_n| := |x_n - x|$, it
    means that $\lim_{n \to \infty} a_n = 0$, as expected.
  \end{itemize}
\end{exo}

\begin{exo}{12.1.2}{Show that the real line with the metric $d(x, y) :=
    |x-y|$ is indeed a metric space.}

  Using Proposition 4.3.3, this claim is obvious. All claims (a)--(d)
  of Definition 12.1.2 are satisfied because:
  \begin{enumerate}[label=(\alph*)]
  \item comes from Proposition 4.3.3(e)
  \item also comes from Proposition 4.3.3(e)
  \item comes from Proposition 4.3.3(f)
  \item comes from Proposition 4.3.3(g).
  \end{enumerate}
\end{exo}

\begin{exo}{12.1.3}{Let $X$ be a set, and let
    $d : X \times X \to [0, \infty)$ be a function. With respect to
    Definition 12.1.2, give an example of a pair $(X,d)$ which...
    \vskip -4mm}
  
  \begin{enumerate}[label=(\alph*)]
  \item obeys the axioms (bcd) but not (a).

    Consider $X = \rr$, and $d$ defined by $d(x,x) = 1$ and $d(x,y) =
    5$ for all $x \neq y \in \rr$.
  \item obeys the axioms (acd) but not (b).

    Consider $X = \rr$, and $d$ defined by $d(x,y) = 0$ for all $x, y
    \in \rr$.
  \item obeys the axioms (abd) but not (c).

    Consider $X = \rr$, and $d$ defined by $d(x,y) = \max(x-y,0)$ for
    all $x,y \in \rr$.
  \item obeys the axioms (abc) but not (d).

    Consider the finite set $X := \{1,2,3\}$ and the application $d$
    defined by $d(1,2) = d(2,1) = d(2,3) = d(3,2) := 1$, and
    $d(1,3) = d(3,1) := 5$, and $d(x,x) = 0$ for all $x \in X$.
  \end{enumerate}  
\end{exo}

\begin{exo}{12.1.4}{Show that the pair $(Y, d|_{Y \times Y})$ deﬁned
    in Example 12.1.5 is indeed a metric space.}

  By definition, since $Y \subseteq X$, we have $x,y \in X$ whenever
  $x,y \in Y$. And furthermore, since $d|_{Y \times Y}(x,y) :=
  d(x,y)$, then the application $d|_{Y \times Y}$ obeys all four
  statements (a)--(d) of Definition 12.1.2. Thus, $(Y, d|_{Y \times
    Y})$ is indeed a metric space.
\end{exo}

\begin{exo}{12.1.5}{Let $n \geq 1$, and let $a_1, a_2, \ldots, a_n$
    and $b_1, b_2, \ldots, b_n$ be real numbers. Verify the identity
    $\left(\sum_{i=1}^n a_i b_i\right)^2 + \frac{1}{2} \sum_{i=1}^{n}
    \sum_{j=1}^{n} (a_i b_j - a_j b_i)^2 = \sum_{i=1}^{n} a_i^2
    \sum_{j=1}^{n} b_j^2$, and conclude the Cauchy-Schwarz inequality.
    Then use the Cauchy-Schwarz inequality to prove the triangle
    inequality.}

  Let's prove these three statements.

  \begin{enumerate}[label=(\roman*)]
  \item To prove the first identity, let's use induction on $n$.

    The base case $n=1$ is obvious: on the left-hand side, we just get
    $(a_1 b_1)^2$, and on the right-hand side, we get $a_1^2 b_1^2$,
    hence the statement.

    Now let's suppose inductively that this identity is true for a
    given positive integer $n \geq 1$, and let's prove that it is
    still true for $n+1$. We have to prove that
    \begin{equation}
      \label{eq:12.1.5a}
      \underbrace{\left(\sum_{i=1}^{n+1} a_i b_i\right)^2}_{:=A} +
      \underbrace{\frac{1}{2} \sum_{i=1}^{n+1} \sum_{j=1}^{n+1} (a_i
        b_j - a_j b_i)^2}_{:= B}
      = \underbrace{\left(\sum_{i=1}^{n+1} a_i^2\right)
        \left(\sum_{j=1}^{n+1} b_j^2\right)}_{:=C}
    \end{equation}
    where we gave a name to each part of the identity for an easier
    computation below. Indeed,
    \begin{itemize}
    \item for $A$, we have
      \begin{align*}
        A &:= \left(\sum_{i=1}^{n+1} a_i b_i\right)^2 \\
          &= \left(a_{n+1} b_{n+1} + \sum_{i=1}^{n} a_i b_i\right)^2
        \\
          &= (a_{n+1} b_{n+1})^2 + \left(\sum_{i=1}^{n} a_i
            b_i\right)^2 + 2 (a_{n+1} b_{n+1}) \sum_{i=1}^{n} a_i b_i
      \end{align*}
      
    \item for $B$, we have
      \begin{align*}
        B &:= \frac{1}{2} \sum_{i=1}^{n+1} \sum_{j=1}^{n+1} (a_i
            b_j - a_j b_i)^2 \\
          &= \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n+1} (a_i b_j -
            a_j b_i)^2 + \frac{1}{2} \sum_{j=1}^{n+1} (a_{n+1} b_j -
            a_j b_{n+1})^2\\
          &= \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} (a_i b_j - a_j
            b_i)^2 +
            \underbrace{\frac{1}{2} \sum_{i=1}^{n} (a_i b_{n+1} -
            a_{n+1} b_i)^2}_{:= 1/2 \times S} +
            \underbrace{\frac{1}{2} \sum_{j=1}^{n} (a_{n+1} b_{j} - a_{j}
            b_{n+1})^2}_{:= 1/2 \times S} \\
          &\quad + \underbrace{\frac{1}{2} (a_{n+1}b_{n+1} -
            b_{n+1}a_{n+1})^2}_{=0} \\
          &= \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} (a_i b_j - a_j
            b_i)^2 + \sum_{k=1}^{n} (a_kb_{n+1} -
            a_{n+1}b_k)^2
      \end{align*}
      
    \item and thus, for $A + B$, we now use the induction hypothesis (IH)
      to get:
      \begin{align*}
        A + B
        &:= (a_{n+1} b_{n+1})^2 + \left(\sum_{i=1}^{n} a_i
          b_i\right)^2 +
          2 (a_{n+1} b_{n+1}) \sum_{i=1}^{n} a_i b_i\\
        &\quad + \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} (a_i b_j - a_j
          b_i)^2 + \sum_{k=1}^{n} (a_kb_{n+1} - a_{n+1}b_k)^2\\
        &= \underbrace{\left(\sum_{i=1}^{n} a_i b_i\right)^2 +
          \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} (a_i b_j - a_j
          b_i)^2}_{\text{apply (IH) here}} \\
        &\quad + (a_{n+1} b_{n+1})^2 +
          2 (a_{n+1} b_{n+1}) \sum_{i=1}^{n} a_i b_i
          + \sum_{k=1}^{n} (a_kb_{n+1} - a_{n+1}b_k)^2\\
        &= \left(\sum_{i=1}^{n} a_i^2\right) \left(\sum_{j=1}^{n}
          b_j^2\right)\\
        &\quad + (a_{n+1} b_{n+1})^2 +
          2 (a_{n+1} b_{n+1}) \sum_{i=1}^{n} a_i b_i
          + \sum_{k=1}^{n} (a_kb_{n+1} - a_{n+1}b_k)^2\\
        &= \left(\sum_{i=1}^{n} a_i^2\right) \left(\sum_{j=1}^{n}
          b_j^2\right) + (a_{n+1} b_{n+1})^2\\
        &\quad + 2 \sum_{i=1}^{n} a_i a_{n+1} b_i b_{n+1} +
          \sum_{i=1}^{n}(a_i^2 b_{n+1}^2 - 2a_ib_{n+1}a_{n+1}b_i + a_{n+1}^2b_i^2)\\
        &= \left(\sum_{i=1}^{n} a_i^2\right) \left(\sum_{j=1}^{n}
          b_j^2\right) + \sum_{i=1}^{n}(a_i^2 b_{n+1}^2 + a_{n+1}^2
          b_i^2) \\
        &= \left(\sum_{i=1}^{n+1} a_i^2\right) \left(\sum_{j=1}^{n+1}
          b_j^2\right) \\
        &= C
      \end{align*}
      so that the identity is indeed true for all natural number $n$.
    \end{itemize}
    
  \item We can use this identity to prove the Cauchy-Schwarz identity,
    \begin{equation}
      \label{eq:12.1.5b}
      \left| \sum_{i=1}^{n} a_i b_i\right| \leq \left( \sum_{i=1}^{n}
        a_i^2 \right)^{1/2} \left( \sum_{i=1}^{n}
        b_i^2 \right)^{1/2}.
    \end{equation}

    Indeed, since $B \geq 0$ in the identity \eqref{eq:12.1.5a}, we
    have
    \[\left(\sum_{i=1}^{n} a_i b_i\right)^2 \leq \left(\sum_{i=1}^{n} a_i^2\right)
      \left(\sum_{j=1}^{n} b_j^2\right)\]
    and thus, taking the square root on both sides, we get
    \eqref{eq:12.1.5b}, as expected.
    
  \item Finally, we can use the Cauchy-Schwarz inequality to prove the
    triangle inequality.

    We have
    \begin{align*}
      \sum_{i=1}^{n} (a_i^2 + b_i^2)
      &= \sum_{i=1}^{n} a_i^2 + \sum_{i=1}^{n} b_i^2 + 2
        \sum_{i=1}^{n} a_i b_i
      &\\
      &\leq \sum_{i=1}^{n} a_i^2 + \sum_{i=1}^{n} b_i^2 + 2
        \left(\sum_{i=1}^{n} a_i^2\right)^{1/2} \left(\sum_{i=1}^{n}
        b_i^2\right)^{1/2}
      &\text{ (by eq. \eqref{eq:12.1.5b})}\\
      &\leq \left( \left( \sum_{i=1}^{n} a_i^2 \right)^{1/2}
        + \left( \sum_{i=1}^{n} b_i^2 \right)^{1/2}\right)^2&
    \end{align*}
    and, since everything is positive, we get the triangle inequality
    by taking square roots on both sides.
  \end{enumerate}  
\end{exo}

\begin{exo}{12.1.6}{Show that $(\rr^n , d_{l^2}$) in Example 12.1.6 is
    indeed a metric space.}

  We have to show the four axioms of Definition 12.1.2.

  \begin{enumerate}[label=(\alph*)]
  \item For all $x \in \rr^n$, we have
    $d_{l^2}(x,x) = \sqrt{\sum_{i=1}^{n} (x_i - x_i)^2} = 0$, as expected.
  \item Positivity: for all $x \neq y \in \rr^n$, there exists at
    least one $1 \leq i \leq n$ such that $x_i \neq y_i$, so that
    $(x_i-y_i)^2 > 0$, and
    $d_{l^2}(x,y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2} > 0$, as
    expected.
  \item Symmetry: for all $x,y \in \rr^n$, we have
    \[d_{l^2}(y,x) = \sqrt{\sum_{i=1}^{n} (y_i - x_i)^2} =
      \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2} = d_{l^2}(x,y)\] as expected.
  \item Triangle inequality: for all $x,y,z \in \rr^n$, we have
    \begin{align*}
      d_{l^2}(x,z)
      &:= \left(\sum_{i=1}^{n} (x_i - z_i)^2\right)^{1/2} &\\
      &= \left(\sum_{i=1}^{n} (a_i + b_i)^2\right)^{1/2}
      &\text{with $a_i := x_i-y_i$ and $b_i := y_i-z_i$}\\
      &\leq \left(\sum_{i=1}^{n} a_i^2\right)^{1/2} +
        \left(\sum_{i=1}^{n} b_i^2\right)^{1/2}
      &\text{(Exercise 12.1.5(iii))}\\
      &\leq \left(\sum_{i=1}^{n} (x_i - y_i)^2\right)^{1/2} +
        \left(\sum_{i=1}^{n} (y_i-z_i)^2\right)^{1/2}& \\
      &\leq d_{l^2}(x,y) + d_{l^2}(y,z)&
    \end{align*}
    as expected.
  \end{enumerate}
  Thus, $(\rr^n, d_{l^2})$ is indeed a metric space.
\end{exo}

\pagebreak
\begin{exo}{12.1.7}{Show that $(\rr^n , d_{l^1}$) in Example 12.1.7 is
    indeed a metric space.}

  Once again, let's show the four axioms of Definition 12.1.2.

  \begin{enumerate}[label=(\alph*)]
  \item For all $x \in \rr^n$, we have
    $d_{l^1}(x,x) = \sum_{i=1}^{n} |x_i - x_i| = 0$, as expected.
  \item Positivity: for all $x \neq y \in \rr^n$, there exists at
    least one $1 \leq i \leq n$ such that $x_i \neq y_i$, so that
    $|x_i-y_i| > 0$, and
    $d_{l^1}(x,y) = \sum_{i=1}^{n} |x_i - y_i| > 0$, as
    expected.
  \item Symmetry: for all $x,y \in \rr^n$, we have
    \[d_{l^1}(y,x) = \sum_{i=1}^{n} |y_i - x_i| =
      \sum_{i=1}^{n} |x_i - y_i| = d_{l^1}(x,y)\]
    as expected.
  \item Triangle inequality: we already know from Proposition 4.3.3(g)
    (generalized to real numbers) that we have the triangle inequality
    $|a-c| \leq |a-b| + |b-c|$ for all $a,b,c \in \rr$. Thus, for all
    $x,y,z \in \rr^n$, we have
    \begin{equation*}
      d_{l^1}(x,z) := \sum_{i=1}^{n} |x_i - z_i| \leq \sum_{i=1}^{n}
      (|x_i - y_i| + |y_i - z_i|) =: d_{l^1}(x,y) + d_{l^1}(y,z)
    \end{equation*}
    as expected.
  \end{enumerate}
  Thus, $(\rr^n, d_{l^1})$ is indeed a metric space.
\end{exo}

\bigskip
\begin{exo}{12.1.8}{Prove the two inequalities in equation (12.1).}

  We have to prove that for all $x,y \in \rr^n$, we have
  \begin{equation}
    \label{eq:12.1.8goal}
    d_{l^2}(x,y) \leq d_{l^1}(x,y) \leq \sqrt{n} \, d_{l^2}(x,y)
  \end{equation}

  \begin{itemize}
  \item The first inequality, since everything is non-negative, is
    equivalent to $d_{l^2}(x,y)^2 \leq d_{l^1}(x,y)^2$, and we will prove
    it in this form.

    Indeed, using a trivial product expansion, we have
    \begin{align*}
      d_{l_1}(x,y)^2
      &:= \left(\sum_{i=1}^{n} |x_i - y_i|\right)^2 \\
      &= \left(\sum_{i=1}^{n} |x_i - y_i|\right) \times
        \left(\sum_{i=1}^{n} |x_i - y_i|\right) \\
      &= \sum_{i=1}^{n} |x_i - y_i|^2 + \overbrace{\sum_{1 \leq i,j \leq n ; \,
        i\neq j} |x_i-y_i| \times |x_j - y_j|}^{\geq 0} \\
      &\geq \sum_{i=1}^{n} |x_i - y_i|^2 =: d_{l^2}(x,y)^2
    \end{align*}
    as expected.
  \item For the second inequality, we use the Cauchy-Schwarz
    inequality, which says that
    \begin{align*}
      d_{l^1}(x,y) &:= \sum_{i=1}^{n} |x_i - y_i|\\
      &= \left| \sum_{i=1}^{n} |x_i - y_i| \times 1 \right|\\
      &\leq \left(\sum_{i=1}^{n} |x_i - y_i|^2 \right)^{1/2}
        \left(\sum_{i=1}^{n} 1^2 \right)^{1/2} \\
      &\leq d_{l^2}(x,y) \times \sqrt{n}
    \end{align*}
    as expected.
  \end{itemize}
\end{exo}

\begin{exo}{12.1.9}{Show that the pair $(\rr^n, d_{l^\infty})$ in
    Example 12.1.9 is a metric space.}

  Once again, let's show the four axioms of Definition 12.1.2. 

  \begin{enumerate}[label=(\alph*)]
  \item For all $x \in \rr^n$, we clearly have
    $d_{l^\infty}(x,x) = \sup \{|x_i - x_i| : 1 \leq i \leq n\} = 0$,
    as expected.
  \item Positivity: for all $x \neq y \in \rr^n$, there exists at
    least one $1 \leq j \leq n$ such that $x_j \neq y_j$. Thus
    $|x_j-y_j| > 0$, and
    $d_{l^\infty}(x,y) = \sup \{|x_i - y_i| : 1 \leq i \leq n\} \geq
    |x_j - y_j| > 0$, as expected.
  \item Symmetry: for all $x,y \in \rr^n$, we have
    \[d_{l^\infty}(x, y) = \sup \{|x_i - y_i| : 1 \leq i \leq n\} =
      \sup \{|y_i - x_i| : 1 \leq i \leq n\} = d_{l^\infty}(y, x)\]
    as expected.
  \item Triangle inequality. Let be $x,y,z \in \rr^n$. We have
    $|x_i - z_i| \leq |x_i - y_i| + |y_i - z_i|$ for all
    $1 \leq i \leq n$, by Proposition 4.3.3(g). But, by definition of
    the supremum, we have $|x_i - y_i| \leq d_{l^\infty}(x,y)$
    and $|y_i - z_i| \leq d_{l^\infty}(y,z)$ for all $1 \leq i \leq
    n$. Thus, we have $|x_i - z_i| \leq d_{l^\infty}(x,y) +
    d_{l^\infty}(y,z)$ for all $1 \leq i \leq n$; i.e., $d_{l^\infty}(x,y) +
    d_{l^\infty}(y,z)$ is an upper bound of the set $\{|x_i -
    z_i| : 1 \leq i \leq n\}$. By definition of the supremum, it
    implies that
    \[d_{l^\infty}(x,z) := \sup \{|x_i - z_i| : 1 \leq i \leq n\} \leq d_{l^\infty}(x,y) +
      d_{l^\infty}(y,z)\]
    as expected.
  \end{enumerate}
  Thus, $(\rr^n, d_{l^1})$ is indeed a metric space.  
\end{exo}

\bigskip
\begin{exo}{12.1.10}{Prove the two inequalities in equation (12.2).}

  We have to prove that for all $x,y \in \rr^n$,
  \[ \frac{1}{\sqrt{n}} d_{l^2}(x,y) \leq d_{l^\infty} (x,y) \leq
    d_{l^2}(x,y).\]

  First, a preliminary remark. By definition, we have
  $d_{l^\infty}(x,y) := \sup \{|x_i - y_i| : 1 \leq i \leq n\}$ for
  all $x,y \in \rr^n$. Since this distance is defined as the supremum
  of a finite set, we know (see Chapter 8 of \textit{Analysis I}) that
  there exists a $1 \leq m \leq n$ such that
  $d_{l^\infty}(x,y) = |x_m - y_m|$ (the supremum belongs to the set).
  The index ``$m$'' will have this meaning below.

  \begin{itemize}
  \item Let's prove the first inequality.
    \begin{align*}
      \frac{1}{\sqrt{n}} d_{l^2}(x,y)
      &:= \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - y_i)^2} \\
      &\leq \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_m - y_m)^2} \\
      &\leq \sqrt{\frac{n}{n} (x_m - y_m)^2} \\
      &= |x_m - y_m| =: d_{l^\infty} (x,y)
    \end{align*}
    as expected.
  \item Now we prove the second one. We have
    \begin{align*}
      d_{l^2}(x,y) &:= \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2} \\
                   &= \sqrt{(x_m - y_m)^2 + \sum_{1 \leq i \leq n ; \, i
                     \neq m} (x_i - y_i)^2}\\
                   &\geq \sqrt{(x_m - y_m)^2} = |x_m - y_m| =: d_{l^\infty}(x,y)
    \end{align*}
    as expected.
  \end{itemize}
\end{exo}

\begin{exo}{12.1.11}{Show that the discrete metric $(X, \ddisc)$ in
    Example 12.1.11 is indeed a metric space.}

  Once again, let's show the four axioms of Definition 12.1.2. 

  \begin{enumerate}[label=(\alph*)]
  \item For all $x \in X$, we have
    $\ddisc(x,x) := 0$ by definition, so that there is nothing to
    prove here.
  \item Positivity: for all $x \neq y \in X$, we have
    $\ddisc(x,y) := 1 > 0$ by definition, so that there's still
    nothing to prove.
  \item Symmetry: for all $x,y \in X$, we have $\ddisc(x,y) =
    \ddisc(y,x) = 1$, so that $\ddisc$ obeys the symmetry property.
  \item Triangle inequality. Let be $x,y,z \in X$, and let's consider
    $\ddisc(x,z)$.
    \begin{itemize}
    \item If $x=z$, then $\ddisc(x,z) = 0$. And since $\ddisc$ is a
      non-negative application, we clearly have $0 =: \ddisc(x,z) \leq
      \ddisc(x,y) + \ddisc(y,z)$ for all $y \in X$.
    \item If $x \neq z$, then we cannot have both $x=y$ and $y=z$ (it
      would be a clear contradiction with $x \neq z$). Thus, at least
      one of the propositions ``$x \neq y$'', ``$y \neq z$'' is true.
      Another way to say that is $\ddisc(x,y) + \ddisc(y,z) \geq 1$.
      But since $\ddisc(x,z) := 1$, we have actually $\ddisc(x,y) +
      \ddisc(y,z) \geq \ddisc(x,z)$, as expected.
    \end{itemize}
  \end{enumerate}
\end{exo}

\begin{exo}{12.1.12}{Prove Proposition 12.1.18.}

  First, recall that for all $x,y \in \rr^n$, we have, from Examples
  12.1.7 and 12.1.9,
  \begin{equation*}
    \frac{1}{\sqrt{n}} \, d_{l^2} (x,y) \leq
    d_{l^\infty}(x,y) \leq d_{l^2}(x,y) \leq
    d_{l^1}(x,y) \leq \sqrt{n} \, d_{l^2}(x,y).
  \end{equation*}

  Note that $n$ is a real constant here.
  
  \begin{itemize}
  \item Let's prove that $(a) \implies (b)$. If
    $\lim_{k \to \infty} d_{l^2}(x^{(k)}, x) = 0$, then by the limit
    laws, the sequence $t_k := \sqrt{n} \, d_{l^2}(x^{(k)}, x)$ also
    converges to $0$ as $k \to \infty$, since $\sqrt{n}$ is a constant
    real number. Thus, we have
    \[d_{l^2}(x^{(k)}, x) \leq d_{l^1}(x^{(k)}, x) \leq \sqrt{n} \,
      d_{l^2}(x^{(k)}, x)\] and, by the squeeze test, this implies
    that $\lim_{k \to \infty} d_{l^1}(x^{(k)}, x)$ as expected.
  \item Let's prove that $(b) \implies (c)$. If
    $\lim_{k \to \infty} d_{l^1}(x^{(k)}, x) = 0$, then we have
    \[0 \leq d_{l^\infty}(x^{(k)}, x) \leq d_{l^1}(x^{(k)}, x)\]
    and, by the squeeze test, this implies
    that $\lim_{k \to \infty} d_{l^\infty}(x^{(k)}, x)$ as expected.
  \item Let's prove that $(c) \implies (d)$. Suppose that
    $\lim_{k \to \infty} d_{l^\infty}(x^{(k)}, x) = 0$. Then, for all
    $1 \leq j \leq n$, we have
    $0 \leq |x_j^{k} - x_j| \leq d_{l^\infty}(x^{(k)}, x)$. Still by
    the squeeze test, this implies that
    $\lim_{k \to \infty} |x_j^{k} - x_j| = 0$, i.e. that
    $(x_j^{k})_{k=m}^\infty$ converges to $x_j$ as $k \to \infty$ (by
    Lemma 12.1.1), as expected.
  \item Finally, let's prove that $(d) \implies (a)$. Using the
    definition of convergence is more appropriate here. Let be
    $\epsilon > 0$ a positive real number, and let be
    $1 \leq j \leq n$. By definition, there exists a natural number
    $N \geq m$ such that $|x_j^{(k)} - x_j| \leq \epsilon / \sqrt{n}$
    whenever $k \geq N$. Thus, if $k \geq N$, we have
    \[d_{l^2}(x^{(k)}, x) := \sqrt{\sum_{j=1}^{n} (x^{(k)}_j - x_j)^2}
      \leq \sqrt{\sum_{j=1}^{n} \frac{\epsilon^2}{n}} \leq \epsilon\]
    so that $\lim_{k \to \infty} d_{l^2}(x^{(k)}, x) = 0$, i.e.,
    $(x^{k})_{k=m}^\infty$ converges to $x$ as $k \to \infty$ in the
    $l^2$ metric (by Lemma 12.1.1), as expected.
  \end{itemize}
\end{exo}

\begin{exo}{12.1.13}{Prove Proposition 12.1.19.}

  Let be $\seq{x^{(n)}}{m}$ a sequence of elements of a set $X$.

  \begin{itemize}
  \item First suppose that $\seq{x^{(n)}}{m}$ is eventually constant.
    Thus, by definition, there exists an $N \geq m$ and an element
    $x \in X$ such that $\seq{x^{(n)}}{m} = x$ for all $n \geq N$.
    This implies that we have $\ddisc(x^{(n)}, x) = 0$ for all $n \geq
    N$. In particular, for all $\epsilon > 0$, we have
    $\ddisc(x^{(n)}, x) \leq \epsilon$ whenever $n \geq N$, so that
    $\seq{x^{(n)}}{m}$ indeed converges to $x$ with respect to
    $\ddisc$.
  \item Conversely, suppose that $\seq{x^{(n)}}{m}$ converges to $x$
    with respect to $\ddisc$. Let be $\epsilon = 1/2$. By definition,
    there exists an $N \geq m$ such that $\ddisc(x^{(n)}, x) \leq 1/2$
    whenever $n \geq N$. Since $\ddisc(x^{(n)}, x)$ cannot be $1$, it
    is necessarily equal to $0$, so that $x^{(n)} = x$ whenever
    $n \geq N$. Thus, the sequence $x^{(n)}$ is indeed eventually
    constant.
  \end{itemize}
\end{exo}

\begin{exo}{12.1.14}{Prove Proposition 12.1.20.}

  Suppose that we have $\lim_{n \to \infty} d(x^{(n)}, x) = 0$ and
  $\lim_{n \to \infty} d(x^{(n)}, x') = 0$. Suppose, for the sake
  of contradiction, that we have $x \neq x'$. Thus, the real number
  $\epsilon := \frac{d(x,x')}{3}$ is positive.

  Since $x^{(n)}$ converges to $x$, there exists a $N_1 \geq m$ such
  that $d(x^{(n)}, x) \leq \epsilon$ whenever $n \geq N_1$.

  Similarly, since $x^{(n)}$ converges to $x'$, there exists a
  $N_2 \geq m$ such that $d(x^{(n)}, x') \leq \epsilon$ whenever
  $n \geq N_2$.

  By the triangle inequality, we thus have, for all $n \geq \max(N_1,
  N_2)$,
  \[d(x, x') \leq d(x, x^{(n)}) + d(x^{(n)}, x') \leq \epsilon +
    \epsilon = \frac{2}{3}d(x,x')\]
  which is a contradiction (since $d(x,x') > 0$ by hypothesis).

  Thus, the limit is unique, and we must have $x=x'$.
\end{exo}

\bigskip
\begin{exo}{12.1.15}{Let be
    $X := \{\seq{a_n}{0} : \sum_{n=0}^{\infty} |a_n| < \infty\}$. We
    define on this space the metrics
    $d_{l^1}(\seq{a_n}{0}, \seq{b_n}{0}) := \sum_{n=0}^{\infty} |a_n -
    b_n|$, and $d_{l^\infty}(\seq{a_n}{0}, \seq{b_n}{0}) := \sup_{n \in
      \nn} |a_n - b_n|$. Then...}

  We have to prove the following statements.

  \begin{enumerate}
  \item $d_{l^1}$ is a metric on $X$.

    We have to prove the four axioms of Definition 12.1.2.

    \begin{enumerate}[label=(\alph*)]
    \item Let be $\seq{a_n}{0} \in X$. We have $d_{l^1}(\seq{a_n}{0},
      \seq{a_n}{0}) = \sum_{n=0}^{\infty} |a_n - a_n| = 0$, as
      expected.
    \item Let be $\seq{a_n}{0}, \seq{b_n}{0}$ two distinct elements of
      $X$. Since they are distinct, there exists at least one $m \in
      \nn$ such as $|a_m - b_m| > 0$. Thus, $d_{l^1}(\seq{a_n}{0},
      \seq{b_n}{0}) = \sum_{n=0}^{\infty} |a_n - b_n| \geq |a_m - b_m|
      > 0$, as expected.
    \item Symmetry: we clearly have
      \[d_{l^1}(\seq{b_n}{0}, \seq{a_n}{0}) = \sum_{n=0}^{\infty}
        |b_n - a_n| = \sum_{n=0}^{\infty} |a_n - b_n| =
        d_{l^1}(\seq{a_n}{0}, \seq{b_n}{0}).\]
    \item Finally, let's prove the triangle inequality. Let be
      $\seq{a_n}{0}, \seq{b_n}{0}, \seq{c_n}{0} \in X$. Since we have
      the triangle inequality for the usual distance $d$ on $\rr$
      (i.e., we have $|a_n - c_n| \leq |a_n - b_n| + |b_n - c_n|$ for
      all $n \in \nn$), we have immediately
      \begin{align*}
        d_{l^1}(\seq{a_n}{0}, \seq{c_n}{0})
        &:= \sum_{n=0}^{\infty} |a_n - c_n|\\
        &\leq \sum_{n=0}^{\infty} (|a_n - b_n| + |b_n - c_n|)
          \; \text{ (consequence of Prop. 7.1.11(h))}\\
        &\leq \sum_{n=0}^{\infty} |a_n - b_n| + \sum_{n=0}^{\infty}
          |b_n - c_n|
          \; \text{ (by Proposition 7.2.14(a))}\\
        &\leq d_{l^1}(\seq{a_n}{0}, \seq{b_n}{0}) +
          d_{l^1}(\seq{b_n}{0}, \seq{c_n}{0}).
      \end{align*}
    \end{enumerate}

    Thus, $d_{l^1}$ is indeed a metric on $X$.
  \item $d_{l^\infty}$ is a metric on $X$.

    Once again, we have to prove the four axioms of Definition 12.1.2.

    \begin{enumerate}[label=(\alph*)]
    \item Let be $\seq{a_n}{0} \in X$. We have
      $d_{l^\infty}(\seq{a_n}{0}, \seq{a_n}{0}) = \sup_{n \in \nn}
      |a_n - a_n| = 0$, as expected.
    \item Let be $\seq{a_n}{0}, \seq{b_n}{0}$ two distinct elements of
      $X$. Since they are distinct, there exists at least one $m \in
      \nn$ such as $|a_m - b_m| > 0$. Thus, $d_{l^\infty}(\seq{a_n}{0},
      \seq{b_n}{0}) = \sup_{n \in \nn} |a_n - b_n| \geq |a_m - b_m|
      > 0$, as expected.
    \item Symmetry: we clearly have
      \[d_{l^\infty}(\seq{b_n}{0}, \seq{a_n}{0}) = \sup_{n \in \nn}
        |b_n - a_n| = \sup_{n \in \nn} |a_n - b_n| =
        d_{l^\infty}(\seq{a_n}{0}, \seq{b_n}{0}).\]
    \item Finally, let's prove the triangle inequality. Let be
      $\seq{a_n}{0}, \seq{b_n}{0}, \seq{c_n}{0} \in X$. Since we have
      the triangle inequality for the usual distance $d$ on $\rr$
      (i.e., we have $|a_n - c_n| \leq |a_n - b_n| + |b_n - c_n|$ for
      all $n \in \nn$), we have immediately
      $|a_m - c_m| \leq \sup_{n \in \nn} |a_n - b_n| + \sup_{n \in
        \nn} |b_n - c_n|$ for all $m \in \nn$, by definition of the
      supremum. In other words,
      $(\sup_{n \in \nn} |a_n - b_n| + \sup_{n \in \nn} |b_n - c_n|)$
      is an upper bound for the set $\{|a_m - c_m| : m \in \nn\}$.
      Thus we have, still by definition of the supremum,
      $\sup_{n \in \nn} |a_n - c_n| \leq \sup_{n \in \nn} |a_n - b_n| +
      \sup_{n \in \nn} |b_n - c_n|$, as expected.
    \end{enumerate}
    Thus, $d_{l^\infty}$ is indeed a metric on $X$.
  \item There exist sequences $x^{(1)}$, $x^{(2)}$, ..., of elements
    of $X$ (i.e., sequences of sequences) which are convergent with
    respect to $d_{l^\infty}$, but are not convergent with respect to
    $d_{l^1}$.

    Here we are dealing with sequences of sequences: we have a
    sequence $(x^{(k)})_{k=1}^\infty$ where each $x^{(k)}$ is
    itself a sequence of real numbers. Thus, let's define
    $(x^{(k)})_{k=1}^\infty$ as follows:
    \[x^{(k)}_n := \left\{
        \begin{array}{ll}
          1/(k+1) & \text{ if } 0 \leq n \leq k \\
          0 & \text{ if } n > k.
        \end{array}
      \right.\]
    Just to make things clearer, we have for instance
    \begin{align*}
      x^{(1)} &:= \frac{1}{2}, \; \frac{1}{2}, \; 0, \; 0, \; 0, \; \ldots \\
      x^{(2)} &:= \frac{1}{3}, \; \frac{1}{3}, \; \frac{1}{3}, \; 0, \; 0, \; \ldots \\
      x^{(3)} &:= \frac{1}{4}, \; \frac{1}{4}, \; \frac{1}{4}, \; \frac{1}{4}, \; 0, \; \ldots
    \end{align*}
    Also, let be the null sequence $\seq{a_n}{0}$ defined by $a_n := 0$ for
    all $n \in \nn$. Thus:
    \begin{itemize}
    \item $(x^{(k)})_{k=1}^\infty$ converges to $\seq{a_n}{0}$ w.r.t.
      the metric $d_{l^\infty}$. Indeed, if we consider a given
      positive integer $k$ (fixed), we have
      \begin{equation*}
        |x^{(k)} - a_n| = |x^{(k)}| = \left\{
          \begin{array}{ll}
            1/(k+1) & \text{ if } 0 \leq n \leq k \\
            0 & \text{ if } n > k.
          \end{array}
        \right.
      \end{equation*}
      so that $d_{l^\infty}\left(\seq{x^{(k)}_n}{0},
        \seq{a_n}{0}\right) := \sup_{n \in \nn} |x^{(k)} - a_n| =
      \frac{1}{k+1}$.

      Thus,
      $\lim_{k \to \infty} d_{l^\infty}\left(\seq{x^{(k)}_n}{0},
        \seq{a_n}{0}\right) = 0$, or in other words,
      $(x^{(k)})_{k=1}^\infty$ converges to $\seq{a_n}{0}$ w.r.t. the
      metric $d_{l^\infty}$ in $X$.
      
    \item But $(x^{(k)})_{k=1}^\infty$ does not converges to
      $\seq{a_n}{0}$ w.r.t. the metric $d_{l^1}$. Indeed, we have, for
      each given (fixed) $k$,
      \begin{align*}
        d_{l^1} \left(\seq{x^{(k)}_n}{0}, \seq{a_n}{0}\right)
        = \sum_{n=0}^{k} \frac{1}{k+1} = 1
      \end{align*}
      Thus, we clearly do not have
      $\lim_{k \to \infty} d_{l^1}\left(\seq{x^{(k)}_n}{0},
        \seq{a_n}{0}\right) = 0$, i.e., $(x^{(k)})_{k=1}^\infty$ does
      not converge to $\seq{a_n}{0}$ w.r.t. the  metric $d_{l^1}$.
    \end{itemize}
  \item Conversely, any sequence which converges with respect to
    $d_{l^1}$ also converges with respect to $d_{l^\infty}$.

    Suppose, for the sake of contradiction, that
    $(x^{(k)})_{k=1}^\infty$ does not converge to $\seq{a_n}{0}$
    w.r.t. the  metric $d_{l^\infty}$, but does converge to $\seq{a_n}{0}$
    w.r.t. the  metric $d_{l^1}$.

    In this case, there exists a $\epsilon > 0$ such that, for all
    $k \geq 1$, we have
    $(\sup_{n \geq 0} |x^{(k)}_n - a_n|) > \epsilon$. In particulier,
    for all $k \geq 1$ and all $n \geq 0$, we have
    $|x^{(k)}_n - a_n| > \epsilon$. Thus,
    $\sum_{n=0}^{\infty} |x^{(k)}_n - a_n|$ is not even a convergent
    series, and we cannot have
    $\lim_{k \to \infty} \left(\sum_{n=0}^{\infty} |x^{(k)}_n - a_n|
    \right) = 0$.
  \end{enumerate}

  Note that this exercise actually shows that in this space $X$, the
  metrics are not equivalent; instead, the convergence in the taxi cab
  metric is stronger than the convergence in the sup norm metric.
  Thus, Proposition 12.1.18 is not true for \emph{any} metric space.
\end{exo}

\bigskip
\begin{exo}{12.1.16}{Let $\seq{x_n}{1}$ and $\seq{y_n}{1}$ be two
    sequences in a metric space $(X, d)$. Suppose that $\seq{x_n}{1}$
    converges to a point $x \in X$, and $\seq{y_n}{1}$ converges to a
    point $y \in X$. Show that
    $\lim_{n \to \infty} d(x_n, y_n) = d(x, y)$.}

  On the one hand, the triangle inequality applied two times to $d$
  gives us
  \[d(x_n, y_n) \leq d(x_n, x) + d(x,y) + d(y, y_n)\]
  but this is only half of what we need to prove the result.
  
  Similarly, we have
  \[d(x, y) \leq d(x, x_n) + d(x_n,y_n) + d(y_n, y)\]
  so that we can combine the previous two inequalities to get
  \[-d(x_n, x) - d(y_n, y) \leq d(x_n, y_n) - d(x, y) \leq d(x_n, x)
    + d(y_n, y)\]
  i.e.,
  \[|d(x_n, y_n) - d(x, y)| \leq d(x_n, x) + d(y_n, y).\]
  
  Let be $\epsilon > 0$. By hypothesis, there exists a $N_1 \geq 1$
  such that $d(x_n, x) \leq \epsilon/2$ whenever $n \geq N_1$.
  Similarly, there exists a $N_2 \geq 1$ such that $d(y_n, y) \leq
  \epsilon/2$ whenever $n \geq N_2$. Thus, if we set $N :=
  \max(N_1,N_2)$, then for all $n \geq N$ we have
  \[|d(x_n, y_n) - d(x, y)| \leq d(x_n, x) + d(y_n, y) \leq 2
    \epsilon/2 \ leq \epsilon\]
  which shows that $\lim_{n \to \infty} d(x_n, y_n) = d(x, y)$, as
  expected.    
\end{exo}

\pagebreak
\begin{exo}{12.2.1}{Verify the claims in Example 12.2.8}

  Let be $(X, \ddisc)$ a metric space, and $E$ a subset of $X$.

  \begin{itemize}
  \item Let be $x \in E$. Then $x$ is an interior point of $E$.
    Indeed, we have $B(x, 1/2) = \{x\} \subseteq E$.
  \item Let be $y \notin E$. Then $y$ is an exterior point of $E$.
    Indeed, we have $B(y, 1/2) \cap E = \{y\} \cap E = \emptyset$.
  \item Finally, there are no boundary points of $E$ in $(X, \ddisc)$.
    Indeed, let be $r > 0$ and any $x \in X$. We will always have
    $B(x, r) = \{x\}$ by definition of the discrete metric $\ddisc$.
    Thus, we have either $x \in E$ and then $x \in \inter (E)$, or $x
    \notin E$ and then $x \in \ext(E)$. Thus, $E$ has no boundary
    points.
  \end{itemize}
\end{exo}
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
